//
// Generated by LLVM NVPTX Back-End
//

.version 8.0
.target sm_60
.address_size 64

	// .globl	_local__makeIndexTuple_chpl // -- Begin function _local__makeIndexTuple_chpl
.visible .global .align 4 .u32 chpl__cid__ic_doSplit_chpl = 2;
.visible .global .align 4 .u32 chpl__cid_RootClass_chpl = 1;
.visible .global .align 4 .u32 chpl__cid_chpl___EndCountBase = 3;
.visible .global .align 4 .u32 chpl__cid_chpl___EndCount_AtomicT_int64_t_int64_t = 4;
.visible .global .align 4 .u32 chpl__cid_chpl_ModuleDeinit = 5;
.visible .global .align 4 .u32 chpl__cid_BaseDist_chpl = 6;
.visible .global .align 4 .u32 chpl__cid_BaseDom_chpl = 8;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularDom_1_int64_t_one_chpl = 9;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularDom_2_int64_t_one_chpl = 11;
.visible .global .align 4 .u32 chpl__cid_BaseArr_chpl = 13;
.visible .global .align 4 .u32 chpl__cid_BaseArrOverRectangularDom_1_int64_t_one_chpl = 14;
.visible .global .align 4 .u32 chpl__cid_BaseArrOverRectangularDom_2_int64_t_one_chpl = 37;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularArr_1_int64_t_one_AbstractLocaleModel_chpl = 15;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularArr_1_int64_t_one_Bin_chpl = 17;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularArr_1_int64_t_one_Particle_chpl = 19;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularArr_1_int64_t_one__real64_chpl = 21;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularArr_1_int64_t_one_chpl_LocalSpinlock_chpl = 23;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularArr_1_int64_t_one_chpl_bool_chpl = 25;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularArr_1_int64_t_one_int64_t_chpl = 27;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularArr_1_int64_t_one_locale_chpl = 29;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularArr_1_int64_t_one_range_int64_t_both_one_chpl = 31;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularArr_1_int64_t_one_string_chpl = 33;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularArr_1_int64_t_one_uint64_t_chpl = 35;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularArr_2_int64_t_one_Particle_chpl = 38;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularArr_2_int64_t_one__real64_chpl = 40;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularArr_2_int64_t_one_int64_t_chpl = 42;
.visible .global .align 4 .u32 chpl__cid_BaseLocale_chpl = 44;
.visible .global .align 4 .u32 chpl__cid_DummyLocale_chpl = 45;
.visible .global .align 4 .u32 chpl__cid_AbstractLocaleModel_chpl = 46;
.visible .global .align 4 .u32 chpl__cid_AbstractRootLocale_chpl = 49;
.visible .global .align 4 .u32 chpl__cid__ic_chpl_direct_counted_range_iter_chpl = 51;
.visible .global .align 4 .u32 chpl__cid__ic_chpl_direct_counted_range_iter_helper_chpl = 52;
.visible .global .align 4 .u32 chpl__cid__ic_chpl_direct_param_stride_range_iter_chpl = 53;
.visible .global .align 4 .u32 chpl__cid__ic_these_range_int64_t_both_one_chpl = 54;
.visible .global .align 4 .u32 chpl__cid_ReduceScanOp_chpl = 55;
.visible .global .align 4 .u32 chpl__cid_SumReduceScanOp__real64_chpl = 56;
.visible .global .align 4 .u32 chpl__cid_MaxReduceScanOp__real64_chpl = 57;
.visible .global .align 4 .u32 chpl__cid_MinReduceScanOp__real64_chpl = 58;
.visible .global .align 4 .u32 chpl__cid_DefaultDist_chpl = 7;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularDom_1_int64_t_one_chpl = 10;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularDom_2_int64_t_one_chpl = 12;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularArr_1_int64_t_one_AbstractLocaleModel_int64_t_chpl = 16;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularArr_1_int64_t_one_Bin_int64_t_chpl = 18;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularArr_1_int64_t_one_Particle_int64_t_chpl = 20;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularArr_1_int64_t_one__real64_int64_t_chpl = 22;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularArr_1_int64_t_one_chpl_LocalSpinlock_int64_t_chpl = 24;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularArr_1_int64_t_one_chpl_bool_int64_t_chpl = 26;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularArr_1_int64_t_one_int64_t_int64_t_chpl = 28;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularArr_1_int64_t_one_locale_int64_t_chpl = 30;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularArr_1_int64_t_one_range_int64_t_both_one_int64_t_chpl = 32;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularArr_1_int64_t_one_string_int64_t_chpl = 34;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularArr_1_int64_t_one_uint64_t_int64_t_chpl = 36;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularArr_2_int64_t_one_Particle_int64_t_chpl = 39;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularArr_2_int64_t_one__real64_int64_t_chpl = 41;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularArr_2_int64_t_one_int64_t_int64_t_chpl = 43;
.visible .global .align 4 .u32 chpl__cid_GPULocale_chpl = 47;
.visible .global .align 4 .u32 chpl__cid_LocaleModel_0_chpl = 48;
.visible .global .align 4 .u32 chpl__cid_RootLocale_chpl = 50;
.visible .global .align 4 .u32 chpl__cid_ReferenceCount_chpl = 59;
.visible .global .align 4 .u32 chpl__cid__ic_chpl_bytes__ref_string_chpl = 60;
.visible .global .align 4 .u32 chpl__cid__ic_split__ref_string_chpl = 61;
.visible .global .align 4 .u32 chpl__cid_Error_chpl = 62;
.visible .global .align 4 .u32 chpl__cid_NilThrownError_chpl = 63;
.visible .global .align 4 .u32 chpl__cid_NilClassError_chpl = 64;
.visible .global .align 4 .u32 chpl__cid_ClassCastError_chpl = 65;
.visible .global .align 4 .u32 chpl__cid_DecodeError_chpl = 66;
.visible .global .align 4 .u32 chpl__cid_IllegalArgumentError_chpl = 67;
.visible .global .align 4 .u32 chpl__cid_CodepointSplitError_chpl = 68;
.visible .global .align 4 .u32 chpl__cid_TaskErrors_chpl = 69;
.visible .global .align 4 .u32 chpl__cid_QioPluginFile_chpl = 90;
.visible .global .align 4 .u32 chpl__cid_QioPluginChannel_chpl = 91;
.visible .global .align 4 .u32 chpl__cid__serializeWrapper_binaryDeserializer_chpl = 92;
.visible .global .align 4 .u32 chpl__cid__serializeWrapper_binarySerializer_chpl = 93;
.visible .global .align 4 .u32 chpl__cid__serializeWrapper_defaultDeserializer_chpl = 94;
.visible .global .align 4 .u32 chpl__cid__serializeWrapper_defaultSerializer_chpl = 95;
.visible .global .align 4 .u32 chpl__cid_SystemError_chpl = 70;
.visible .global .align 4 .u32 chpl__cid_BlockingIoError_chpl = 71;
.visible .global .align 4 .u32 chpl__cid_ChildProcessError_chpl = 72;
.visible .global .align 4 .u32 chpl__cid_ConnectionError_chpl = 73;
.visible .global .align 4 .u32 chpl__cid_BrokenPipeError_chpl = 74;
.visible .global .align 4 .u32 chpl__cid_ConnectionAbortedError_chpl = 75;
.visible .global .align 4 .u32 chpl__cid_ConnectionRefusedError_chpl = 76;
.visible .global .align 4 .u32 chpl__cid_ConnectionResetError_chpl = 77;
.visible .global .align 4 .u32 chpl__cid_FileExistsError_chpl = 78;
.visible .global .align 4 .u32 chpl__cid_FileNotFoundError_chpl = 79;
.visible .global .align 4 .u32 chpl__cid_InterruptedError_chpl = 80;
.visible .global .align 4 .u32 chpl__cid_IsADirectoryError_chpl = 81;
.visible .global .align 4 .u32 chpl__cid_NotADirectoryError_chpl = 82;
.visible .global .align 4 .u32 chpl__cid_PermissionError_chpl = 83;
.visible .global .align 4 .u32 chpl__cid_ProcessLookupError_chpl = 84;
.visible .global .align 4 .u32 chpl__cid_TimeoutError_chpl = 85;
.visible .global .align 4 .u32 chpl__cid_IoError_chpl = 86;
.visible .global .align 4 .u32 chpl__cid_EofError_chpl = 87;
.visible .global .align 4 .u32 chpl__cid_UnexpectedEofError_chpl = 88;
.visible .global .align 4 .u32 chpl__cid_BadFormatError_chpl = 89;
.visible .global .align 4 .u32 chpl__cid_Timezone_chpl = 96;
.visible .global .align 4 .u32 chpl_numGlobalsOnHeap;
.visible .global .align 8 .b8 chpl_globals_registry[8];
.global .align 1 .b8 __unnamed_1[40] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 100, 105, 114, 101, 99, 116, 95, 112, 97, 114, 97, 109, 95, 115, 116, 114, 105, 100, 101, 95, 114, 97, 110, 103, 101, 95, 105, 116, 101, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5495 = generic(__unnamed_1);
.global .align 1 .b8 __unnamed_2[42] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 100, 105, 114, 101, 99, 116, 95, 99, 111, 117, 110, 116, 101, 100, 95, 114, 97, 110, 103, 101, 95, 105, 116, 101, 114, 95, 104, 101, 108, 112, 101, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5496 = generic(__unnamed_2);
.global .align 1 .b8 __unnamed_3[35] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 100, 105, 114, 101, 99, 116, 95, 99, 111, 117, 110, 116, 101, 100, 95, 114, 97, 110, 103, 101, 95, 105, 116, 101, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5497 = generic(__unnamed_3);
.global .align 1 .b8 __unnamed_4[34] = {95, 69, 110, 100, 67, 111, 117, 110, 116, 40, 97, 116, 111, 109, 105, 99, 32, 105, 110, 116, 40, 54, 52, 41, 44, 105, 110, 116, 40, 54, 52, 41, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5498 = generic(__unnamed_4);
.global .align 1 .b8 __unnamed_5[12] = {68, 101, 99, 111, 100, 101, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5499 = generic(__unnamed_5);
.global .align 1 .b8 __unnamed_6[15] = {78, 105, 108, 84, 104, 114, 111, 119, 110, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5500 = generic(__unnamed_6);
.global .align 1 .b8 __unnamed_7[21] = {73, 108, 108, 101, 103, 97, 108, 65, 114, 103, 117, 109, 101, 110, 116, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5501 = generic(__unnamed_7);
.global .align 1 .b8 __unnamed_8[27] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 100, 105, 114, 101, 99, 116, 95, 114, 97, 110, 103, 101, 95, 105, 116, 101, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5502 = generic(__unnamed_8);
.global .align 1 .b8 __unnamed_9[33] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 114, 97, 110, 103, 101, 95, 105, 110, 116, 54, 52, 95, 116, 95, 98, 111, 116, 104, 95, 111, 110, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_5503 = generic(__unnamed_9);
.global .align 1 .b8 __unnamed_10[27] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 98, 121, 116, 101, 115, 95, 95, 114, 101, 102, 95, 115, 116, 114, 105, 110, 103, 0};
.visible .global .align 8 .u64 _cstr_literal_5504 = generic(__unnamed_10);
.global .align 1 .b8 __unnamed_11[26] = {95, 105, 99, 95, 95, 105, 110, 100, 101, 120, 76, 101, 110, 95, 95, 114, 101, 102, 95, 115, 116, 114, 105, 110, 103, 0};
.visible .global .align 8 .u64 _cstr_literal_5505 = generic(__unnamed_11);
.global .align 1 .b8 __unnamed_12[28] = {95, 105, 99, 95, 95, 99, 112, 73, 110, 100, 101, 120, 76, 101, 110, 95, 95, 114, 101, 102, 95, 115, 116, 114, 105, 110, 103, 0};
.visible .global .align 8 .u64 _cstr_literal_5506 = generic(__unnamed_12);
.global .align 1 .b8 __unnamed_13[27] = {95, 105, 99, 95, 99, 111, 100, 101, 112, 111, 105, 110, 116, 115, 95, 95, 114, 101, 102, 95, 115, 116, 114, 105, 110, 103, 0};
.visible .global .align 8 .u64 _cstr_literal_5507 = generic(__unnamed_13);
.global .align 1 .b8 __unnamed_14[20] = {67, 111, 100, 101, 112, 111, 105, 110, 116, 83, 112, 108, 105, 116, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5508 = generic(__unnamed_14);
.global .align 1 .b8 __unnamed_15[12] = {68, 117, 109, 109, 121, 76, 111, 99, 97, 108, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_5509 = generic(__unnamed_15);
.global .align 1 .b8 __unnamed_16[9] = {69, 111, 102, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5510 = generic(__unnamed_16);
.global .align 1 .b8 __unnamed_17[19] = {85, 110, 101, 120, 112, 101, 99, 116, 101, 100, 69, 111, 102, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5511 = generic(__unnamed_17);
.global .align 1 .b8 __unnamed_18[15] = {66, 97, 100, 70, 111, 114, 109, 97, 116, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5512 = generic(__unnamed_18);
.global .align 1 .b8 __unnamed_19[16] = {66, 108, 111, 99, 107, 105, 110, 103, 73, 111, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5513 = generic(__unnamed_19);
.global .align 1 .b8 __unnamed_20[18] = {67, 104, 105, 108, 100, 80, 114, 111, 99, 101, 115, 115, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5514 = generic(__unnamed_20);
.global .align 1 .b8 __unnamed_21[16] = {66, 114, 111, 107, 101, 110, 80, 105, 112, 101, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5515 = generic(__unnamed_21);
.global .align 1 .b8 __unnamed_22[23] = {67, 111, 110, 110, 101, 99, 116, 105, 111, 110, 65, 98, 111, 114, 116, 101, 100, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5516 = generic(__unnamed_22);
.global .align 1 .b8 __unnamed_23[23] = {67, 111, 110, 110, 101, 99, 116, 105, 111, 110, 82, 101, 102, 117, 115, 101, 100, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5517 = generic(__unnamed_23);
.global .align 1 .b8 __unnamed_24[21] = {67, 111, 110, 110, 101, 99, 116, 105, 111, 110, 82, 101, 115, 101, 116, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5518 = generic(__unnamed_24);
.global .align 1 .b8 __unnamed_25[16] = {70, 105, 108, 101, 69, 120, 105, 115, 116, 115, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5519 = generic(__unnamed_25);
.global .align 1 .b8 __unnamed_26[18] = {70, 105, 108, 101, 78, 111, 116, 70, 111, 117, 110, 100, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5520 = generic(__unnamed_26);
.global .align 1 .b8 __unnamed_27[17] = {73, 110, 116, 101, 114, 114, 117, 112, 116, 101, 100, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5521 = generic(__unnamed_27);
.global .align 1 .b8 __unnamed_28[18] = {73, 115, 65, 68, 105, 114, 101, 99, 116, 111, 114, 121, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5522 = generic(__unnamed_28);
.global .align 1 .b8 __unnamed_29[19] = {78, 111, 116, 65, 68, 105, 114, 101, 99, 116, 111, 114, 121, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5523 = generic(__unnamed_29);
.global .align 1 .b8 __unnamed_30[16] = {80, 101, 114, 109, 105, 115, 115, 105, 111, 110, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5524 = generic(__unnamed_30);
.global .align 1 .b8 __unnamed_31[19] = {80, 114, 111, 99, 101, 115, 115, 76, 111, 111, 107, 117, 112, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5525 = generic(__unnamed_31);
.global .align 1 .b8 __unnamed_32[13] = {84, 105, 109, 101, 111, 117, 116, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5526 = generic(__unnamed_32);
.global .align 1 .b8 __unnamed_33[8] = {73, 111, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5527 = generic(__unnamed_33);
.global .align 1 .b8 __unnamed_34[12] = {83, 121, 115, 116, 101, 109, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5528 = generic(__unnamed_34);
.global .align 1 .b8 __unnamed_35[39] = {95, 115, 101, 114, 105, 97, 108, 105, 122, 101, 87, 114, 97, 112, 112, 101, 114, 40, 100, 101, 102, 97, 117, 108, 116, 68, 101, 115, 101, 114, 105, 97, 108, 105, 122, 101, 114, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5529 = generic(__unnamed_35);
.global .align 1 .b8 __unnamed_36[15] = {82, 101, 102, 101, 114, 101, 110, 99, 101, 67, 111, 117, 110, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5530 = generic(__unnamed_36);
.global .align 1 .b8 __unnamed_37[37] = {95, 115, 101, 114, 105, 97, 108, 105, 122, 101, 87, 114, 97, 112, 112, 101, 114, 40, 100, 101, 102, 97, 117, 108, 116, 83, 101, 114, 105, 97, 108, 105, 122, 101, 114, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5531 = generic(__unnamed_37);
.global .align 1 .b8 __unnamed_38[12] = {68, 101, 102, 97, 117, 108, 116, 68, 105, 115, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5532 = generic(__unnamed_38);
.global .align 1 .b8 __unnamed_39[22] = {100, 111, 109, 97, 105, 110, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5533 = generic(__unnamed_39);
.global .align 1 .b8 __unnamed_40[31] = {91, 100, 111, 109, 97, 105, 110, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 93, 32, 108, 111, 99, 97, 108, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_5534 = generic(__unnamed_40);
.global .align 1 .b8 __unnamed_41[41] = {66, 97, 115, 101, 65, 114, 114, 79, 118, 101, 114, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 68, 111, 109, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5535 = generic(__unnamed_41);
.global .align 1 .b8 __unnamed_42[18] = {95, 105, 99, 95, 95, 97, 114, 114, 115, 95, 66, 97, 115, 101, 68, 111, 109, 0};
.visible .global .align 8 .u64 _cstr_literal_5536 = generic(__unnamed_42);
.global .align 1 .b8 __unnamed_43[21] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 84, 97, 115, 107, 69, 114, 114, 111, 114, 115, 0};
.visible .global .align 8 .u64 _cstr_literal_5537 = generic(__unnamed_43);
.global .align 1 .b8 __unnamed_44[11] = {84, 97, 115, 107, 69, 114, 114, 111, 114, 115, 0};
.visible .global .align 8 .u64 _cstr_literal_5538 = generic(__unnamed_44);
.global .align 1 .b8 __unnamed_45[38] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 100, 105, 114, 101, 99, 116, 95, 112, 111, 115, 95, 115, 116, 114, 105, 100, 101, 95, 114, 97, 110, 103, 101, 95, 105, 116, 101, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5539 = generic(__unnamed_45);
.global .align 1 .b8 __unnamed_46[27] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 95, 115, 101, 114, 105, 97, 108, 86, 105, 101, 119, 73, 116, 101, 114, 49, 68, 0};
.visible .global .align 8 .u64 _cstr_literal_5540 = generic(__unnamed_46);
.global .align 1 .b8 __unnamed_47[25] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 95, 115, 101, 114, 105, 97, 108, 86, 105, 101, 119, 73, 116, 101, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5541 = generic(__unnamed_47);
.global .align 1 .b8 __unnamed_48[61] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 108, 111, 99, 97, 108, 101, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5542 = generic(__unnamed_48);
.global .align 1 .b8 __unnamed_49[73] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 97, 114, 114, 97, 121, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 108, 111, 99, 97, 108, 101, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5543 = generic(__unnamed_49);
.global .align 1 .b8 __unnamed_50[11] = {82, 111, 111, 116, 76, 111, 99, 97, 108, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_5544 = generic(__unnamed_50);
.global .align 1 .b8 __unnamed_51[46] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 68, 111, 109, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_5545 = generic(__unnamed_51);
.global .align 1 .b8 __unnamed_52[59] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 100, 111, 109, 97, 105, 110, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 68, 111, 109, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_5546 = generic(__unnamed_52);
.global .align 1 .b8 __unnamed_53[42] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 105, 110, 105, 116, 79, 110, 76, 111, 99, 97, 108, 101, 115, 95, 65, 98, 115, 116, 114, 97, 99, 116, 82, 111, 111, 116, 76, 111, 99, 97, 108, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_5547 = generic(__unnamed_53);
.global .align 1 .b8 __unnamed_54[54] = {91, 100, 111, 109, 97, 105, 110, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 93, 32, 117, 110, 109, 97, 110, 97, 103, 101, 100, 32, 65, 98, 115, 116, 114, 97, 99, 116, 76, 111, 99, 97, 108, 101, 77, 111, 100, 101, 108, 0};
.visible .global .align 8 .u64 _cstr_literal_5548 = generic(__unnamed_54);
.global .align 1 .b8 __unnamed_55[10] = {71, 80, 85, 76, 111, 99, 97, 108, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_5549 = generic(__unnamed_55);
.global .align 1 .b8 __unnamed_56[15] = {76, 111, 99, 97, 108, 101, 77, 111, 100, 101, 108, 40, 48, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5550 = generic(__unnamed_56);
.global .align 1 .b8 __unnamed_57[22] = {100, 111, 109, 97, 105, 110, 40, 50, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5551 = generic(__unnamed_57);
.global .align 1 .b8 __unnamed_58[33] = {91, 100, 111, 109, 97, 105, 110, 40, 50, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 93, 32, 80, 97, 114, 116, 105, 99, 108, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_5552 = generic(__unnamed_58);
.global .align 1 .b8 __unnamed_59[33] = {91, 100, 111, 109, 97, 105, 110, 40, 50, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 93, 32, 114, 101, 97, 108, 40, 54, 52, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5553 = generic(__unnamed_59);
.global .align 1 .b8 __unnamed_60[33] = {91, 100, 111, 109, 97, 105, 110, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 93, 32, 80, 97, 114, 116, 105, 99, 108, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_5554 = generic(__unnamed_60);
.global .align 1 .b8 __unnamed_61[33] = {91, 100, 111, 109, 97, 105, 110, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 93, 32, 114, 101, 97, 108, 40, 54, 52, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5555 = generic(__unnamed_61);
.global .align 1 .b8 __unnamed_62[32] = {91, 100, 111, 109, 97, 105, 110, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 93, 32, 105, 110, 116, 40, 54, 52, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5556 = generic(__unnamed_62);
.global .align 1 .b8 __unnamed_63[32] = {91, 100, 111, 109, 97, 105, 110, 40, 50, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 93, 32, 105, 110, 116, 40, 54, 52, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5557 = generic(__unnamed_63);
.global .align 1 .b8 __unnamed_64[28] = {91, 100, 111, 109, 97, 105, 110, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 93, 32, 66, 105, 110, 0};
.visible .global .align 8 .u64 _cstr_literal_5558 = generic(__unnamed_64);
.global .align 1 .b8 __unnamed_65[41] = {66, 97, 115, 101, 65, 114, 114, 79, 118, 101, 114, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 68, 111, 109, 40, 50, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5559 = generic(__unnamed_65);
.global .align 1 .b8 __unnamed_66[51] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 104, 101, 108, 112, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 68, 111, 109, 95, 50, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_5560 = generic(__unnamed_66);
.global .align 1 .b8 __unnamed_67[46] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 68, 111, 109, 95, 50, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_5561 = generic(__unnamed_67);
.global .align 1 .b8 __unnamed_68[62] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 50, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 105, 110, 116, 54, 52, 95, 116, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5562 = generic(__unnamed_68);
.global .align 1 .b8 __unnamed_69[74] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 97, 114, 114, 97, 121, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 50, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 105, 110, 116, 54, 52, 95, 116, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5563 = generic(__unnamed_69);
.global .align 1 .b8 __unnamed_70[35] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 100, 105, 114, 101, 99, 116, 95, 115, 116, 114, 105, 100, 101, 100, 95, 114, 97, 110, 103, 101, 95, 105, 116, 101, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5564 = generic(__unnamed_70);
.global .align 1 .b8 __unnamed_71[51] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 104, 101, 108, 112, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 68, 111, 109, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_5565 = generic(__unnamed_71);
.global .align 1 .b8 __unnamed_72[62] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 95, 114, 101, 97, 108, 54, 52, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5566 = generic(__unnamed_72);
.global .align 1 .b8 __unnamed_73[74] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 97, 114, 114, 97, 121, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 95, 114, 101, 97, 108, 54, 52, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5567 = generic(__unnamed_73);
.global .align 1 .b8 __unnamed_74[33] = {91, 100, 111, 109, 97, 105, 110, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 93, 32, 117, 105, 110, 116, 40, 54, 52, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5568 = generic(__unnamed_74);
.global .align 1 .b8 __unnamed_75[63] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 117, 105, 110, 116, 54, 52, 95, 116, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5569 = generic(__unnamed_75);
.global .align 1 .b8 __unnamed_76[75] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 97, 114, 114, 97, 121, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 117, 105, 110, 116, 54, 52, 95, 116, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5570 = generic(__unnamed_76);
.global .align 1 .b8 __unnamed_77[63] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 80, 97, 114, 116, 105, 99, 108, 101, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5571 = generic(__unnamed_77);
.global .align 1 .b8 __unnamed_78[75] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 97, 114, 114, 97, 121, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 80, 97, 114, 116, 105, 99, 108, 101, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5572 = generic(__unnamed_78);
.global .align 1 .b8 __unnamed_79[83] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 112, 114, 111, 109, 111, 49, 95, 120, 95, 95, 114, 101, 102, 95, 95, 97, 114, 114, 97, 121, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 80, 97, 114, 116, 105, 99, 108, 101, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5573 = generic(__unnamed_79);
.global .align 1 .b8 __unnamed_80[26] = {77, 97, 120, 82, 101, 100, 117, 99, 101, 83, 99, 97, 110, 79, 112, 40, 114, 101, 97, 108, 40, 54, 52, 41, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5574 = generic(__unnamed_80);
.global .align 1 .b8 __unnamed_81[83] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 112, 114, 111, 109, 111, 50, 95, 121, 95, 95, 114, 101, 102, 95, 95, 97, 114, 114, 97, 121, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 80, 97, 114, 116, 105, 99, 108, 101, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5575 = generic(__unnamed_81);
.global .align 1 .b8 __unnamed_82[26] = {77, 105, 110, 82, 101, 100, 117, 99, 101, 83, 99, 97, 110, 79, 112, 40, 114, 101, 97, 108, 40, 54, 52, 41, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5576 = generic(__unnamed_82);
.global .align 1 .b8 __unnamed_83[52] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 116, 117, 112, 108, 101, 95, 50, 95, 115, 116, 97, 114, 95, 114, 97, 110, 103, 101, 95, 105, 110, 116, 54, 52, 95, 116, 95, 98, 111, 116, 104, 95, 111, 110, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_5577 = generic(__unnamed_83);
.global .align 1 .b8 __unnamed_84[31] = {91, 100, 111, 109, 97, 105, 110, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 93, 32, 115, 116, 114, 105, 110, 103, 0};
.visible .global .align 8 .u64 _cstr_literal_5578 = generic(__unnamed_84);
.global .align 1 .b8 __unnamed_85[22] = {95, 105, 99, 95, 115, 112, 108, 105, 116, 95, 95, 114, 101, 102, 95, 115, 116, 114, 105, 110, 103, 0};
.visible .global .align 8 .u64 _cstr_literal_5579 = generic(__unnamed_85);
.global .align 1 .b8 __unnamed_86[12] = {95, 105, 99, 95, 100, 111, 83, 112, 108, 105, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5580 = generic(__unnamed_86);
.global .align 1 .b8 __unnamed_87[13] = {95, 105, 99, 95, 97, 100, 97, 112, 116, 105, 118, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_5581 = generic(__unnamed_87);
.global .align 1 .b8 __unnamed_88[48] = {91, 100, 111, 109, 97, 105, 110, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 93, 32, 114, 97, 110, 103, 101, 40, 105, 110, 116, 40, 54, 52, 41, 44, 98, 111, 116, 104, 44, 111, 110, 101, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5582 = generic(__unnamed_88);
.global .align 1 .b8 __unnamed_89[29] = {91, 100, 111, 109, 97, 105, 110, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 93, 32, 98, 111, 111, 108, 0};
.visible .global .align 8 .u64 _cstr_literal_5583 = generic(__unnamed_89);
.global .align 1 .b8 __unnamed_90[43] = {91, 100, 111, 109, 97, 105, 110, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 93, 32, 99, 104, 112, 108, 95, 76, 111, 99, 97, 108, 83, 112, 105, 110, 108, 111, 99, 107, 0};
.visible .global .align 8 .u64 _cstr_literal_5584 = generic(__unnamed_90);
.global .align 1 .b8 __unnamed_91[64] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 99, 104, 112, 108, 95, 98, 111, 111, 108, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5585 = generic(__unnamed_91);
.global .align 1 .b8 __unnamed_92[76] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 97, 114, 114, 97, 121, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 99, 104, 112, 108, 95, 98, 111, 111, 108, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5586 = generic(__unnamed_92);
.global .align 1 .b8 __unnamed_93[26] = {83, 117, 109, 82, 101, 100, 117, 99, 101, 83, 99, 97, 110, 79, 112, 40, 114, 101, 97, 108, 40, 54, 52, 41, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5587 = generic(__unnamed_93);
.global .align 1 .b8 __unnamed_94[18] = {99, 104, 112, 108, 95, 77, 111, 100, 117, 108, 101, 68, 101, 105, 110, 105, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5588 = generic(__unnamed_94);
.global .align 1 .b8 __unnamed_95[36] = {95, 115, 101, 114, 105, 97, 108, 105, 122, 101, 87, 114, 97, 112, 112, 101, 114, 40, 98, 105, 110, 97, 114, 121, 83, 101, 114, 105, 97, 108, 105, 122, 101, 114, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5589 = generic(__unnamed_95);
.global .align 1 .b8 __unnamed_96[38] = {95, 115, 101, 114, 105, 97, 108, 105, 122, 101, 87, 114, 97, 112, 112, 101, 114, 40, 98, 105, 110, 97, 114, 121, 68, 101, 115, 101, 114, 105, 97, 108, 105, 122, 101, 114, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5590 = generic(__unnamed_96);
.global .align 1 .b8 __unnamed_97[62] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 105, 110, 116, 54, 52, 95, 116, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5591 = generic(__unnamed_97);
.global .align 1 .b8 __unnamed_98[74] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 97, 114, 114, 97, 121, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 105, 110, 116, 54, 52, 95, 116, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5592 = generic(__unnamed_98);
.global .align 1 .b8 __unnamed_99[30] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 108, 105, 115, 116, 95, 105, 110, 116, 54, 52, 95, 116, 95, 70, 0};
.visible .global .align 8 .u64 _cstr_literal_5593 = generic(__unnamed_99);
.global .align 1 .b8 __unnamed_100[74] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 65, 98, 115, 116, 114, 97, 99, 116, 76, 111, 99, 97, 108, 101, 77, 111, 100, 101, 108, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5594 = generic(__unnamed_100);
.global .align 1 .b8 __unnamed_101[86] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 97, 114, 114, 97, 121, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 65, 98, 115, 116, 114, 97, 99, 116, 76, 111, 99, 97, 108, 101, 77, 111, 100, 101, 108, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5595 = generic(__unnamed_101);
.global .align 1 .b8 __unnamed_102[63] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 50, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 80, 97, 114, 116, 105, 99, 108, 101, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5596 = generic(__unnamed_102);
.global .align 1 .b8 __unnamed_103[75] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 97, 114, 114, 97, 121, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 50, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 80, 97, 114, 116, 105, 99, 108, 101, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5597 = generic(__unnamed_103);
.global .align 1 .b8 __unnamed_104[31] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 95, 115, 101, 114, 105, 97, 108, 86, 105, 101, 119, 73, 116, 101, 114, 72, 101, 108, 112, 101, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5598 = generic(__unnamed_104);
.global .align 1 .b8 __unnamed_105[62] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 50, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 95, 114, 101, 97, 108, 54, 52, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5599 = generic(__unnamed_105);
.global .align 1 .b8 __unnamed_106[74] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 97, 114, 114, 97, 121, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 50, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 95, 114, 101, 97, 108, 54, 52, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5600 = generic(__unnamed_106);
.global .align 1 .b8 __unnamed_107[58] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 66, 105, 110, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5601 = generic(__unnamed_107);
.global .align 1 .b8 __unnamed_108[70] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 97, 114, 114, 97, 121, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 66, 105, 110, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5602 = generic(__unnamed_108);
.global .align 1 .b8 __unnamed_109[61] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 115, 116, 114, 105, 110, 103, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5603 = generic(__unnamed_109);
.global .align 1 .b8 __unnamed_110[73] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 97, 114, 114, 97, 121, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 115, 116, 114, 105, 110, 103, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5604 = generic(__unnamed_110);
.global .align 1 .b8 __unnamed_111[77] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 114, 97, 110, 103, 101, 95, 105, 110, 116, 54, 52, 95, 116, 95, 98, 111, 116, 104, 95, 111, 110, 101, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5605 = generic(__unnamed_111);
.global .align 1 .b8 __unnamed_112[89] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 97, 114, 114, 97, 121, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 114, 97, 110, 103, 101, 95, 105, 110, 116, 54, 52, 95, 116, 95, 98, 111, 116, 104, 95, 111, 110, 101, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5606 = generic(__unnamed_112);
.global .align 1 .b8 __unnamed_113[73] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 99, 104, 112, 108, 95, 76, 111, 99, 97, 108, 83, 112, 105, 110, 108, 111, 99, 107, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5607 = generic(__unnamed_113);
.global .align 1 .b8 __unnamed_114[85] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 97, 114, 114, 97, 121, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 99, 104, 112, 108, 95, 76, 111, 99, 97, 108, 83, 112, 105, 110, 108, 111, 99, 107, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5608 = generic(__unnamed_114);
.global .align 1 .b8 __unnamed_115[14] = {78, 105, 108, 67, 108, 97, 115, 115, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5609 = generic(__unnamed_115);
.global .align 1 .b8 __unnamed_116[15] = {67, 108, 97, 115, 115, 67, 97, 115, 116, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5610 = generic(__unnamed_116);
.global .align 1 .b8 __unnamed_117[59] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 100, 111, 109, 97, 105, 110, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 68, 111, 109, 95, 50, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_5611 = generic(__unnamed_117);
.visible .global .align 8 .u64 chpl_mem_descs[243] = {generic(__unnamed_1), generic(__unnamed_2), generic(__unnamed_3), generic(__unnamed_4), generic(__unnamed_5), generic(__unnamed_6), generic(__unnamed_7), generic(__unnamed_8), generic(__unnamed_9), generic(__unnamed_10), generic(__unnamed_11), generic(__unnamed_12), generic(__unnamed_13), generic(__unnamed_14), generic(__unnamed_15), generic(__unnamed_16), generic(__unnamed_17), generic(__unnamed_18), generic(__unnamed_19), generic(__unnamed_20), generic(__unnamed_21), generic(__unnamed_22), generic(__unnamed_23), generic(__unnamed_24), generic(__unnamed_25), generic(__unnamed_26), generic(__unnamed_27), generic(__unnamed_28), generic(__unnamed_29), generic(__unnamed_30), generic(__unnamed_31), generic(__unnamed_32), generic(__unnamed_33), generic(__unnamed_34), generic(__unnamed_35), generic(__unnamed_36), generic(__unnamed_37), generic(__unnamed_38), generic(__unnamed_39), generic(__unnamed_40), generic(__unnamed_41), generic(__unnamed_42), generic(__unnamed_43), generic(__unnamed_44), generic(__unnamed_9), generic(__unnamed_45), generic(__unnamed_46), generic(__unnamed_47), generic(__unnamed_48), generic(__unnamed_49), generic(__unnamed_50), generic(__unnamed_51), generic(__unnamed_52), generic(__unnamed_53), generic(__unnamed_53), generic(__unnamed_54), generic(__unnamed_55), generic(__unnamed_56), generic(__unnamed_8), generic(__unnamed_57), generic(__unnamed_58), generic(__unnamed_59), generic(__unnamed_60), generic(__unnamed_61), generic(__unnamed_62), generic(__unnamed_63), generic(__unnamed_64), generic(__unnamed_65), generic(__unnamed_8), generic(__unnamed_66), generic(__unnamed_66), generic(__unnamed_67), generic(__unnamed_68), generic(__unnamed_69), generic(__unnamed_8), generic(__unnamed_1), generic(__unnamed_70), generic(__unnamed_8), generic(__unnamed_8), generic(__unnamed_71), generic(__unnamed_51), generic(__unnamed_72), generic(__unnamed_73), generic(__unnamed_1), generic(__unnamed_70), generic(__unnamed_74), generic(__unnamed_46), generic(__unnamed_47), generic(__unnamed_75), generic(__unnamed_76), generic(__unnamed_51), generic(__unnamed_77), generic(__unnamed_78), generic(__unnamed_46), generic(__unnamed_47), generic(__unnamed_77), generic(__unnamed_78), generic(__unnamed_51), generic(__unnamed_77), generic(__unnamed_78), generic(__unnamed_79), generic(__unnamed_79), generic(__unnamed_80), generic(__unnamed_79), generic(__unnamed_81), generic(__unnamed_81), generic(__unnamed_82), generic(__unnamed_81), generic(__unnamed_8), generic(__unnamed_8), generic(__unnamed_83), generic(__unnamed_84), generic(__unnamed_8), generic(__unnamed_85), generic(__unnamed_86), generic(__unnamed_8), generic(__unnamed_8), generic(__unnamed_87), generic(__unnamed_88), generic(__unnamed_89), generic(__unnamed_90), generic(__unnamed_91), generic(__unnamed_92), generic(__unnamed_87), generic(__unnamed_87), generic(__unnamed_52), generic(__unnamed_87), generic(__unnamed_93), generic(__unnamed_94), generic(__unnamed_95), generic(__unnamed_96), generic(__unnamed_97), generic(__unnamed_98), generic(__unnamed_46), generic(__unnamed_47), generic(__unnamed_97), generic(__unnamed_98), generic(__unnamed_97), generic(__unnamed_98), generic(__unnamed_99), generic(__unnamed_48), generic(__unnamed_49), generic(__unnamed_48), generic(__unnamed_49), generic(__unnamed_48), generic(__unnamed_49), generic(__unnamed_100), generic(__unnamed_101), generic(__unnamed_46), generic(__unnamed_47), generic(__unnamed_100), generic(__unnamed_101), generic(__unnamed_100), generic(__unnamed_101), generic(__unnamed_67), generic(__unnamed_102), generic(__unnamed_103), generic(__unnamed_66), generic(__unnamed_66), generic(__unnamed_67), generic(__unnamed_104), generic(__unnamed_47), generic(__unnamed_102), generic(__unnamed_103), generic(__unnamed_67), generic(__unnamed_102), generic(__unnamed_103), generic(__unnamed_105), generic(__unnamed_106), generic(__unnamed_104), generic(__unnamed_47), generic(__unnamed_105), generic(__unnamed_106), generic(__unnamed_105), generic(__unnamed_106), generic(__unnamed_72), generic(__unnamed_73), generic(__unnamed_46), generic(__unnamed_47), generic(__unnamed_72), generic(__unnamed_73), generic(__unnamed_72), generic(__unnamed_73), generic(__unnamed_68), generic(__unnamed_69), generic(__unnamed_104), generic(__unnamed_47), generic(__unnamed_68), generic(__unnamed_69), generic(__unnamed_68), generic(__unnamed_69), generic(__unnamed_107), generic(__unnamed_108), generic(__unnamed_46), generic(__unnamed_47), generic(__unnamed_107), generic(__unnamed_108), generic(__unnamed_107), generic(__unnamed_108), generic(__unnamed_107), generic(__unnamed_108), generic(__unnamed_75), generic(__unnamed_76), generic(__unnamed_75), generic(__unnamed_76), generic(__unnamed_109), generic(__unnamed_110), generic(__unnamed_46), generic(__unnamed_47), generic(__unnamed_109), generic(__unnamed_110), generic(__unnamed_109), generic(__unnamed_110), generic(__unnamed_109), generic(__unnamed_110), generic(__unnamed_111), generic(__unnamed_112), generic(__unnamed_46), generic(__unnamed_47), generic(__unnamed_111), generic(__unnamed_112), generic(__unnamed_111), generic(__unnamed_112), generic(__unnamed_91), generic(__unnamed_92), generic(__unnamed_46), generic(__unnamed_47), generic(__unnamed_91), generic(__unnamed_92), generic(__unnamed_91), generic(__unnamed_92), generic(__unnamed_113), generic(__unnamed_114), generic(__unnamed_46), generic(__unnamed_47), generic(__unnamed_113), generic(__unnamed_114), generic(__unnamed_113), generic(__unnamed_114), generic(__unnamed_115), generic(__unnamed_116), generic(__unnamed_52), generic(__unnamed_117)};
.visible .global .align 4 .u32 chpl_mem_numDescs = 243;
.visible .global .align 4 .b8 chpl_subclass_max_id[388] = {0, 0, 0, 0, 96, 0, 0, 0, 2, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 12, 0, 0, 0, 10, 0, 0, 0, 10, 0, 0, 0, 12, 0, 0, 0, 12, 0, 0, 0, 43, 0, 0, 0, 36, 0, 0, 0, 16, 0, 0, 0, 16, 0, 0, 0, 18, 0, 0, 0, 18, 0, 0, 0, 20, 0, 0, 0, 20, 0, 0, 0, 22, 0, 0, 0, 22, 0, 0, 0, 24, 0, 0, 0, 24, 0, 0, 0, 26, 0, 0, 0, 26, 0, 0, 0, 28, 0, 0, 0, 28, 0, 0, 0, 30, 0, 0, 0, 30, 0, 0, 0, 32, 0, 0, 0, 32, 0, 0, 0, 34, 0, 0, 0, 34, 0, 0, 0, 36, 0, 0, 0, 36, 0, 0, 0, 43, 0, 0, 0, 39, 0, 0, 0, 39, 0, 0, 0, 41, 0, 0, 0, 41, 0, 0, 0, 43, 0, 0, 0, 43, 0, 0, 0, 50, 0, 0, 0, 45, 0, 0, 0, 48, 0, 0, 0, 47, 0, 0, 0, 48, 0, 0, 0, 50, 0, 0, 0, 50, 0, 0, 0, 51, 0, 0, 0, 52, 0, 0, 0, 53, 0, 0, 0, 54, 0, 0, 0, 58, 0, 0, 0, 56, 0, 0, 0, 57, 0, 0, 0, 58, 0, 0, 0, 59, 0, 0, 0, 60, 0, 0, 0, 61, 0, 0, 0, 89, 0, 0, 0, 63, 0, 0, 0, 64, 0, 0, 0, 65, 0, 0, 0, 66, 0, 0, 0, 67, 0, 0, 0, 68, 0, 0, 0, 69, 0, 0, 0, 86, 0, 0, 0, 71, 0, 0, 0, 72, 0, 0, 0, 77, 0, 0, 0, 74, 0, 0, 0, 75, 0, 0, 0, 76, 0, 0, 0, 77, 0, 0, 0, 78, 0, 0, 0, 79, 0, 0, 0, 80, 0, 0, 0, 81, 0, 0, 0, 82, 0, 0, 0, 83, 0, 0, 0, 84, 0, 0, 0, 85, 0, 0, 0, 86, 0, 0, 0, 87, 0, 0, 0, 88, 0, 0, 0, 89, 0, 0, 0, 90, 0, 0, 0, 91, 0, 0, 0, 92, 0, 0, 0, 93, 0, 0, 0, 94, 0, 0, 0, 95, 0, 0, 0, 96, 0, 0, 0};
.global .align 1 .b8 __unnamed_118[1];
.visible .global .align 8 .u64 _cstr_literal_4684_chpl = generic(__unnamed_118);
.global .align 1 .b8 __unnamed_119[10] = {82, 111, 111, 116, 67, 108, 97, 115, 115, 0};
.visible .global .align 8 .u64 _cstr_literal_5612 = generic(__unnamed_119);
.global .align 1 .b8 __unnamed_120[14] = {95, 69, 110, 100, 67, 111, 117, 110, 116, 66, 97, 115, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_5613 = generic(__unnamed_120);
.global .align 1 .b8 __unnamed_121[9] = {66, 97, 115, 101, 68, 105, 115, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_5614 = generic(__unnamed_121);
.global .align 1 .b8 __unnamed_122[8] = {66, 97, 115, 101, 68, 111, 109, 0};
.visible .global .align 8 .u64 _cstr_literal_5615 = generic(__unnamed_122);
.global .align 1 .b8 __unnamed_123[34] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 68, 111, 109, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5616 = generic(__unnamed_123);
.global .align 1 .b8 __unnamed_124[34] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 68, 111, 109, 40, 50, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5617 = generic(__unnamed_124);
.global .align 1 .b8 __unnamed_125[8] = {66, 97, 115, 101, 65, 114, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5618 = generic(__unnamed_125);
.global .align 1 .b8 __unnamed_126[64] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 44, 117, 110, 109, 97, 110, 97, 103, 101, 100, 32, 65, 98, 115, 116, 114, 97, 99, 116, 76, 111, 99, 97, 108, 101, 77, 111, 100, 101, 108, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5619 = generic(__unnamed_126);
.global .align 1 .b8 __unnamed_127[38] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 44, 66, 105, 110, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5620 = generic(__unnamed_127);
.global .align 1 .b8 __unnamed_128[43] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 44, 80, 97, 114, 116, 105, 99, 108, 101, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5621 = generic(__unnamed_128);
.global .align 1 .b8 __unnamed_129[43] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 44, 114, 101, 97, 108, 40, 54, 52, 41, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5622 = generic(__unnamed_129);
.global .align 1 .b8 __unnamed_130[53] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 44, 99, 104, 112, 108, 95, 76, 111, 99, 97, 108, 83, 112, 105, 110, 108, 111, 99, 107, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5623 = generic(__unnamed_130);
.global .align 1 .b8 __unnamed_131[39] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 44, 98, 111, 111, 108, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5624 = generic(__unnamed_131);
.global .align 1 .b8 __unnamed_132[42] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 44, 105, 110, 116, 40, 54, 52, 41, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5625 = generic(__unnamed_132);
.global .align 1 .b8 __unnamed_133[41] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 44, 108, 111, 99, 97, 108, 101, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5626 = generic(__unnamed_133);
.global .align 1 .b8 __unnamed_134[58] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 44, 114, 97, 110, 103, 101, 40, 105, 110, 116, 40, 54, 52, 41, 44, 98, 111, 116, 104, 44, 111, 110, 101, 41, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5627 = generic(__unnamed_134);
.global .align 1 .b8 __unnamed_135[41] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 44, 115, 116, 114, 105, 110, 103, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5628 = generic(__unnamed_135);
.global .align 1 .b8 __unnamed_136[43] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 44, 117, 105, 110, 116, 40, 54, 52, 41, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5629 = generic(__unnamed_136);
.global .align 1 .b8 __unnamed_137[43] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 40, 50, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 44, 80, 97, 114, 116, 105, 99, 108, 101, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5630 = generic(__unnamed_137);
.global .align 1 .b8 __unnamed_138[43] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 40, 50, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 44, 114, 101, 97, 108, 40, 54, 52, 41, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5631 = generic(__unnamed_138);
.global .align 1 .b8 __unnamed_139[42] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 40, 50, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 44, 105, 110, 116, 40, 54, 52, 41, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_5632 = generic(__unnamed_139);
.global .align 1 .b8 __unnamed_140[11] = {66, 97, 115, 101, 76, 111, 99, 97, 108, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_5633 = generic(__unnamed_140);
.global .align 1 .b8 __unnamed_141[20] = {65, 98, 115, 116, 114, 97, 99, 116, 76, 111, 99, 97, 108, 101, 77, 111, 100, 101, 108, 0};
.visible .global .align 8 .u64 _cstr_literal_5634 = generic(__unnamed_141);
.global .align 1 .b8 __unnamed_142[19] = {65, 98, 115, 116, 114, 97, 99, 116, 82, 111, 111, 116, 76, 111, 99, 97, 108, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_5635 = generic(__unnamed_142);
.global .align 1 .b8 __unnamed_143[13] = {82, 101, 100, 117, 99, 101, 83, 99, 97, 110, 79, 112, 0};
.visible .global .align 8 .u64 _cstr_literal_5636 = generic(__unnamed_143);
.global .align 1 .b8 __unnamed_144[6] = {69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_2610_chpl = generic(__unnamed_144);
.global .align 1 .b8 __unnamed_145[16] = {67, 111, 110, 110, 101, 99, 116, 105, 111, 110, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_5637 = generic(__unnamed_145);
.global .align 1 .b8 __unnamed_146[14] = {81, 105, 111, 80, 108, 117, 103, 105, 110, 70, 105, 108, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_5638 = generic(__unnamed_146);
.global .align 1 .b8 __unnamed_147[17] = {81, 105, 111, 80, 108, 117, 103, 105, 110, 67, 104, 97, 110, 110, 101, 108, 0};
.visible .global .align 8 .u64 _cstr_literal_5639 = generic(__unnamed_147);
.global .align 1 .b8 __unnamed_148[9] = {84, 105, 109, 101, 122, 111, 110, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_5640 = generic(__unnamed_148);
.visible .global .align 8 .u64 chpl_classNames[97] = {generic(__unnamed_118), generic(__unnamed_119), generic(__unnamed_86), generic(__unnamed_120), generic(__unnamed_4), generic(__unnamed_94), generic(__unnamed_121), generic(__unnamed_38), generic(__unnamed_122), generic(__unnamed_123), generic(__unnamed_39), generic(__unnamed_124), generic(__unnamed_57), generic(__unnamed_125), generic(__unnamed_41), generic(__unnamed_126), generic(__unnamed_54), generic(__unnamed_127), generic(__unnamed_64), generic(__unnamed_128), generic(__unnamed_60), generic(__unnamed_129), generic(__unnamed_61), generic(__unnamed_130), generic(__unnamed_90), generic(__unnamed_131), generic(__unnamed_89), generic(__unnamed_132), generic(__unnamed_62), generic(__unnamed_133), generic(__unnamed_40), generic(__unnamed_134), generic(__unnamed_88), generic(__unnamed_135), generic(__unnamed_84), generic(__unnamed_136), generic(__unnamed_74), generic(__unnamed_65), generic(__unnamed_137), generic(__unnamed_58), generic(__unnamed_138), generic(__unnamed_59), generic(__unnamed_139), generic(__unnamed_63), generic(__unnamed_140), generic(__unnamed_15), generic(__unnamed_141), generic(__unnamed_55), generic(__unnamed_56), generic(__unnamed_142), generic(__unnamed_50), generic(__unnamed_3), generic(__unnamed_2), generic(__unnamed_1), generic(__unnamed_9), generic(__unnamed_143), generic(__unnamed_93), generic(__unnamed_80), generic(__unnamed_82), generic(__unnamed_36), generic(__unnamed_10), generic(__unnamed_85), generic(__unnamed_144), generic(__unnamed_6), generic(__unnamed_115), generic(__unnamed_116), generic(__unnamed_5), generic(__unnamed_7), generic(__unnamed_14), generic(__unnamed_44), generic(__unnamed_34), generic(__unnamed_19), generic(__unnamed_20), generic(__unnamed_145), generic(__unnamed_21), generic(__unnamed_22), generic(__unnamed_23), generic(__unnamed_24), generic(__unnamed_25), generic(__unnamed_26), generic(__unnamed_27), generic(__unnamed_28), generic(__unnamed_29), generic(__unnamed_30), generic(__unnamed_31), generic(__unnamed_32), generic(__unnamed_33), generic(__unnamed_16), generic(__unnamed_17), generic(__unnamed_18), generic(__unnamed_146), generic(__unnamed_147), generic(__unnamed_96), generic(__unnamed_95), generic(__unnamed_35), generic(__unnamed_37), generic(__unnamed_148)};
.visible .global .align 8 .b8 chpl_finfo[16];
.visible .global .align 8 .b8 chpl_vmtable[8];
.visible .global .align 4 .u32 chpl_nodeID = -1;
.visible .global .align 8 .u64 chpl_privateObjects;
.shared .align 8 .b8 _ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage[152];
.shared .align 8 .b8 _ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage[152];
.shared .align 8 .b8 _ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage[152];
                                        // @_local__makeIndexTuple_chpl
.visible .func _local__makeIndexTuple_chpl(
	.param .b64 _local__makeIndexTuple_chpl_param_0,
	.param .b64 _local__makeIndexTuple_chpl_param_1
)
{
	.reg .b64 	%rd<4>;

// %bb.0:
	ld.param.u64 	%rd1, [_local__makeIndexTuple_chpl_param_0];
	ld.u64 	%rd2, [%rd1];
	ld.param.u64 	%rd3, [_local__makeIndexTuple_chpl_param_1];
	st.u64 	[%rd3], %rd2;
	ret;
                                        // -- End function
}
	// .globl	_makeIndexTuple_chpl    // -- Begin function _makeIndexTuple_chpl
.visible .func _makeIndexTuple_chpl(
	.param .b64 _makeIndexTuple_chpl_param_0,
	.param .b64 _makeIndexTuple_chpl_param_1
)                                       // @_makeIndexTuple_chpl
{
	.reg .b64 	%rd<4>;

// %bb.0:
	ld.param.u64 	%rd1, [_makeIndexTuple_chpl_param_0];
	ld.u64 	%rd2, [%rd1];
	ld.param.u64 	%rd3, [_makeIndexTuple_chpl_param_1];
	st.u64 	[%rd3], %rd2;
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_ChapelArray_line_2548_ // -- Begin function chpl_gpu_kernel_ChapelArray_line_2548_
.visible .entry chpl_gpu_kernel_ChapelArray_line_2548_(
	.param .u64 chpl_gpu_kernel_ChapelArray_line_2548__param_0,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_2548__param_1,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_2548__param_2,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_2548__param_3,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_2548__param_4,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_2548__param_5,
	.param .u32 chpl_gpu_kernel_ChapelArray_line_2548__param_6
)                                       // @chpl_gpu_kernel_ChapelArray_line_2548_
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<20>;
	.reg .f64 	%fd<17>;

// %bb.0:
	ld.param.u64 	%rd6, [chpl_gpu_kernel_ChapelArray_line_2548__param_0];
	ld.param.u64 	%rd9, [chpl_gpu_kernel_ChapelArray_line_2548__param_2];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd10, %r2, %r1;
	cvt.s64.s32 	%rd11, %r3;
	add.s64 	%rd3, %rd10, %rd11;
	add.s64 	%rd4, %rd3, %rd6;
	setp.gt.s64 	%p1, %rd4, %rd9;
	@%p1 bra 	$L__BB2_2;
// %bb.1:
	ld.param.u64 	%rd5, [chpl_gpu_kernel_ChapelArray_line_2548__param_1];
	ld.param.u64 	%rd7, [chpl_gpu_kernel_ChapelArray_line_2548__param_4];
	cvta.to.global.u64 	%rd1, %rd7;
	ld.param.u64 	%rd8, [chpl_gpu_kernel_ChapelArray_line_2548__param_3];
	cvta.to.global.u64 	%rd2, %rd8;
	mul.lo.s64 	%rd12, %rd3, 144;
	add.s64 	%rd13, %rd2, %rd12;
	mul.lo.s64 	%rd14, %rd5, 144;
	add.s64 	%rd15, %rd13, %rd14;
	mul.lo.s64 	%rd16, %rd4, 144;
	add.s64 	%rd17, %rd1, %rd16;
	ld.global.u64 	%rd18, [%rd15];
	ld.global.f64 	%fd1, [%rd15+8];
	ld.global.f64 	%fd2, [%rd15+16];
	ld.global.f64 	%fd3, [%rd15+24];
	ld.global.f64 	%fd4, [%rd15+32];
	ld.global.f64 	%fd5, [%rd15+40];
	ld.global.f64 	%fd6, [%rd15+48];
	ld.global.f64 	%fd7, [%rd15+56];
	ld.global.f64 	%fd8, [%rd15+64];
	ld.global.f64 	%fd9, [%rd15+72];
	ld.global.f64 	%fd10, [%rd15+80];
	ld.global.f64 	%fd11, [%rd15+88];
	ld.global.f64 	%fd12, [%rd15+96];
	ld.global.f64 	%fd13, [%rd15+104];
	ld.global.f64 	%fd14, [%rd15+112];
	ld.global.f64 	%fd15, [%rd15+120];
	ld.global.f64 	%fd16, [%rd15+128];
	ld.global.u64 	%rd19, [%rd15+136];
	st.global.u64 	[%rd17], %rd18;
	st.global.f64 	[%rd17+8], %fd1;
	st.global.f64 	[%rd17+16], %fd2;
	st.global.f64 	[%rd17+24], %fd3;
	st.global.f64 	[%rd17+32], %fd4;
	st.global.f64 	[%rd17+40], %fd5;
	st.global.f64 	[%rd17+48], %fd6;
	st.global.f64 	[%rd17+56], %fd7;
	st.global.f64 	[%rd17+64], %fd8;
	st.global.f64 	[%rd17+72], %fd9;
	st.global.f64 	[%rd17+80], %fd10;
	st.global.f64 	[%rd17+88], %fd11;
	st.global.f64 	[%rd17+96], %fd12;
	st.global.f64 	[%rd17+104], %fd13;
	st.global.f64 	[%rd17+112], %fd14;
	st.global.f64 	[%rd17+120], %fd15;
	st.global.f64 	[%rd17+128], %fd16;
	st.global.u64 	[%rd17+136], %rd19;
$L__BB2_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_ChapelArray_line_2563_ // -- Begin function chpl_gpu_kernel_ChapelArray_line_2563_
.visible .entry chpl_gpu_kernel_ChapelArray_line_2563_(
	.param .u64 chpl_gpu_kernel_ChapelArray_line_2563__param_0,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_2563__param_1,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_2563__param_2,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_2563__param_3,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_2563__param_4
)                                       // @chpl_gpu_kernel_ChapelArray_line_2563_
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<20>;
	.reg .f64 	%fd<17>;

// %bb.0:
	ld.param.u64 	%rd6, [chpl_gpu_kernel_ChapelArray_line_2563__param_0];
	ld.param.u64 	%rd9, [chpl_gpu_kernel_ChapelArray_line_2563__param_2];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd10, %r2, %r1;
	cvt.s64.s32 	%rd11, %r3;
	add.s64 	%rd3, %rd10, %rd11;
	add.s64 	%rd4, %rd3, %rd6;
	setp.gt.s64 	%p1, %rd4, %rd9;
	@%p1 bra 	$L__BB3_2;
// %bb.1:
	ld.param.u64 	%rd5, [chpl_gpu_kernel_ChapelArray_line_2563__param_1];
	ld.param.u64 	%rd7, [chpl_gpu_kernel_ChapelArray_line_2563__param_4];
	cvta.to.global.u64 	%rd1, %rd7;
	ld.param.u64 	%rd8, [chpl_gpu_kernel_ChapelArray_line_2563__param_3];
	cvta.to.global.u64 	%rd2, %rd8;
	mul.lo.s64 	%rd12, %rd3, 144;
	add.s64 	%rd13, %rd2, %rd12;
	mul.lo.s64 	%rd14, %rd5, 144;
	add.s64 	%rd15, %rd13, %rd14;
	mul.lo.s64 	%rd16, %rd4, 144;
	add.s64 	%rd17, %rd1, %rd16;
	ld.global.u64 	%rd18, [%rd15];
	ld.global.f64 	%fd1, [%rd15+8];
	ld.global.f64 	%fd2, [%rd15+16];
	ld.global.f64 	%fd3, [%rd15+24];
	ld.global.f64 	%fd4, [%rd15+32];
	ld.global.f64 	%fd5, [%rd15+40];
	ld.global.f64 	%fd6, [%rd15+48];
	ld.global.f64 	%fd7, [%rd15+56];
	ld.global.f64 	%fd8, [%rd15+64];
	ld.global.f64 	%fd9, [%rd15+72];
	ld.global.f64 	%fd10, [%rd15+80];
	ld.global.f64 	%fd11, [%rd15+88];
	ld.global.f64 	%fd12, [%rd15+96];
	ld.global.f64 	%fd13, [%rd15+104];
	ld.global.f64 	%fd14, [%rd15+112];
	ld.global.f64 	%fd15, [%rd15+120];
	ld.global.f64 	%fd16, [%rd15+128];
	ld.global.u64 	%rd19, [%rd15+136];
	st.global.u64 	[%rd17], %rd18;
	st.global.f64 	[%rd17+8], %fd1;
	st.global.f64 	[%rd17+16], %fd2;
	st.global.f64 	[%rd17+24], %fd3;
	st.global.f64 	[%rd17+32], %fd4;
	st.global.f64 	[%rd17+40], %fd5;
	st.global.f64 	[%rd17+48], %fd6;
	st.global.f64 	[%rd17+56], %fd7;
	st.global.f64 	[%rd17+64], %fd8;
	st.global.f64 	[%rd17+72], %fd9;
	st.global.f64 	[%rd17+80], %fd10;
	st.global.f64 	[%rd17+88], %fd11;
	st.global.f64 	[%rd17+96], %fd12;
	st.global.f64 	[%rd17+104], %fd13;
	st.global.f64 	[%rd17+112], %fd14;
	st.global.f64 	[%rd17+120], %fd15;
	st.global.f64 	[%rd17+128], %fd16;
	st.global.u64 	[%rd17+136], %rd19;
$L__BB3_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_ChapelArray_line_3282_ // -- Begin function chpl_gpu_kernel_ChapelArray_line_3282_
.visible .entry chpl_gpu_kernel_ChapelArray_line_3282_(
	.param .u64 chpl_gpu_kernel_ChapelArray_line_3282__param_0,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_3282__param_1,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_3282__param_2,
	.param .f64 chpl_gpu_kernel_ChapelArray_line_3282__param_3
)                                       // @chpl_gpu_kernel_ChapelArray_line_3282_
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<11>;
	.reg .f64 	%fd<2>;

// %bb.0:
	ld.param.u64 	%rd2, [chpl_gpu_kernel_ChapelArray_line_3282__param_0];
	ld.param.u64 	%rd5, [chpl_gpu_kernel_ChapelArray_line_3282__param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd6, %r2, %r1;
	cvt.s64.s32 	%rd7, %r3;
	add.s64 	%rd8, %rd7, %rd2;
	add.s64 	%rd9, %rd8, %rd6;
	setp.gt.s64 	%p1, %rd9, %rd5;
	@%p1 bra 	$L__BB4_2;
// %bb.1:
	ld.param.f64 	%fd1, [chpl_gpu_kernel_ChapelArray_line_3282__param_3];
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelArray_line_3282__param_2];
	cvta.to.global.u64 	%rd4, %rd3;
	shl.b64 	%rd10, %rd9, 3;
	add.s64 	%rd1, %rd4, %rd10;
	st.global.f64 	[%rd1], %fd1;
$L__BB4_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_ChapelArray_line_3282_2 // -- Begin function chpl_gpu_kernel_ChapelArray_line_3282_2
.visible .entry chpl_gpu_kernel_ChapelArray_line_3282_2(
	.param .u64 chpl_gpu_kernel_ChapelArray_line_3282_2_param_0,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_3282_2_param_1,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_3282_2_param_2,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_3282_2_param_3,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_3282_2_param_4,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_3282_2_param_5,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_3282_2_param_6
)                                       // @chpl_gpu_kernel_ChapelArray_line_3282_2
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<28>;

// %bb.0:
	ld.param.u64 	%rd13, [chpl_gpu_kernel_ChapelArray_line_3282_2_param_6];
	ld.param.u64 	%rd12, [chpl_gpu_kernel_ChapelArray_line_3282_2_param_5];
	ld.param.u64 	%rd14, [chpl_gpu_kernel_ChapelArray_line_3282_2_param_0];
	ld.param.u64 	%rd16, [chpl_gpu_kernel_ChapelArray_line_3282_2_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd18, %r2, %r1;
	cvt.s64.s32 	%rd19, %r3;
	add.s64 	%rd20, %rd19, %rd14;
	add.s64 	%rd3, %rd20, %rd18;
	setp.le.s64 	%p1, %rd3, %rd16;
	setp.le.s64 	%p2, %rd12, %rd13;
	and.pred  	%p3, %p1, %p2;
	@!%p3 bra 	$L__BB5_3;
	bra.uni 	$L__BB5_1;
$L__BB5_1:
	ld.param.u64 	%rd11, [chpl_gpu_kernel_ChapelArray_line_3282_2_param_4];
	ld.param.u64 	%rd15, [chpl_gpu_kernel_ChapelArray_line_3282_2_param_3];
	cvta.to.global.u64 	%rd1, %rd15;
	ld.param.u64 	%rd17, [chpl_gpu_kernel_ChapelArray_line_3282_2_param_2];
	cvta.to.global.u64 	%rd2, %rd17;
	shl.b64 	%rd4, %rd3, 3;
	shl.b64 	%rd21, %rd12, 3;
	add.s64 	%rd27, %rd1, %rd21;
	sub.s64 	%rd22, %rd13, %rd12;
	add.s64 	%rd26, %rd22, 1;
$L__BB5_2:                              // =>This Inner Loop Header: Depth=1
	ld.global.u64 	%rd23, [%rd2+96];
	mul.lo.s64 	%rd24, %rd4, %rd23;
	add.s64 	%rd25, %rd27, %rd24;
	st.global.u64 	[%rd25], %rd11;
	add.s64 	%rd27, %rd27, 8;
	add.s64 	%rd26, %rd26, -1;
	setp.ne.s64 	%p4, %rd26, 0;
	@%p4 bra 	$L__BB5_2;
$L__BB5_3:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_ChapelArray_line_3282_3 // -- Begin function chpl_gpu_kernel_ChapelArray_line_3282_3
.visible .entry chpl_gpu_kernel_ChapelArray_line_3282_3(
	.param .u64 chpl_gpu_kernel_ChapelArray_line_3282_3_param_0,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_3282_3_param_1,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_3282_3_param_2,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_3282_3_param_3,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_3282_3_param_4,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_3282_3_param_5
)                                       // @chpl_gpu_kernel_ChapelArray_line_3282_3
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<19>;

// %bb.0:
	ld.param.u64 	%rd6, [chpl_gpu_kernel_ChapelArray_line_3282_3_param_0];
	ld.param.u64 	%rd8, [chpl_gpu_kernel_ChapelArray_line_3282_3_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd10, %r2, %r1;
	cvt.s64.s32 	%rd11, %r3;
	add.s64 	%rd12, %rd11, %rd6;
	add.s64 	%rd3, %rd12, %rd10;
	setp.gt.s64 	%p1, %rd3, %rd8;
	@%p1 bra 	$L__BB6_2;
// %bb.1:
	ld.param.u64 	%rd5, [chpl_gpu_kernel_ChapelArray_line_3282_3_param_5];
	ld.param.u64 	%rd4, [chpl_gpu_kernel_ChapelArray_line_3282_3_param_2];
	ld.param.u64 	%rd7, [chpl_gpu_kernel_ChapelArray_line_3282_3_param_4];
	cvta.to.global.u64 	%rd1, %rd7;
	ld.param.u64 	%rd9, [chpl_gpu_kernel_ChapelArray_line_3282_3_param_3];
	cvta.to.global.u64 	%rd2, %rd9;
	ld.global.u64 	%rd13, [%rd2+96];
	mul.lo.s64 	%rd14, %rd13, %rd4;
	shl.b64 	%rd15, %rd14, 3;
	add.s64 	%rd16, %rd1, %rd15;
	shl.b64 	%rd17, %rd3, 3;
	add.s64 	%rd18, %rd16, %rd17;
	st.global.u64 	[%rd18], %rd5;
$L__BB6_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_ChapelArray_line_3282_4 // -- Begin function chpl_gpu_kernel_ChapelArray_line_3282_4
.visible .entry chpl_gpu_kernel_ChapelArray_line_3282_4(
	.param .u64 chpl_gpu_kernel_ChapelArray_line_3282_4_param_0,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_3282_4_param_1,
	.param .u64 chpl_gpu_kernel_ChapelArray_line_3282_4_param_2,
	.param .u8 chpl_gpu_kernel_ChapelArray_line_3282_4_param_3
)                                       // @chpl_gpu_kernel_ChapelArray_line_3282_4
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<10>;

// %bb.0:
	ld.param.u64 	%rd2, [chpl_gpu_kernel_ChapelArray_line_3282_4_param_0];
	ld.param.u64 	%rd5, [chpl_gpu_kernel_ChapelArray_line_3282_4_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd6, %r2, %r1;
	cvt.s64.s32 	%rd7, %r3;
	add.s64 	%rd8, %rd7, %rd2;
	add.s64 	%rd9, %rd8, %rd6;
	setp.gt.s64 	%p1, %rd9, %rd5;
	@%p1 bra 	$L__BB7_2;
// %bb.1:
	ld.param.u8 	%rs1, [chpl_gpu_kernel_ChapelArray_line_3282_4_param_3];
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelArray_line_3282_4_param_2];
	cvta.to.global.u64 	%rd4, %rd3;
	add.s64 	%rd1, %rd4, %rd9;
	st.global.u8 	[%rd1], %rs1;
$L__BB7_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1554_ // -- Begin function chpl_gpu_kernel_ChapelBase_line_1554_
.visible .entry chpl_gpu_kernel_ChapelBase_line_1554_(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554__param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554__param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554__param_2
)                                       // @chpl_gpu_kernel_ChapelBase_line_1554_
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<12>;

// %bb.0:
	ld.param.u64 	%rd2, [chpl_gpu_kernel_ChapelBase_line_1554__param_0];
	ld.param.u64 	%rd5, [chpl_gpu_kernel_ChapelBase_line_1554__param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd6, %r2, %r1;
	cvt.s64.s32 	%rd7, %r3;
	add.s64 	%rd8, %rd7, %rd2;
	add.s64 	%rd9, %rd8, %rd6;
	setp.gt.s64 	%p1, %rd9, %rd5;
	@%p1 bra 	$L__BB8_2;
// %bb.1:
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1554__param_2];
	cvta.to.global.u64 	%rd4, %rd3;
	shl.b64 	%rd10, %rd9, 3;
	add.s64 	%rd1, %rd4, %rd10;
	mov.u64 	%rd11, 0;
	st.global.u64 	[%rd1], %rd11;
$L__BB8_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1554_2 // -- Begin function chpl_gpu_kernel_ChapelBase_line_1554_2
.visible .entry chpl_gpu_kernel_ChapelBase_line_1554_2(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554_2_param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554_2_param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554_2_param_2,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554_2_param_3,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554_2_param_4,
	.param .u32 chpl_gpu_kernel_ChapelBase_line_1554_2_param_5
)                                       // @chpl_gpu_kernel_ChapelBase_line_1554_2
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<13>;

// %bb.0:
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1554_2_param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_ChapelBase_line_1554_2_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd7, %r2, %r1;
	cvt.s64.s32 	%rd8, %r3;
	add.s64 	%rd9, %rd8, %rd3;
	add.s64 	%rd10, %rd9, %rd7;
	setp.gt.s64 	%p1, %rd10, %rd6;
	@%p1 bra 	$L__BB9_2;
// %bb.1:
	ld.param.u64 	%rd4, [chpl_gpu_kernel_ChapelBase_line_1554_2_param_3];
	cvta.to.global.u64 	%rd5, %rd4;
	shl.b64 	%rd11, %rd10, 4;
	add.s64 	%rd1, %rd5, %rd11;
	add.s64 	%rd2, %rd1, 8;
	ld.global.u32 	%r4, [chpl_nodeID];
	mov.b32 	%r5, 0;
	st.global.v2.u32 	[%rd1], {%r4, %r5};
	mov.u64 	%rd12, 0;
	st.global.u64 	[%rd2], %rd12;
$L__BB9_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1554_3 // -- Begin function chpl_gpu_kernel_ChapelBase_line_1554_3
.visible .entry chpl_gpu_kernel_ChapelBase_line_1554_3(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554_3_param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554_3_param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554_3_param_2
)                                       // @chpl_gpu_kernel_ChapelBase_line_1554_3
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<12>;

// %bb.0:
	ld.param.u64 	%rd2, [chpl_gpu_kernel_ChapelBase_line_1554_3_param_0];
	ld.param.u64 	%rd5, [chpl_gpu_kernel_ChapelBase_line_1554_3_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd6, %r2, %r1;
	cvt.s64.s32 	%rd7, %r3;
	add.s64 	%rd8, %rd7, %rd2;
	add.s64 	%rd9, %rd8, %rd6;
	setp.gt.s64 	%p1, %rd9, %rd5;
	@%p1 bra 	$L__BB10_2;
// %bb.1:
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1554_3_param_2];
	cvta.to.global.u64 	%rd4, %rd3;
	shl.b64 	%rd10, %rd9, 3;
	add.s64 	%rd1, %rd4, %rd10;
	mov.u64 	%rd11, 0;
	st.global.u64 	[%rd1], %rd11;
$L__BB10_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1554_4 // -- Begin function chpl_gpu_kernel_ChapelBase_line_1554_4
.visible .entry chpl_gpu_kernel_ChapelBase_line_1554_4(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554_4_param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554_4_param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554_4_param_2
)                                       // @chpl_gpu_kernel_ChapelBase_line_1554_4
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<12>;

// %bb.0:
	ld.param.u64 	%rd2, [chpl_gpu_kernel_ChapelBase_line_1554_4_param_0];
	ld.param.u64 	%rd5, [chpl_gpu_kernel_ChapelBase_line_1554_4_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd6, %r2, %r1;
	cvt.s64.s32 	%rd7, %r3;
	add.s64 	%rd8, %rd7, %rd2;
	add.s64 	%rd9, %rd8, %rd6;
	setp.gt.s64 	%p1, %rd9, %rd5;
	@%p1 bra 	$L__BB11_2;
// %bb.1:
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1554_4_param_2];
	cvta.to.global.u64 	%rd4, %rd3;
	shl.b64 	%rd10, %rd9, 3;
	add.s64 	%rd1, %rd4, %rd10;
	mov.u64 	%rd11, 0;
	st.global.u64 	[%rd1], %rd11;
$L__BB11_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1554_5 // -- Begin function chpl_gpu_kernel_ChapelBase_line_1554_5
.visible .entry chpl_gpu_kernel_ChapelBase_line_1554_5(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554_5_param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554_5_param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554_5_param_2
)                                       // @chpl_gpu_kernel_ChapelBase_line_1554_5
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<10>;

// %bb.0:
	ld.param.u64 	%rd2, [chpl_gpu_kernel_ChapelBase_line_1554_5_param_0];
	ld.param.u64 	%rd5, [chpl_gpu_kernel_ChapelBase_line_1554_5_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd6, %r2, %r1;
	cvt.s64.s32 	%rd7, %r3;
	add.s64 	%rd8, %rd7, %rd2;
	add.s64 	%rd9, %rd8, %rd6;
	setp.gt.s64 	%p1, %rd9, %rd5;
	@%p1 bra 	$L__BB12_2;
// %bb.1:
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1554_5_param_2];
	cvta.to.global.u64 	%rd4, %rd3;
	add.s64 	%rd1, %rd4, %rd9;
	mov.u16 	%rs1, 0;
	st.global.u8 	[%rd1], %rs1;
$L__BB12_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1554_6 // -- Begin function chpl_gpu_kernel_ChapelBase_line_1554_6
.visible .entry chpl_gpu_kernel_ChapelBase_line_1554_6(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554_6_param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554_6_param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554_6_param_2
)                                       // @chpl_gpu_kernel_ChapelBase_line_1554_6
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<14>;

// %bb.0:
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1554_6_param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_ChapelBase_line_1554_6_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd7, %r2, %r1;
	cvt.s64.s32 	%rd8, %r3;
	add.s64 	%rd9, %rd8, %rd3;
	add.s64 	%rd10, %rd9, %rd7;
	setp.gt.s64 	%p1, %rd10, %rd6;
	@%p1 bra 	$L__BB13_2;
// %bb.1:
	ld.param.u64 	%rd4, [chpl_gpu_kernel_ChapelBase_line_1554_6_param_2];
	cvta.to.global.u64 	%rd5, %rd4;
	shl.b64 	%rd11, %rd10, 4;
	add.s64 	%rd2, %rd5, %rd11;
	add.s64 	%rd1, %rd2, 8;
	mov.u64 	%rd12, 1;
	st.global.u64 	[%rd2], %rd12;
	mov.u64 	%rd13, 0;
	st.global.u64 	[%rd1], %rd13;
$L__BB13_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1554_7 // -- Begin function chpl_gpu_kernel_ChapelBase_line_1554_7
.visible .entry chpl_gpu_kernel_ChapelBase_line_1554_7(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554_7_param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554_7_param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554_7_param_2,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554_7_param_3,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1554_7_param_4,
	.param .u32 chpl_gpu_kernel_ChapelBase_line_1554_7_param_5
)                                       // @chpl_gpu_kernel_ChapelBase_line_1554_7
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<13>;

// %bb.0:
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1554_7_param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_ChapelBase_line_1554_7_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd7, %r2, %r1;
	cvt.s64.s32 	%rd8, %r3;
	add.s64 	%rd9, %rd8, %rd3;
	add.s64 	%rd10, %rd9, %rd7;
	setp.gt.s64 	%p1, %rd10, %rd6;
	@%p1 bra 	$L__BB14_2;
// %bb.1:
	ld.param.u64 	%rd4, [chpl_gpu_kernel_ChapelBase_line_1554_7_param_3];
	cvta.to.global.u64 	%rd5, %rd4;
	shl.b64 	%rd11, %rd10, 4;
	add.s64 	%rd1, %rd5, %rd11;
	add.s64 	%rd2, %rd1, 8;
	ld.global.u32 	%r4, [chpl_nodeID];
	mov.b32 	%r5, 0;
	st.global.v2.u32 	[%rd1], {%r4, %r5};
	mov.u64 	%rd12, 0;
	st.global.u64 	[%rd2], %rd12;
$L__BB14_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1563_ // -- Begin function chpl_gpu_kernel_ChapelBase_line_1563_
.visible .entry chpl_gpu_kernel_ChapelBase_line_1563_(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563__param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563__param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563__param_2
)                                       // @chpl_gpu_kernel_ChapelBase_line_1563_
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<12>;

// %bb.0:
	ld.param.u64 	%rd2, [chpl_gpu_kernel_ChapelBase_line_1563__param_0];
	ld.param.u64 	%rd5, [chpl_gpu_kernel_ChapelBase_line_1563__param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd6, %r2, %r1;
	cvt.s64.s32 	%rd7, %r3;
	add.s64 	%rd8, %rd7, %rd2;
	add.s64 	%rd9, %rd8, %rd6;
	setp.gt.s64 	%p1, %rd9, %rd5;
	@%p1 bra 	$L__BB15_2;
// %bb.1:
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1563__param_2];
	cvta.to.global.u64 	%rd4, %rd3;
	shl.b64 	%rd10, %rd9, 3;
	add.s64 	%rd1, %rd4, %rd10;
	mov.u64 	%rd11, 0;
	st.global.u64 	[%rd1], %rd11;
$L__BB15_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1563_2 // -- Begin function chpl_gpu_kernel_ChapelBase_line_1563_2
.visible .entry chpl_gpu_kernel_ChapelBase_line_1563_2(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563_2_param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563_2_param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563_2_param_2
)                                       // @chpl_gpu_kernel_ChapelBase_line_1563_2
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<12>;

// %bb.0:
	ld.param.u64 	%rd2, [chpl_gpu_kernel_ChapelBase_line_1563_2_param_0];
	ld.param.u64 	%rd5, [chpl_gpu_kernel_ChapelBase_line_1563_2_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd6, %r2, %r1;
	cvt.s64.s32 	%rd7, %r3;
	add.s64 	%rd8, %rd7, %rd2;
	add.s64 	%rd9, %rd8, %rd6;
	setp.gt.s64 	%p1, %rd9, %rd5;
	@%p1 bra 	$L__BB16_2;
// %bb.1:
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1563_2_param_2];
	cvta.to.global.u64 	%rd4, %rd3;
	shl.b64 	%rd10, %rd9, 3;
	add.s64 	%rd1, %rd4, %rd10;
	mov.u64 	%rd11, 0;
	st.global.u64 	[%rd1], %rd11;
$L__BB16_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1563_3 // -- Begin function chpl_gpu_kernel_ChapelBase_line_1563_3
.visible .entry chpl_gpu_kernel_ChapelBase_line_1563_3(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563_3_param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563_3_param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563_3_param_2
)                                       // @chpl_gpu_kernel_ChapelBase_line_1563_3
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<14>;

// %bb.0:
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1563_3_param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_ChapelBase_line_1563_3_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd7, %r2, %r1;
	cvt.s64.s32 	%rd8, %r3;
	add.s64 	%rd9, %rd8, %rd3;
	add.s64 	%rd10, %rd9, %rd7;
	setp.gt.s64 	%p1, %rd10, %rd6;
	@%p1 bra 	$L__BB17_2;
// %bb.1:
	ld.param.u64 	%rd4, [chpl_gpu_kernel_ChapelBase_line_1563_3_param_2];
	cvta.to.global.u64 	%rd5, %rd4;
	shl.b64 	%rd11, %rd10, 4;
	add.s64 	%rd2, %rd5, %rd11;
	add.s64 	%rd1, %rd2, 8;
	mov.u64 	%rd12, 1;
	st.global.u64 	[%rd2], %rd12;
	mov.u64 	%rd13, 0;
	st.global.u64 	[%rd1], %rd13;
$L__BB17_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1563_4 // -- Begin function chpl_gpu_kernel_ChapelBase_line_1563_4
.visible .entry chpl_gpu_kernel_ChapelBase_line_1563_4(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563_4_param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563_4_param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563_4_param_2,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563_4_param_3,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563_4_param_4,
	.param .u32 chpl_gpu_kernel_ChapelBase_line_1563_4_param_5
)                                       // @chpl_gpu_kernel_ChapelBase_line_1563_4
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<13>;

// %bb.0:
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1563_4_param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_ChapelBase_line_1563_4_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd7, %r2, %r1;
	cvt.s64.s32 	%rd8, %r3;
	add.s64 	%rd9, %rd8, %rd3;
	add.s64 	%rd10, %rd9, %rd7;
	setp.gt.s64 	%p1, %rd10, %rd6;
	@%p1 bra 	$L__BB18_2;
// %bb.1:
	ld.param.u64 	%rd4, [chpl_gpu_kernel_ChapelBase_line_1563_4_param_3];
	cvta.to.global.u64 	%rd5, %rd4;
	shl.b64 	%rd11, %rd10, 4;
	add.s64 	%rd1, %rd5, %rd11;
	add.s64 	%rd2, %rd1, 8;
	ld.global.u32 	%r4, [chpl_nodeID];
	mov.b32 	%r5, 0;
	st.global.v2.u32 	[%rd1], {%r4, %r5};
	mov.u64 	%rd12, 0;
	st.global.u64 	[%rd2], %rd12;
$L__BB18_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1563_5 // -- Begin function chpl_gpu_kernel_ChapelBase_line_1563_5
.visible .entry chpl_gpu_kernel_ChapelBase_line_1563_5(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563_5_param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563_5_param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563_5_param_2,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563_5_param_3,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563_5_param_4,
	.param .u32 chpl_gpu_kernel_ChapelBase_line_1563_5_param_5
)                                       // @chpl_gpu_kernel_ChapelBase_line_1563_5
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<13>;

// %bb.0:
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1563_5_param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_ChapelBase_line_1563_5_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd7, %r2, %r1;
	cvt.s64.s32 	%rd8, %r3;
	add.s64 	%rd9, %rd8, %rd3;
	add.s64 	%rd10, %rd9, %rd7;
	setp.gt.s64 	%p1, %rd10, %rd6;
	@%p1 bra 	$L__BB19_2;
// %bb.1:
	ld.param.u64 	%rd4, [chpl_gpu_kernel_ChapelBase_line_1563_5_param_3];
	cvta.to.global.u64 	%rd5, %rd4;
	shl.b64 	%rd11, %rd10, 4;
	add.s64 	%rd1, %rd5, %rd11;
	add.s64 	%rd2, %rd1, 8;
	ld.global.u32 	%r4, [chpl_nodeID];
	mov.b32 	%r5, 0;
	st.global.v2.u32 	[%rd1], {%r4, %r5};
	mov.u64 	%rd12, 0;
	st.global.u64 	[%rd2], %rd12;
$L__BB19_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1563_6 // -- Begin function chpl_gpu_kernel_ChapelBase_line_1563_6
.visible .entry chpl_gpu_kernel_ChapelBase_line_1563_6(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563_6_param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563_6_param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563_6_param_2
)                                       // @chpl_gpu_kernel_ChapelBase_line_1563_6
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<12>;

// %bb.0:
	ld.param.u64 	%rd2, [chpl_gpu_kernel_ChapelBase_line_1563_6_param_0];
	ld.param.u64 	%rd5, [chpl_gpu_kernel_ChapelBase_line_1563_6_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd6, %r2, %r1;
	cvt.s64.s32 	%rd7, %r3;
	add.s64 	%rd8, %rd7, %rd2;
	add.s64 	%rd9, %rd8, %rd6;
	setp.gt.s64 	%p1, %rd9, %rd5;
	@%p1 bra 	$L__BB20_2;
// %bb.1:
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1563_6_param_2];
	cvta.to.global.u64 	%rd4, %rd3;
	shl.b64 	%rd10, %rd9, 3;
	add.s64 	%rd1, %rd4, %rd10;
	mov.u64 	%rd11, 0;
	st.global.u64 	[%rd1], %rd11;
$L__BB20_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1563_7 // -- Begin function chpl_gpu_kernel_ChapelBase_line_1563_7
.visible .entry chpl_gpu_kernel_ChapelBase_line_1563_7(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563_7_param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563_7_param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1563_7_param_2
)                                       // @chpl_gpu_kernel_ChapelBase_line_1563_7
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<10>;

// %bb.0:
	ld.param.u64 	%rd2, [chpl_gpu_kernel_ChapelBase_line_1563_7_param_0];
	ld.param.u64 	%rd5, [chpl_gpu_kernel_ChapelBase_line_1563_7_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd6, %r2, %r1;
	cvt.s64.s32 	%rd7, %r3;
	add.s64 	%rd8, %rd7, %rd2;
	add.s64 	%rd9, %rd8, %rd6;
	setp.gt.s64 	%p1, %rd9, %rd5;
	@%p1 bra 	$L__BB21_2;
// %bb.1:
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1563_7_param_2];
	cvta.to.global.u64 	%rd4, %rd3;
	add.s64 	%rd1, %rd4, %rd9;
	mov.u16 	%rs1, 0;
	st.global.u8 	[%rd1], %rs1;
$L__BB21_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1764_ // -- Begin function chpl_gpu_kernel_ChapelBase_line_1764_
.visible .entry chpl_gpu_kernel_ChapelBase_line_1764_(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1764__param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1764__param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1764__param_2
)                                       // @chpl_gpu_kernel_ChapelBase_line_1764_
{


// %bb.0:
	ret;
                                        // -- End function
}
	// .globl	_local_contains_chpl    // -- Begin function _local_contains_chpl
.visible .func  (.param .b32 func_retval0) _local_contains_chpl(
	.param .b64 _local_contains_chpl_param_0,
	.param .b64 _local_contains_chpl_param_1
)                                       // @_local_contains_chpl
{
	.reg .pred 	%p<4>;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<7>;

// %bb.0:
	ld.param.u64 	%rd1, [_local_contains_chpl_param_0];
	ld.param.u64 	%rd2, [_local_contains_chpl_param_1];
	ld.u64 	%rd3, [%rd1+16];
	ld.u64 	%rd4, [%rd2];
	ld.u64 	%rd5, [%rd3+72];
	ld.u64 	%rd6, [%rd3+80];
	setp.le.s64 	%p1, %rd4, %rd6;
	setp.ge.s64 	%p2, %rd4, %rd5;
	and.pred  	%p3, %p1, %p2;
	selp.u32 	%r1, 1, 0, %p3;
	st.param.b32 	[func_retval0+0], %r1;
	ret;
                                        // -- End function
}
	// .globl	contains_chpl           // -- Begin function contains_chpl
.visible .func  (.param .b32 func_retval0) contains_chpl(
	.param .b64 contains_chpl_param_0,
	.param .b64 contains_chpl_param_1
)                                       // @contains_chpl
{
	.reg .pred 	%p<4>;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<7>;

// %bb.0:
	ld.param.u64 	%rd1, [contains_chpl_param_0];
	ld.param.u64 	%rd2, [contains_chpl_param_1];
	ld.u64 	%rd3, [%rd1+16];
	ld.u64 	%rd4, [%rd2];
	ld.u64 	%rd5, [%rd3+72];
	ld.u64 	%rd6, [%rd3+80];
	setp.le.s64 	%p1, %rd4, %rd6;
	setp.ge.s64 	%p2, %rd4, %rd5;
	and.pred  	%p3, %p1, %p2;
	selp.u32 	%r1, 1, 0, %p3;
	st.param.b32 	[func_retval0+0], %r1;
	ret;
                                        // -- End function
}
	// .globl	_local_deinit_chpl      // -- Begin function _local_deinit_chpl
.visible .func _local_deinit_chpl(
	.param .align 8 .b8 _local_deinit_chpl_param_0[16]
)                                       // @_local_deinit_chpl
{


// %bb.0:
	ret;
                                        // -- End function
}
	// .globl	deinit_chpl42           // -- Begin function deinit_chpl42
.visible .func deinit_chpl42(
	.param .align 8 .b8 deinit_chpl42_param_0[16]
)                                       // @deinit_chpl42
{


// %bb.0:
	ret;
                                        // -- End function
}
	// .globl	_local_init_chpl        // -- Begin function _local_init_chpl
.visible .func _local_init_chpl(
	.param .b64 _local_init_chpl_param_0
)                                       // @_local_init_chpl
{
	.reg .b64 	%rd<4>;

// %bb.0:
	ld.param.u64 	%rd1, [_local_init_chpl_param_0];
	mov.u64 	%rd2, 1;
	st.u64 	[%rd1], %rd2;
	mov.u64 	%rd3, 0;
	st.u64 	[%rd1+8], %rd3;
	ret;
                                        // -- End function
}
	// .globl	init_chpl61             // -- Begin function init_chpl61
.visible .func init_chpl61(
	.param .b64 init_chpl61_param_0
)                                       // @init_chpl61
{
	.reg .b64 	%rd<4>;

// %bb.0:
	ld.param.u64 	%rd1, [init_chpl61_param_0];
	mov.u64 	%rd2, 1;
	st.u64 	[%rd1], %rd2;
	mov.u64 	%rd3, 0;
	st.u64 	[%rd1+8], %rd3;
	ret;
                                        // -- End function
}
	// .globl	_local_init_chpl2       // -- Begin function _local_init_chpl2
.visible .func _local_init_chpl2(
	.param .b64 _local_init_chpl2_param_0,
	.param .b64 _local_init_chpl2_param_1,
	.param .b64 _local_init_chpl2_param_2,
	.param .b64 _local_init_chpl2_param_3,
	.param .b64 _local_init_chpl2_param_4
)                                       // @_local_init_chpl2
{
	.reg .b64 	%rd<4>;

// %bb.0:
	ld.param.u64 	%rd1, [_local_init_chpl2_param_0];
	ld.param.u64 	%rd2, [_local_init_chpl2_param_1];
	st.u64 	[%rd1], %rd2;
	ld.param.u64 	%rd3, [_local_init_chpl2_param_2];
	st.u64 	[%rd1+8], %rd3;
	ret;
                                        // -- End function
}
	// .globl	init_chpl67             // -- Begin function init_chpl67
.visible .func init_chpl67(
	.param .b64 init_chpl67_param_0,
	.param .b64 init_chpl67_param_1,
	.param .b64 init_chpl67_param_2,
	.param .b64 init_chpl67_param_3,
	.param .b64 init_chpl67_param_4
)                                       // @init_chpl67
{
	.reg .b64 	%rd<4>;

// %bb.0:
	ld.param.u64 	%rd1, [init_chpl67_param_0];
	ld.param.u64 	%rd2, [init_chpl67_param_1];
	st.u64 	[%rd1], %rd2;
	ld.param.u64 	%rd3, [init_chpl67_param_2];
	st.u64 	[%rd1+8], %rd3;
	ret;
                                        // -- End function
}
	// .globl	_local_accumulateOntoState_chpl // -- Begin function _local_accumulateOntoState_chpl
.visible .func _local_accumulateOntoState_chpl(
	.param .b64 _local_accumulateOntoState_chpl_param_0,
	.param .b64 _local_accumulateOntoState_chpl_param_1,
	.param .b64 _local_accumulateOntoState_chpl_param_2,
	.param .b64 _local_accumulateOntoState_chpl_param_3,
	.param .b32 _local_accumulateOntoState_chpl_param_4
)                                       // @_local_accumulateOntoState_chpl
{
	.reg .pred 	%p<3>;
	.reg .b64 	%rd<2>;
	.reg .f64 	%fd<6>;

// %bb.0:
	ld.param.u64 	%rd1, [_local_accumulateOntoState_chpl_param_1];
	ld.f64 	%fd1, [%rd1];
	ld.param.f64 	%fd2, [_local_accumulateOntoState_chpl_param_2];
	setp.gt.f64 	%p1, %fd1, %fd2;
	abs.f64 	%fd3, %fd1;
	setp.le.f64 	%p2, %fd3, 0d7FF0000000000000;
	selp.f64 	%fd4, %fd2, %fd1, %p2;
	selp.f64 	%fd5, %fd1, %fd4, %p1;
	st.f64 	[%rd1], %fd5;
	ret;
                                        // -- End function
}
	// .globl	accumulateOntoState_chpl // -- Begin function accumulateOntoState_chpl
.visible .func accumulateOntoState_chpl(
	.param .b64 accumulateOntoState_chpl_param_0,
	.param .b64 accumulateOntoState_chpl_param_1,
	.param .b64 accumulateOntoState_chpl_param_2,
	.param .b64 accumulateOntoState_chpl_param_3,
	.param .b32 accumulateOntoState_chpl_param_4
)                                       // @accumulateOntoState_chpl
{
	.reg .pred 	%p<3>;
	.reg .b64 	%rd<2>;
	.reg .f64 	%fd<6>;

// %bb.0:
	ld.param.u64 	%rd1, [accumulateOntoState_chpl_param_1];
	ld.f64 	%fd1, [%rd1];
	ld.param.f64 	%fd2, [accumulateOntoState_chpl_param_2];
	setp.gt.f64 	%p1, %fd1, %fd2;
	abs.f64 	%fd3, %fd1;
	setp.le.f64 	%p2, %fd3, 0d7FF0000000000000;
	selp.f64 	%fd4, %fd2, %fd1, %p2;
	selp.f64 	%fd5, %fd1, %fd4, %p1;
	st.f64 	[%rd1], %fd5;
	ret;
                                        // -- End function
}
	// .globl	_local_accumulateOntoState_chpl2 // -- Begin function _local_accumulateOntoState_chpl2
.visible .func _local_accumulateOntoState_chpl2(
	.param .b64 _local_accumulateOntoState_chpl2_param_0,
	.param .b64 _local_accumulateOntoState_chpl2_param_1,
	.param .b64 _local_accumulateOntoState_chpl2_param_2,
	.param .b64 _local_accumulateOntoState_chpl2_param_3,
	.param .b32 _local_accumulateOntoState_chpl2_param_4
)                                       // @_local_accumulateOntoState_chpl2
{
	.reg .pred 	%p<3>;
	.reg .b64 	%rd<2>;
	.reg .f64 	%fd<6>;

// %bb.0:
	ld.param.u64 	%rd1, [_local_accumulateOntoState_chpl2_param_1];
	ld.f64 	%fd1, [%rd1];
	ld.param.f64 	%fd2, [_local_accumulateOntoState_chpl2_param_2];
	setp.lt.f64 	%p1, %fd1, %fd2;
	abs.f64 	%fd3, %fd1;
	setp.le.f64 	%p2, %fd3, 0d7FF0000000000000;
	selp.f64 	%fd4, %fd2, %fd1, %p2;
	selp.f64 	%fd5, %fd1, %fd4, %p1;
	st.f64 	[%rd1], %fd5;
	ret;
                                        // -- End function
}
	// .globl	accumulateOntoState_chpl2 // -- Begin function accumulateOntoState_chpl2
.visible .func accumulateOntoState_chpl2(
	.param .b64 accumulateOntoState_chpl2_param_0,
	.param .b64 accumulateOntoState_chpl2_param_1,
	.param .b64 accumulateOntoState_chpl2_param_2,
	.param .b64 accumulateOntoState_chpl2_param_3,
	.param .b32 accumulateOntoState_chpl2_param_4
)                                       // @accumulateOntoState_chpl2
{
	.reg .pred 	%p<3>;
	.reg .b64 	%rd<2>;
	.reg .f64 	%fd<6>;

// %bb.0:
	ld.param.u64 	%rd1, [accumulateOntoState_chpl2_param_1];
	ld.f64 	%fd1, [%rd1];
	ld.param.f64 	%fd2, [accumulateOntoState_chpl2_param_2];
	setp.lt.f64 	%p1, %fd1, %fd2;
	abs.f64 	%fd3, %fd1;
	setp.le.f64 	%p2, %fd3, 0d7FF0000000000000;
	selp.f64 	%fd4, %fd2, %fd1, %p2;
	selp.f64 	%fd5, %fd1, %fd4, %p1;
	st.f64 	[%rd1], %fd5;
	ret;
                                        // -- End function
}
	// .globl	_local_dsiMember_chpl   // -- Begin function _local_dsiMember_chpl
.visible .func  (.param .b32 func_retval0) _local_dsiMember_chpl(
	.param .b64 _local_dsiMember_chpl_param_0,
	.param .b64 _local_dsiMember_chpl_param_1
)                                       // @_local_dsiMember_chpl
{
	.reg .pred 	%p<4>;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<6>;

// %bb.0:
	ld.param.u64 	%rd1, [_local_dsiMember_chpl_param_0];
	ld.param.u64 	%rd2, [_local_dsiMember_chpl_param_1];
	ld.u64 	%rd3, [%rd1+72];
	ld.u64 	%rd4, [%rd1+80];
	ld.u64 	%rd5, [%rd2];
	setp.le.s64 	%p1, %rd5, %rd4;
	setp.ge.s64 	%p2, %rd5, %rd3;
	and.pred  	%p3, %p1, %p2;
	selp.u32 	%r1, 1, 0, %p3;
	st.param.b32 	[func_retval0+0], %r1;
	ret;
                                        // -- End function
}
	// .globl	dsiMember_chpl          // -- Begin function dsiMember_chpl
.visible .func  (.param .b32 func_retval0) dsiMember_chpl(
	.param .b64 dsiMember_chpl_param_0,
	.param .b64 dsiMember_chpl_param_1
)                                       // @dsiMember_chpl
{
	.reg .pred 	%p<4>;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<6>;

// %bb.0:
	ld.param.u64 	%rd1, [dsiMember_chpl_param_0];
	ld.param.u64 	%rd2, [dsiMember_chpl_param_1];
	ld.u64 	%rd3, [%rd1+72];
	ld.u64 	%rd4, [%rd1+80];
	ld.u64 	%rd5, [%rd2];
	setp.le.s64 	%p1, %rd5, %rd4;
	setp.ge.s64 	%p2, %rd5, %rd3;
	and.pred  	%p3, %p1, %p2;
	selp.u32 	%r1, 1, 0, %p3;
	st.param.b32 	[func_retval0+0], %r1;
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1175_ // -- Begin function chpl_gpu_kernel_DefaultRectangular_line_1175_
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1175_(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1175__param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1175__param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1175__param_2
)                                       // @chpl_gpu_kernel_DefaultRectangular_line_1175_
{


// %bb.0:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1545_ // -- Begin function chpl_gpu_kernel_DefaultRectangular_line_1545_
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1545_(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545__param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545__param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545__param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545__param_3
)                                       // @chpl_gpu_kernel_DefaultRectangular_line_1545_
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<15>;

// %bb.0:
	ld.param.u64 	%rd4, [chpl_gpu_kernel_DefaultRectangular_line_1545__param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_DefaultRectangular_line_1545__param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd8, %r2, %r1;
	cvt.s64.s32 	%rd9, %r3;
	add.s64 	%rd10, %rd9, %rd4;
	add.s64 	%rd3, %rd10, %rd8;
	setp.gt.s64 	%p1, %rd3, %rd6;
	@%p1 bra 	$L__BB38_2;
// %bb.1:
	ld.param.u64 	%rd5, [chpl_gpu_kernel_DefaultRectangular_line_1545__param_3];
	cvta.to.global.u64 	%rd1, %rd5;
	ld.param.u64 	%rd7, [chpl_gpu_kernel_DefaultRectangular_line_1545__param_2];
	cvta.to.global.u64 	%rd2, %rd7;
	shl.b64 	%rd11, %rd3, 4;
	add.s64 	%rd12, %rd2, %rd11;
	add.s64 	%rd13, %rd1, %rd11;
	ld.global.v2.u32 	{%r4, %r5}, [%rd13];
	ld.global.u64 	%rd14, [%rd13+8];
	st.global.v2.u32 	[%rd12], {%r4, %r5};
	st.global.u64 	[%rd12+8], %rd14;
$L__BB38_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1545_10 // -- Begin function chpl_gpu_kernel_DefaultRectangular_line_1545_10
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1545_10(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_10_param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_10_param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_10_param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_10_param_3
)                                       // @chpl_gpu_kernel_DefaultRectangular_line_1545_10
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<13>;

// %bb.0:
	ld.param.u64 	%rd3, [chpl_gpu_kernel_DefaultRectangular_line_1545_10_param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_DefaultRectangular_line_1545_10_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd9, %r2, %r1;
	cvt.s64.s32 	%rd10, %r3;
	add.s64 	%rd11, %rd10, %rd3;
	add.s64 	%rd12, %rd11, %rd9;
	setp.gt.s64 	%p1, %rd12, %rd6;
	@%p1 bra 	$L__BB39_2;
// %bb.1:
	ld.param.u64 	%rd4, [chpl_gpu_kernel_DefaultRectangular_line_1545_10_param_3];
	cvta.to.global.u64 	%rd5, %rd4;
	ld.param.u64 	%rd7, [chpl_gpu_kernel_DefaultRectangular_line_1545_10_param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	add.s64 	%rd1, %rd5, %rd12;
	add.s64 	%rd2, %rd8, %rd12;
	ld.global.u8 	%rs1, [%rd1];
	st.global.u8 	[%rd2], %rs1;
$L__BB39_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1545_11 // -- Begin function chpl_gpu_kernel_DefaultRectangular_line_1545_11
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1545_11(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_11_param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_11_param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_11_param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_11_param_3,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_11_param_4,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_11_param_5,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_11_param_6
)                                       // @chpl_gpu_kernel_DefaultRectangular_line_1545_11
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<29>;
	.reg .f64 	%fd<17>;

// %bb.0:
	ld.param.u64 	%rd7, [chpl_gpu_kernel_DefaultRectangular_line_1545_11_param_0];
	ld.param.u64 	%rd9, [chpl_gpu_kernel_DefaultRectangular_line_1545_11_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd13, %r2, %r1;
	cvt.s64.s32 	%rd14, %r3;
	add.s64 	%rd15, %rd14, %rd7;
	add.s64 	%rd5, %rd15, %rd13;
	setp.gt.s64 	%p1, %rd5, %rd9;
	@%p1 bra 	$L__BB40_2;
// %bb.1:
	ld.param.u64 	%rd6, [chpl_gpu_kernel_DefaultRectangular_line_1545_11_param_2];
	ld.param.u64 	%rd8, [chpl_gpu_kernel_DefaultRectangular_line_1545_11_param_6];
	cvta.to.global.u64 	%rd1, %rd8;
	ld.param.u64 	%rd10, [chpl_gpu_kernel_DefaultRectangular_line_1545_11_param_5];
	cvta.to.global.u64 	%rd2, %rd10;
	ld.param.u64 	%rd11, [chpl_gpu_kernel_DefaultRectangular_line_1545_11_param_4];
	cvta.to.global.u64 	%rd3, %rd11;
	ld.param.u64 	%rd12, [chpl_gpu_kernel_DefaultRectangular_line_1545_11_param_3];
	cvta.to.global.u64 	%rd4, %rd12;
	ld.global.u64 	%rd16, [%rd4+96];
	mul.lo.s64 	%rd17, %rd16, %rd6;
	mul.lo.s64 	%rd18, %rd17, 144;
	add.s64 	%rd19, %rd3, %rd18;
	mul.lo.s64 	%rd20, %rd5, 144;
	add.s64 	%rd21, %rd19, %rd20;
	ld.global.u64 	%rd22, [%rd2+96];
	mul.lo.s64 	%rd23, %rd22, %rd6;
	mul.lo.s64 	%rd24, %rd23, 144;
	add.s64 	%rd25, %rd1, %rd24;
	add.s64 	%rd26, %rd25, %rd20;
	ld.global.u64 	%rd27, [%rd26];
	ld.global.f64 	%fd1, [%rd26+8];
	ld.global.f64 	%fd2, [%rd26+16];
	ld.global.f64 	%fd3, [%rd26+24];
	ld.global.f64 	%fd4, [%rd26+32];
	ld.global.f64 	%fd5, [%rd26+40];
	ld.global.f64 	%fd6, [%rd26+48];
	ld.global.f64 	%fd7, [%rd26+56];
	ld.global.f64 	%fd8, [%rd26+64];
	ld.global.f64 	%fd9, [%rd26+72];
	ld.global.f64 	%fd10, [%rd26+80];
	ld.global.f64 	%fd11, [%rd26+88];
	ld.global.f64 	%fd12, [%rd26+96];
	ld.global.f64 	%fd13, [%rd26+104];
	ld.global.f64 	%fd14, [%rd26+112];
	ld.global.f64 	%fd15, [%rd26+120];
	ld.global.f64 	%fd16, [%rd26+128];
	ld.global.u64 	%rd28, [%rd26+136];
	st.global.u64 	[%rd21], %rd27;
	st.global.f64 	[%rd21+8], %fd1;
	st.global.f64 	[%rd21+16], %fd2;
	st.global.f64 	[%rd21+24], %fd3;
	st.global.f64 	[%rd21+32], %fd4;
	st.global.f64 	[%rd21+40], %fd5;
	st.global.f64 	[%rd21+48], %fd6;
	st.global.f64 	[%rd21+56], %fd7;
	st.global.f64 	[%rd21+64], %fd8;
	st.global.f64 	[%rd21+72], %fd9;
	st.global.f64 	[%rd21+80], %fd10;
	st.global.f64 	[%rd21+88], %fd11;
	st.global.f64 	[%rd21+96], %fd12;
	st.global.f64 	[%rd21+104], %fd13;
	st.global.f64 	[%rd21+112], %fd14;
	st.global.f64 	[%rd21+120], %fd15;
	st.global.f64 	[%rd21+128], %fd16;
	st.global.u64 	[%rd21+136], %rd28;
$L__BB40_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1545_12 // -- Begin function chpl_gpu_kernel_DefaultRectangular_line_1545_12
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1545_12(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_12_param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_12_param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_12_param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_12_param_3,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_12_param_4,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_12_param_5,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_12_param_6,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_12_param_7
)                                       // @chpl_gpu_kernel_DefaultRectangular_line_1545_12
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<39>;

// %bb.0:
	ld.param.u64 	%rd17, [chpl_gpu_kernel_DefaultRectangular_line_1545_12_param_7];
	ld.param.u64 	%rd16, [chpl_gpu_kernel_DefaultRectangular_line_1545_12_param_6];
	ld.param.u64 	%rd18, [chpl_gpu_kernel_DefaultRectangular_line_1545_12_param_0];
	ld.param.u64 	%rd20, [chpl_gpu_kernel_DefaultRectangular_line_1545_12_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd24, %r2, %r1;
	cvt.s64.s32 	%rd25, %r3;
	add.s64 	%rd26, %rd25, %rd18;
	add.s64 	%rd5, %rd26, %rd24;
	setp.le.s64 	%p1, %rd5, %rd20;
	setp.le.s64 	%p2, %rd16, %rd17;
	and.pred  	%p3, %p1, %p2;
	@!%p3 bra 	$L__BB41_3;
	bra.uni 	$L__BB41_1;
$L__BB41_1:
	ld.param.u64 	%rd19, [chpl_gpu_kernel_DefaultRectangular_line_1545_12_param_5];
	cvta.to.global.u64 	%rd1, %rd19;
	ld.param.u64 	%rd21, [chpl_gpu_kernel_DefaultRectangular_line_1545_12_param_4];
	cvta.to.global.u64 	%rd2, %rd21;
	ld.param.u64 	%rd22, [chpl_gpu_kernel_DefaultRectangular_line_1545_12_param_2];
	ld.param.u64 	%rd23, [chpl_gpu_kernel_DefaultRectangular_line_1545_12_param_3];
	cvta.to.global.u64 	%rd3, %rd23;
	cvta.to.global.u64 	%rd4, %rd22;
	shl.b64 	%rd6, %rd5, 3;
	shl.b64 	%rd27, %rd16, 3;
	add.s64 	%rd38, %rd1, %rd27;
	add.s64 	%rd37, %rd3, %rd27;
	sub.s64 	%rd28, %rd17, %rd16;
	add.s64 	%rd36, %rd28, 1;
$L__BB41_2:                             // =>This Inner Loop Header: Depth=1
	ld.global.u64 	%rd29, [%rd4+96];
	mul.lo.s64 	%rd30, %rd6, %rd29;
	add.s64 	%rd31, %rd37, %rd30;
	ld.global.u64 	%rd32, [%rd2+96];
	mul.lo.s64 	%rd33, %rd6, %rd32;
	add.s64 	%rd34, %rd38, %rd33;
	ld.global.u64 	%rd35, [%rd34];
	st.global.u64 	[%rd31], %rd35;
	add.s64 	%rd38, %rd38, 8;
	add.s64 	%rd37, %rd37, 8;
	add.s64 	%rd36, %rd36, -1;
	setp.ne.s64 	%p4, %rd36, 0;
	@%p4 bra 	$L__BB41_2;
$L__BB41_3:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1545_13 // -- Begin function chpl_gpu_kernel_DefaultRectangular_line_1545_13
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1545_13(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_13_param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_13_param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_13_param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_13_param_3
)                                       // @chpl_gpu_kernel_DefaultRectangular_line_1545_13
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<13>;

// %bb.0:
	ld.param.u64 	%rd3, [chpl_gpu_kernel_DefaultRectangular_line_1545_13_param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_DefaultRectangular_line_1545_13_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd9, %r2, %r1;
	cvt.s64.s32 	%rd10, %r3;
	add.s64 	%rd11, %rd10, %rd3;
	add.s64 	%rd12, %rd11, %rd9;
	setp.gt.s64 	%p1, %rd12, %rd6;
	@%p1 bra 	$L__BB42_2;
// %bb.1:
	ld.param.u64 	%rd4, [chpl_gpu_kernel_DefaultRectangular_line_1545_13_param_3];
	cvta.to.global.u64 	%rd5, %rd4;
	ld.param.u64 	%rd7, [chpl_gpu_kernel_DefaultRectangular_line_1545_13_param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	add.s64 	%rd1, %rd5, %rd12;
	add.s64 	%rd2, %rd8, %rd12;
	ld.global.u8 	%rs1, [%rd1];
	st.global.u8 	[%rd2], %rs1;
$L__BB42_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1545_14 // -- Begin function chpl_gpu_kernel_DefaultRectangular_line_1545_14
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1545_14(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_14_param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_14_param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_14_param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_14_param_3,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_14_param_4,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_14_param_5,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_14_param_6,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_14_param_7
)                                       // @chpl_gpu_kernel_DefaultRectangular_line_1545_14
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<39>;
	.reg .f64 	%fd<2>;

// %bb.0:
	ld.param.u64 	%rd16, [chpl_gpu_kernel_DefaultRectangular_line_1545_14_param_7];
	ld.param.u64 	%rd15, [chpl_gpu_kernel_DefaultRectangular_line_1545_14_param_6];
	ld.param.u64 	%rd17, [chpl_gpu_kernel_DefaultRectangular_line_1545_14_param_0];
	ld.param.u64 	%rd19, [chpl_gpu_kernel_DefaultRectangular_line_1545_14_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd23, %r2, %r1;
	cvt.s64.s32 	%rd24, %r3;
	add.s64 	%rd25, %rd24, %rd17;
	add.s64 	%rd5, %rd25, %rd23;
	setp.le.s64 	%p1, %rd5, %rd19;
	setp.le.s64 	%p2, %rd15, %rd16;
	and.pred  	%p3, %p1, %p2;
	@!%p3 bra 	$L__BB43_3;
	bra.uni 	$L__BB43_1;
$L__BB43_1:
	ld.param.u64 	%rd18, [chpl_gpu_kernel_DefaultRectangular_line_1545_14_param_5];
	cvta.to.global.u64 	%rd1, %rd18;
	ld.param.u64 	%rd20, [chpl_gpu_kernel_DefaultRectangular_line_1545_14_param_4];
	cvta.to.global.u64 	%rd2, %rd20;
	ld.param.u64 	%rd21, [chpl_gpu_kernel_DefaultRectangular_line_1545_14_param_2];
	ld.param.u64 	%rd22, [chpl_gpu_kernel_DefaultRectangular_line_1545_14_param_3];
	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	ld.global.u64 	%rd26, [%rd4+96];
	ld.global.u64 	%rd27, [%rd2+96];
	mul.lo.s64 	%rd28, %rd27, %rd5;
	shl.b64 	%rd29, %rd28, 3;
	shl.b64 	%rd30, %rd15, 3;
	add.s64 	%rd31, %rd29, %rd30;
	add.s64 	%rd38, %rd1, %rd31;
	mul.lo.s64 	%rd32, %rd26, %rd5;
	shl.b64 	%rd33, %rd32, 3;
	add.s64 	%rd34, %rd33, %rd30;
	add.s64 	%rd37, %rd3, %rd34;
	sub.s64 	%rd35, %rd16, %rd15;
	add.s64 	%rd36, %rd35, 1;
$L__BB43_2:                             // =>This Inner Loop Header: Depth=1
	ld.global.f64 	%fd1, [%rd38];
	st.global.f64 	[%rd37], %fd1;
	add.s64 	%rd38, %rd38, 8;
	add.s64 	%rd37, %rd37, 8;
	add.s64 	%rd36, %rd36, -1;
	setp.ne.s64 	%p4, %rd36, 0;
	@%p4 bra 	$L__BB43_2;
$L__BB43_3:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1545_15 // -- Begin function chpl_gpu_kernel_DefaultRectangular_line_1545_15
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1545_15(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_15_param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_15_param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_15_param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_15_param_3,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_15_param_4,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_15_param_5,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_15_param_6,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_15_param_7
)                                       // @chpl_gpu_kernel_DefaultRectangular_line_1545_15
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<40>;
	.reg .f64 	%fd<17>;

// %bb.0:
	ld.param.u64 	%rd16, [chpl_gpu_kernel_DefaultRectangular_line_1545_15_param_7];
	ld.param.u64 	%rd15, [chpl_gpu_kernel_DefaultRectangular_line_1545_15_param_6];
	ld.param.u64 	%rd17, [chpl_gpu_kernel_DefaultRectangular_line_1545_15_param_0];
	ld.param.u64 	%rd19, [chpl_gpu_kernel_DefaultRectangular_line_1545_15_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd23, %r2, %r1;
	cvt.s64.s32 	%rd24, %r3;
	add.s64 	%rd25, %rd24, %rd17;
	add.s64 	%rd5, %rd25, %rd23;
	setp.le.s64 	%p1, %rd5, %rd19;
	setp.le.s64 	%p2, %rd15, %rd16;
	and.pred  	%p3, %p1, %p2;
	@!%p3 bra 	$L__BB44_3;
	bra.uni 	$L__BB44_1;
$L__BB44_1:
	ld.param.u64 	%rd18, [chpl_gpu_kernel_DefaultRectangular_line_1545_15_param_5];
	cvta.to.global.u64 	%rd38, %rd18;
	ld.param.u64 	%rd20, [chpl_gpu_kernel_DefaultRectangular_line_1545_15_param_4];
	cvta.to.global.u64 	%rd2, %rd20;
	ld.param.u64 	%rd21, [chpl_gpu_kernel_DefaultRectangular_line_1545_15_param_2];
	ld.param.u64 	%rd22, [chpl_gpu_kernel_DefaultRectangular_line_1545_15_param_3];
	cvta.to.global.u64 	%rd37, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	sub.s64 	%rd26, %rd16, %rd15;
	add.s64 	%rd39, %rd26, 1;
	mul.lo.s64 	%rd7, %rd5, 144;
	mul.lo.s64 	%rd8, %rd15, 144;
$L__BB44_2:                             // =>This Inner Loop Header: Depth=1
	ld.global.u64 	%rd27, [%rd4+96];
	mul.lo.s64 	%rd28, %rd7, %rd27;
	add.s64 	%rd29, %rd37, %rd8;
	add.s64 	%rd30, %rd29, %rd28;
	ld.global.u64 	%rd31, [%rd2+96];
	mul.lo.s64 	%rd32, %rd7, %rd31;
	add.s64 	%rd33, %rd38, %rd8;
	add.s64 	%rd34, %rd33, %rd32;
	ld.global.u64 	%rd35, [%rd34];
	ld.global.f64 	%fd1, [%rd34+8];
	ld.global.f64 	%fd2, [%rd34+16];
	ld.global.f64 	%fd3, [%rd34+24];
	ld.global.f64 	%fd4, [%rd34+32];
	ld.global.f64 	%fd5, [%rd34+40];
	ld.global.f64 	%fd6, [%rd34+48];
	ld.global.f64 	%fd7, [%rd34+56];
	ld.global.f64 	%fd8, [%rd34+64];
	ld.global.f64 	%fd9, [%rd34+72];
	ld.global.f64 	%fd10, [%rd34+80];
	ld.global.f64 	%fd11, [%rd34+88];
	ld.global.f64 	%fd12, [%rd34+96];
	ld.global.f64 	%fd13, [%rd34+104];
	ld.global.f64 	%fd14, [%rd34+112];
	ld.global.f64 	%fd15, [%rd34+120];
	ld.global.f64 	%fd16, [%rd34+128];
	ld.global.u64 	%rd36, [%rd34+136];
	st.global.u64 	[%rd30], %rd35;
	st.global.f64 	[%rd30+8], %fd1;
	st.global.f64 	[%rd30+16], %fd2;
	st.global.f64 	[%rd30+24], %fd3;
	st.global.f64 	[%rd30+32], %fd4;
	st.global.f64 	[%rd30+40], %fd5;
	st.global.f64 	[%rd30+48], %fd6;
	st.global.f64 	[%rd30+56], %fd7;
	st.global.f64 	[%rd30+64], %fd8;
	st.global.f64 	[%rd30+72], %fd9;
	st.global.f64 	[%rd30+80], %fd10;
	st.global.f64 	[%rd30+88], %fd11;
	st.global.f64 	[%rd30+96], %fd12;
	st.global.f64 	[%rd30+104], %fd13;
	st.global.f64 	[%rd30+112], %fd14;
	st.global.f64 	[%rd30+120], %fd15;
	st.global.f64 	[%rd30+128], %fd16;
	st.global.u64 	[%rd30+136], %rd36;
	add.s64 	%rd39, %rd39, -1;
	add.s64 	%rd38, %rd38, 144;
	add.s64 	%rd37, %rd37, 144;
	setp.ne.s64 	%p4, %rd39, 0;
	@%p4 bra 	$L__BB44_2;
$L__BB44_3:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1545_16 // -- Begin function chpl_gpu_kernel_DefaultRectangular_line_1545_16
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1545_16(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_16_param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_16_param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_16_param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_16_param_3,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_16_param_4,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_16_param_5,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_16_param_6
)                                       // @chpl_gpu_kernel_DefaultRectangular_line_1545_16
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<28>;

// %bb.0:
	ld.param.u64 	%rd7, [chpl_gpu_kernel_DefaultRectangular_line_1545_16_param_0];
	ld.param.u64 	%rd9, [chpl_gpu_kernel_DefaultRectangular_line_1545_16_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd13, %r2, %r1;
	cvt.s64.s32 	%rd14, %r3;
	add.s64 	%rd15, %rd14, %rd7;
	add.s64 	%rd5, %rd15, %rd13;
	setp.gt.s64 	%p1, %rd5, %rd9;
	@%p1 bra 	$L__BB45_2;
// %bb.1:
	ld.param.u64 	%rd6, [chpl_gpu_kernel_DefaultRectangular_line_1545_16_param_2];
	ld.param.u64 	%rd8, [chpl_gpu_kernel_DefaultRectangular_line_1545_16_param_6];
	cvta.to.global.u64 	%rd1, %rd8;
	ld.param.u64 	%rd10, [chpl_gpu_kernel_DefaultRectangular_line_1545_16_param_5];
	cvta.to.global.u64 	%rd2, %rd10;
	ld.param.u64 	%rd11, [chpl_gpu_kernel_DefaultRectangular_line_1545_16_param_4];
	cvta.to.global.u64 	%rd3, %rd11;
	ld.param.u64 	%rd12, [chpl_gpu_kernel_DefaultRectangular_line_1545_16_param_3];
	cvta.to.global.u64 	%rd4, %rd12;
	ld.global.u64 	%rd16, [%rd4+96];
	mul.lo.s64 	%rd17, %rd16, %rd6;
	shl.b64 	%rd18, %rd17, 3;
	add.s64 	%rd19, %rd3, %rd18;
	shl.b64 	%rd20, %rd5, 3;
	add.s64 	%rd21, %rd19, %rd20;
	ld.global.u64 	%rd22, [%rd2+96];
	mul.lo.s64 	%rd23, %rd22, %rd6;
	shl.b64 	%rd24, %rd23, 3;
	add.s64 	%rd25, %rd1, %rd24;
	add.s64 	%rd26, %rd25, %rd20;
	ld.global.u64 	%rd27, [%rd26];
	st.global.u64 	[%rd21], %rd27;
$L__BB45_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1545_17 // -- Begin function chpl_gpu_kernel_DefaultRectangular_line_1545_17
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1545_17(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_17_param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_17_param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_17_param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_17_param_3,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_17_param_4,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_17_param_5,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_17_param_6
)                                       // @chpl_gpu_kernel_DefaultRectangular_line_1545_17
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<27>;
	.reg .f64 	%fd<2>;

// %bb.0:
	ld.param.u64 	%rd7, [chpl_gpu_kernel_DefaultRectangular_line_1545_17_param_0];
	ld.param.u64 	%rd9, [chpl_gpu_kernel_DefaultRectangular_line_1545_17_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd13, %r2, %r1;
	cvt.s64.s32 	%rd14, %r3;
	add.s64 	%rd15, %rd14, %rd7;
	add.s64 	%rd5, %rd15, %rd13;
	setp.gt.s64 	%p1, %rd5, %rd9;
	@%p1 bra 	$L__BB46_2;
// %bb.1:
	ld.param.u64 	%rd6, [chpl_gpu_kernel_DefaultRectangular_line_1545_17_param_2];
	ld.param.u64 	%rd8, [chpl_gpu_kernel_DefaultRectangular_line_1545_17_param_6];
	cvta.to.global.u64 	%rd1, %rd8;
	ld.param.u64 	%rd10, [chpl_gpu_kernel_DefaultRectangular_line_1545_17_param_5];
	cvta.to.global.u64 	%rd2, %rd10;
	ld.param.u64 	%rd11, [chpl_gpu_kernel_DefaultRectangular_line_1545_17_param_4];
	cvta.to.global.u64 	%rd3, %rd11;
	ld.param.u64 	%rd12, [chpl_gpu_kernel_DefaultRectangular_line_1545_17_param_3];
	cvta.to.global.u64 	%rd4, %rd12;
	ld.global.u64 	%rd16, [%rd4+96];
	mul.lo.s64 	%rd17, %rd16, %rd6;
	shl.b64 	%rd18, %rd17, 3;
	add.s64 	%rd19, %rd3, %rd18;
	shl.b64 	%rd20, %rd5, 3;
	add.s64 	%rd21, %rd19, %rd20;
	ld.global.u64 	%rd22, [%rd2+96];
	mul.lo.s64 	%rd23, %rd22, %rd6;
	shl.b64 	%rd24, %rd23, 3;
	add.s64 	%rd25, %rd1, %rd24;
	add.s64 	%rd26, %rd25, %rd20;
	ld.global.f64 	%fd1, [%rd26];
	st.global.f64 	[%rd21], %fd1;
$L__BB46_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1545_2 // -- Begin function chpl_gpu_kernel_DefaultRectangular_line_1545_2
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1545_2(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_2_param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_2_param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_2_param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_2_param_3
)                                       // @chpl_gpu_kernel_DefaultRectangular_line_1545_2
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<15>;

// %bb.0:
	ld.param.u64 	%rd4, [chpl_gpu_kernel_DefaultRectangular_line_1545_2_param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_DefaultRectangular_line_1545_2_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd8, %r2, %r1;
	cvt.s64.s32 	%rd9, %r3;
	add.s64 	%rd10, %rd9, %rd4;
	add.s64 	%rd3, %rd10, %rd8;
	setp.gt.s64 	%p1, %rd3, %rd6;
	@%p1 bra 	$L__BB47_2;
// %bb.1:
	ld.param.u64 	%rd5, [chpl_gpu_kernel_DefaultRectangular_line_1545_2_param_3];
	cvta.to.global.u64 	%rd1, %rd5;
	ld.param.u64 	%rd7, [chpl_gpu_kernel_DefaultRectangular_line_1545_2_param_2];
	cvta.to.global.u64 	%rd2, %rd7;
	shl.b64 	%rd11, %rd3, 4;
	add.s64 	%rd12, %rd2, %rd11;
	add.s64 	%rd13, %rd1, %rd11;
	ld.global.v2.u32 	{%r4, %r5}, [%rd13];
	ld.global.u64 	%rd14, [%rd13+8];
	st.global.v2.u32 	[%rd12], {%r4, %r5};
	st.global.u64 	[%rd12+8], %rd14;
$L__BB47_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1545_3 // -- Begin function chpl_gpu_kernel_DefaultRectangular_line_1545_3
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1545_3(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_3_param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_3_param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_3_param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_3_param_3
)                                       // @chpl_gpu_kernel_DefaultRectangular_line_1545_3
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<16>;
	.reg .f64 	%fd<17>;

// %bb.0:
	ld.param.u64 	%rd4, [chpl_gpu_kernel_DefaultRectangular_line_1545_3_param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_DefaultRectangular_line_1545_3_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd8, %r2, %r1;
	cvt.s64.s32 	%rd9, %r3;
	add.s64 	%rd10, %rd9, %rd4;
	add.s64 	%rd3, %rd10, %rd8;
	setp.gt.s64 	%p1, %rd3, %rd6;
	@%p1 bra 	$L__BB48_2;
// %bb.1:
	ld.param.u64 	%rd5, [chpl_gpu_kernel_DefaultRectangular_line_1545_3_param_3];
	cvta.to.global.u64 	%rd1, %rd5;
	ld.param.u64 	%rd7, [chpl_gpu_kernel_DefaultRectangular_line_1545_3_param_2];
	cvta.to.global.u64 	%rd2, %rd7;
	mul.lo.s64 	%rd11, %rd3, 144;
	add.s64 	%rd12, %rd2, %rd11;
	add.s64 	%rd13, %rd1, %rd11;
	ld.global.u64 	%rd14, [%rd13];
	ld.global.f64 	%fd1, [%rd13+8];
	ld.global.f64 	%fd2, [%rd13+16];
	ld.global.f64 	%fd3, [%rd13+24];
	ld.global.f64 	%fd4, [%rd13+32];
	ld.global.f64 	%fd5, [%rd13+40];
	ld.global.f64 	%fd6, [%rd13+48];
	ld.global.f64 	%fd7, [%rd13+56];
	ld.global.f64 	%fd8, [%rd13+64];
	ld.global.f64 	%fd9, [%rd13+72];
	ld.global.f64 	%fd10, [%rd13+80];
	ld.global.f64 	%fd11, [%rd13+88];
	ld.global.f64 	%fd12, [%rd13+96];
	ld.global.f64 	%fd13, [%rd13+104];
	ld.global.f64 	%fd14, [%rd13+112];
	ld.global.f64 	%fd15, [%rd13+120];
	ld.global.f64 	%fd16, [%rd13+128];
	ld.global.u64 	%rd15, [%rd13+136];
	st.global.u64 	[%rd12], %rd14;
	st.global.f64 	[%rd12+8], %fd1;
	st.global.f64 	[%rd12+16], %fd2;
	st.global.f64 	[%rd12+24], %fd3;
	st.global.f64 	[%rd12+32], %fd4;
	st.global.f64 	[%rd12+40], %fd5;
	st.global.f64 	[%rd12+48], %fd6;
	st.global.f64 	[%rd12+56], %fd7;
	st.global.f64 	[%rd12+64], %fd8;
	st.global.f64 	[%rd12+72], %fd9;
	st.global.f64 	[%rd12+80], %fd10;
	st.global.f64 	[%rd12+88], %fd11;
	st.global.f64 	[%rd12+96], %fd12;
	st.global.f64 	[%rd12+104], %fd13;
	st.global.f64 	[%rd12+112], %fd14;
	st.global.f64 	[%rd12+120], %fd15;
	st.global.f64 	[%rd12+128], %fd16;
	st.global.u64 	[%rd12+136], %rd15;
$L__BB48_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1545_4 // -- Begin function chpl_gpu_kernel_DefaultRectangular_line_1545_4
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1545_4(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_4_param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_4_param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_4_param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_4_param_3
)                                       // @chpl_gpu_kernel_DefaultRectangular_line_1545_4
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<14>;
	.reg .f64 	%fd<2>;

// %bb.0:
	ld.param.u64 	%rd3, [chpl_gpu_kernel_DefaultRectangular_line_1545_4_param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_DefaultRectangular_line_1545_4_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd9, %r2, %r1;
	cvt.s64.s32 	%rd10, %r3;
	add.s64 	%rd11, %rd10, %rd3;
	add.s64 	%rd12, %rd11, %rd9;
	setp.gt.s64 	%p1, %rd12, %rd6;
	@%p1 bra 	$L__BB49_2;
// %bb.1:
	ld.param.u64 	%rd4, [chpl_gpu_kernel_DefaultRectangular_line_1545_4_param_3];
	cvta.to.global.u64 	%rd5, %rd4;
	ld.param.u64 	%rd7, [chpl_gpu_kernel_DefaultRectangular_line_1545_4_param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	shl.b64 	%rd13, %rd12, 3;
	add.s64 	%rd1, %rd5, %rd13;
	add.s64 	%rd2, %rd8, %rd13;
	ld.global.f64 	%fd1, [%rd1];
	st.global.f64 	[%rd2], %fd1;
$L__BB49_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1545_5 // -- Begin function chpl_gpu_kernel_DefaultRectangular_line_1545_5
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1545_5(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_5_param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_5_param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_5_param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_5_param_3
)                                       // @chpl_gpu_kernel_DefaultRectangular_line_1545_5
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<15>;

// %bb.0:
	ld.param.u64 	%rd3, [chpl_gpu_kernel_DefaultRectangular_line_1545_5_param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_DefaultRectangular_line_1545_5_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd9, %r2, %r1;
	cvt.s64.s32 	%rd10, %r3;
	add.s64 	%rd11, %rd10, %rd3;
	add.s64 	%rd12, %rd11, %rd9;
	setp.gt.s64 	%p1, %rd12, %rd6;
	@%p1 bra 	$L__BB50_2;
// %bb.1:
	ld.param.u64 	%rd4, [chpl_gpu_kernel_DefaultRectangular_line_1545_5_param_3];
	cvta.to.global.u64 	%rd5, %rd4;
	ld.param.u64 	%rd7, [chpl_gpu_kernel_DefaultRectangular_line_1545_5_param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	shl.b64 	%rd13, %rd12, 3;
	add.s64 	%rd1, %rd5, %rd13;
	add.s64 	%rd2, %rd8, %rd13;
	ld.global.u64 	%rd14, [%rd1];
	st.global.u64 	[%rd2], %rd14;
$L__BB50_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1545_6 // -- Begin function chpl_gpu_kernel_DefaultRectangular_line_1545_6
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1545_6(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_6_param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_6_param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_6_param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_6_param_3
)                                       // @chpl_gpu_kernel_DefaultRectangular_line_1545_6
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<8>;
	.reg .b64 	%rd<31>;
	.reg .f64 	%fd<5>;

// %bb.0:
	ld.param.u64 	%rd4, [chpl_gpu_kernel_DefaultRectangular_line_1545_6_param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_DefaultRectangular_line_1545_6_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd8, %r2, %r1;
	cvt.s64.s32 	%rd9, %r3;
	add.s64 	%rd10, %rd9, %rd4;
	add.s64 	%rd3, %rd10, %rd8;
	setp.gt.s64 	%p1, %rd3, %rd6;
	@%p1 bra 	$L__BB51_2;
// %bb.1:
	ld.param.u64 	%rd5, [chpl_gpu_kernel_DefaultRectangular_line_1545_6_param_3];
	cvta.to.global.u64 	%rd1, %rd5;
	ld.param.u64 	%rd7, [chpl_gpu_kernel_DefaultRectangular_line_1545_6_param_2];
	cvta.to.global.u64 	%rd2, %rd7;
	mul.lo.s64 	%rd11, %rd3, 184;
	add.s64 	%rd12, %rd2, %rd11;
	add.s64 	%rd13, %rd1, %rd11;
	ld.global.u64 	%rd14, [%rd13];
	ld.global.u64 	%rd15, [%rd13+8];
	ld.global.v2.u32 	{%r4, %r5}, [%rd13+16];
	ld.global.u64 	%rd16, [%rd13+24];
	ld.global.u64 	%rd17, [%rd13+32];
	ld.global.u64 	%rd18, [%rd13+40];
	ld.global.u64 	%rd19, [%rd13+48];
	ld.global.v2.u32 	{%r6, %r7}, [%rd13+56];
	ld.global.u64 	%rd20, [%rd13+64];
	ld.global.u64 	%rd21, [%rd13+72];
	ld.global.u64 	%rd22, [%rd13+80];
	ld.global.u64 	%rd23, [%rd13+120];
	ld.global.u64 	%rd24, [%rd13+128];
	ld.global.u64 	%rd25, [%rd13+136];
	ld.global.u64 	%rd26, [%rd13+144];
	ld.global.f64 	%fd1, [%rd13+152];
	ld.global.f64 	%fd2, [%rd13+160];
	ld.global.f64 	%fd3, [%rd13+168];
	ld.global.f64 	%fd4, [%rd13+176];
	ld.global.u64 	%rd27, [%rd13+88];
	ld.global.u64 	%rd28, [%rd13+96];
	ld.global.u64 	%rd29, [%rd13+104];
	ld.global.u64 	%rd30, [%rd13+112];
	st.global.u64 	[%rd12+112], %rd30;
	st.global.u64 	[%rd12+104], %rd29;
	st.global.u64 	[%rd12+96], %rd28;
	st.global.u64 	[%rd12+88], %rd27;
	st.global.u64 	[%rd12], %rd14;
	st.global.u64 	[%rd12+8], %rd15;
	st.global.v2.u32 	[%rd12+16], {%r4, %r5};
	st.global.u64 	[%rd12+24], %rd16;
	st.global.u64 	[%rd12+32], %rd17;
	st.global.u64 	[%rd12+40], %rd18;
	st.global.u64 	[%rd12+48], %rd19;
	st.global.v2.u32 	[%rd12+56], {%r6, %r7};
	st.global.u64 	[%rd12+64], %rd20;
	st.global.u64 	[%rd12+72], %rd21;
	st.global.u64 	[%rd12+80], %rd22;
	st.global.u64 	[%rd12+120], %rd23;
	st.global.u64 	[%rd12+128], %rd24;
	st.global.u64 	[%rd12+136], %rd25;
	st.global.u64 	[%rd12+144], %rd26;
	st.global.f64 	[%rd12+152], %fd1;
	st.global.f64 	[%rd12+160], %fd2;
	st.global.f64 	[%rd12+168], %fd3;
	st.global.f64 	[%rd12+176], %fd4;
$L__BB51_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1545_7 // -- Begin function chpl_gpu_kernel_DefaultRectangular_line_1545_7
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1545_7(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_7_param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_7_param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_7_param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_7_param_3
)                                       // @chpl_gpu_kernel_DefaultRectangular_line_1545_7
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<15>;

// %bb.0:
	ld.param.u64 	%rd3, [chpl_gpu_kernel_DefaultRectangular_line_1545_7_param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_DefaultRectangular_line_1545_7_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd9, %r2, %r1;
	cvt.s64.s32 	%rd10, %r3;
	add.s64 	%rd11, %rd10, %rd3;
	add.s64 	%rd12, %rd11, %rd9;
	setp.gt.s64 	%p1, %rd12, %rd6;
	@%p1 bra 	$L__BB52_2;
// %bb.1:
	ld.param.u64 	%rd4, [chpl_gpu_kernel_DefaultRectangular_line_1545_7_param_3];
	cvta.to.global.u64 	%rd5, %rd4;
	ld.param.u64 	%rd7, [chpl_gpu_kernel_DefaultRectangular_line_1545_7_param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	shl.b64 	%rd13, %rd12, 3;
	add.s64 	%rd1, %rd5, %rd13;
	add.s64 	%rd2, %rd8, %rd13;
	ld.global.u64 	%rd14, [%rd1];
	st.global.u64 	[%rd2], %rd14;
$L__BB52_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1545_8 // -- Begin function chpl_gpu_kernel_DefaultRectangular_line_1545_8
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1545_8(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_8_param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_8_param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_8_param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_8_param_3
)                                       // @chpl_gpu_kernel_DefaultRectangular_line_1545_8
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<19>;

// %bb.0:
	ld.param.u64 	%rd3, [chpl_gpu_kernel_DefaultRectangular_line_1545_8_param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_DefaultRectangular_line_1545_8_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd9, %r2, %r1;
	cvt.s64.s32 	%rd10, %r3;
	add.s64 	%rd11, %rd10, %rd3;
	add.s64 	%rd12, %rd11, %rd9;
	setp.gt.s64 	%p1, %rd12, %rd6;
	@%p1 bra 	$L__BB53_2;
// %bb.1:
	ld.param.u64 	%rd4, [chpl_gpu_kernel_DefaultRectangular_line_1545_8_param_3];
	cvta.to.global.u64 	%rd5, %rd4;
	ld.param.u64 	%rd7, [chpl_gpu_kernel_DefaultRectangular_line_1545_8_param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	mul.lo.s64 	%rd13, %rd12, 40;
	add.s64 	%rd1, %rd5, %rd13;
	add.s64 	%rd2, %rd8, %rd13;
	ld.global.u64 	%rd14, [%rd1];
	ld.global.u64 	%rd15, [%rd1+8];
	ld.global.u64 	%rd16, [%rd1+16];
	ld.global.u64 	%rd17, [%rd1+24];
	ld.global.u64 	%rd18, [%rd1+32];
	st.global.u64 	[%rd2+32], %rd18;
	st.global.u64 	[%rd2+24], %rd17;
	st.global.u64 	[%rd2+16], %rd16;
	st.global.u64 	[%rd2+8], %rd15;
	st.global.u64 	[%rd2], %rd14;
$L__BB53_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1545_9 // -- Begin function chpl_gpu_kernel_DefaultRectangular_line_1545_9
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1545_9(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_9_param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_9_param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_9_param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1545_9_param_3
)                                       // @chpl_gpu_kernel_DefaultRectangular_line_1545_9
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<18>;

// %bb.0:
	ld.param.u64 	%rd5, [chpl_gpu_kernel_DefaultRectangular_line_1545_9_param_0];
	ld.param.u64 	%rd8, [chpl_gpu_kernel_DefaultRectangular_line_1545_9_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd11, %r2, %r1;
	cvt.s64.s32 	%rd12, %r3;
	add.s64 	%rd13, %rd12, %rd5;
	add.s64 	%rd14, %rd13, %rd11;
	setp.gt.s64 	%p1, %rd14, %rd8;
	@%p1 bra 	$L__BB54_2;
// %bb.1:
	ld.param.u64 	%rd6, [chpl_gpu_kernel_DefaultRectangular_line_1545_9_param_3];
	cvta.to.global.u64 	%rd7, %rd6;
	ld.param.u64 	%rd9, [chpl_gpu_kernel_DefaultRectangular_line_1545_9_param_2];
	cvta.to.global.u64 	%rd10, %rd9;
	shl.b64 	%rd15, %rd14, 4;
	add.s64 	%rd4, %rd10, %rd15;
	add.s64 	%rd1, %rd4, 8;
	add.s64 	%rd3, %rd7, %rd15;
	add.s64 	%rd2, %rd3, 8;
	ld.global.u64 	%rd16, [%rd3];
	ld.global.u64 	%rd17, [%rd2];
	st.global.u64 	[%rd4], %rd16;
	st.global.u64 	[%rd1], %rd17;
$L__BB54_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1559_ // -- Begin function chpl_gpu_kernel_DefaultRectangular_line_1559_
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1559_(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1559__param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1559__param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1559__param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1559__param_3
)                                       // @chpl_gpu_kernel_DefaultRectangular_line_1559_
{


// %bb.0:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_amatter3d_line_264_ // -- Begin function chpl_gpu_kernel_amatter3d_line_264_
.visible .entry chpl_gpu_kernel_amatter3d_line_264_(
	.param .u64 chpl_gpu_kernel_amatter3d_line_264__param_0,
	.param .u64 chpl_gpu_kernel_amatter3d_line_264__param_1,
	.param .u64 chpl_gpu_kernel_amatter3d_line_264__param_2,
	.param .f64 chpl_gpu_kernel_amatter3d_line_264__param_3,
	.param .u64 chpl_gpu_kernel_amatter3d_line_264__param_4
)                                       // @chpl_gpu_kernel_amatter3d_line_264_
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<24>;
	.reg .b64 	%rd<18>;
	.reg .f64 	%fd<49>;

// %bb.0:
	ld.param.f64 	%fd47, [chpl_gpu_kernel_amatter3d_line_264__param_3];
	ld.param.u64 	%rd4, [chpl_gpu_kernel_amatter3d_line_264__param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_amatter3d_line_264__param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r2, %tid.x;
	mul.wide.s32 	%rd9, %r3, %r1;
	cvt.s64.s32 	%rd10, %r2;
	add.s64 	%rd11, %rd10, %rd4;
	add.s64 	%rd12, %rd11, %rd9;
	setp.gt.s64 	%p1, %rd12, %rd6;
	@%p1 bra 	$L__BB56_2;
// %bb.1:
	ld.param.u64 	%rd7, [chpl_gpu_kernel_amatter3d_line_264__param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	shl.b64 	%rd13, %rd12, 3;
	add.s64 	%rd2, %rd8, %rd13;
	ld.global.f64 	%fd7, [%rd2];
	add.rn.f64 	%fd47, %fd7, %fd47;
$L__BB56_2:
	// begin inline asm
	mov.u32 %r4, %laneid;
	// end inline asm
	mov.b32 	%r5, 1;
	mov.b32 	%r6, 31;
	mov.b32 	%r7, -1;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd8, %fd47;  mov.b64 {lo, hi}, %fd47;  shfl.sync.down.b32 lo|p, lo, %r5, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r5, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd8, %fd8, r0;}
	// end inline asm
	mov.b32 	%r8, 2;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd10, %fd8;  mov.b64 {lo, hi}, %fd8;  shfl.sync.down.b32 lo|p, lo, %r8, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r8, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd10, %fd10, r0;}
	// end inline asm
	mov.b32 	%r11, 4;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd12, %fd10;  mov.b64 {lo, hi}, %fd10;  shfl.sync.down.b32 lo|p, lo, %r11, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r11, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd12, %fd12, r0;}
	// end inline asm
	mov.b32 	%r14, 8;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd14, %fd12;  mov.b64 {lo, hi}, %fd12;  shfl.sync.down.b32 lo|p, lo, %r14, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r14, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd14, %fd14, r0;}
	// end inline asm
	mov.b32 	%r17, 16;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd48, %fd14;  mov.b64 {lo, hi}, %fd14;  shfl.sync.down.b32 lo|p, lo, %r17, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r17, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd48, %fd48, r0;}
	// end inline asm
	setp.ne.s32 	%p2, %r4, 0;
	@%p2 bra 	$L__BB56_4;
// %bb.3:
	shr.s32 	%r20, %r2, 31;
	shr.u32 	%r21, %r20, 27;
	add.s32 	%r22, %r2, %r21;
	shr.s32 	%r23, %r22, 5;
	mul.wide.s32 	%rd14, %r23, 8;
	mov.u64 	%rd15, _ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage;
	add.s64 	%rd16, %rd15, %rd14;
	st.shared.f64 	[%rd16+16], %fd48;
$L__BB56_4:
	bar.sync 	0;
	setp.ne.s32 	%p3, %r2, 0;
	@%p3 bra 	$L__BB56_6;
// %bb.5:
	ld.shared.f64 	%fd18, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+24];
	add.rn.f64 	%fd19, %fd48, %fd18;
	ld.shared.f64 	%fd20, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+32];
	add.rn.f64 	%fd21, %fd19, %fd20;
	ld.shared.f64 	%fd22, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+40];
	add.rn.f64 	%fd23, %fd21, %fd22;
	ld.shared.f64 	%fd24, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+48];
	add.rn.f64 	%fd25, %fd23, %fd24;
	ld.shared.f64 	%fd26, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+56];
	add.rn.f64 	%fd27, %fd25, %fd26;
	ld.shared.f64 	%fd28, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+64];
	add.rn.f64 	%fd29, %fd27, %fd28;
	ld.shared.f64 	%fd30, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+72];
	add.rn.f64 	%fd31, %fd29, %fd30;
	ld.shared.f64 	%fd32, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+80];
	add.rn.f64 	%fd33, %fd31, %fd32;
	ld.shared.f64 	%fd34, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+88];
	add.rn.f64 	%fd35, %fd33, %fd34;
	ld.shared.f64 	%fd36, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+96];
	add.rn.f64 	%fd37, %fd35, %fd36;
	ld.shared.f64 	%fd38, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+104];
	add.rn.f64 	%fd39, %fd37, %fd38;
	ld.shared.f64 	%fd40, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+112];
	add.rn.f64 	%fd41, %fd39, %fd40;
	ld.shared.f64 	%fd42, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+120];
	add.rn.f64 	%fd43, %fd41, %fd42;
	ld.shared.f64 	%fd44, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+128];
	add.rn.f64 	%fd45, %fd43, %fd44;
	ld.shared.f64 	%fd46, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+136];
	add.rn.f64 	%fd48, %fd45, %fd46;
$L__BB56_6:
	@%p3 bra 	$L__BB56_8;
// %bb.7:
	ld.param.u64 	%rd5, [chpl_gpu_kernel_amatter3d_line_264__param_4];
	cvta.to.global.u64 	%rd1, %rd5;
	mul.wide.u32 	%rd17, %r1, 8;
	add.s64 	%rd3, %rd1, %rd17;
	st.global.f64 	[%rd3], %fd48;
$L__BB56_8:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_amatter3d_line_265_ // -- Begin function chpl_gpu_kernel_amatter3d_line_265_
.visible .entry chpl_gpu_kernel_amatter3d_line_265_(
	.param .u64 chpl_gpu_kernel_amatter3d_line_265__param_0,
	.param .u64 chpl_gpu_kernel_amatter3d_line_265__param_1,
	.param .u64 chpl_gpu_kernel_amatter3d_line_265__param_2,
	.param .f64 chpl_gpu_kernel_amatter3d_line_265__param_3,
	.param .u64 chpl_gpu_kernel_amatter3d_line_265__param_4
)                                       // @chpl_gpu_kernel_amatter3d_line_265_
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<24>;
	.reg .b64 	%rd<18>;
	.reg .f64 	%fd<49>;

// %bb.0:
	ld.param.f64 	%fd47, [chpl_gpu_kernel_amatter3d_line_265__param_3];
	ld.param.u64 	%rd4, [chpl_gpu_kernel_amatter3d_line_265__param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_amatter3d_line_265__param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r2, %tid.x;
	mul.wide.s32 	%rd9, %r3, %r1;
	cvt.s64.s32 	%rd10, %r2;
	add.s64 	%rd11, %rd10, %rd4;
	add.s64 	%rd12, %rd11, %rd9;
	setp.gt.s64 	%p1, %rd12, %rd6;
	@%p1 bra 	$L__BB57_2;
// %bb.1:
	ld.param.u64 	%rd7, [chpl_gpu_kernel_amatter3d_line_265__param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	shl.b64 	%rd13, %rd12, 3;
	add.s64 	%rd2, %rd8, %rd13;
	ld.global.f64 	%fd7, [%rd2];
	add.rn.f64 	%fd47, %fd7, %fd47;
$L__BB57_2:
	// begin inline asm
	mov.u32 %r4, %laneid;
	// end inline asm
	mov.b32 	%r5, 1;
	mov.b32 	%r6, 31;
	mov.b32 	%r7, -1;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd8, %fd47;  mov.b64 {lo, hi}, %fd47;  shfl.sync.down.b32 lo|p, lo, %r5, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r5, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd8, %fd8, r0;}
	// end inline asm
	mov.b32 	%r8, 2;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd10, %fd8;  mov.b64 {lo, hi}, %fd8;  shfl.sync.down.b32 lo|p, lo, %r8, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r8, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd10, %fd10, r0;}
	// end inline asm
	mov.b32 	%r11, 4;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd12, %fd10;  mov.b64 {lo, hi}, %fd10;  shfl.sync.down.b32 lo|p, lo, %r11, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r11, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd12, %fd12, r0;}
	// end inline asm
	mov.b32 	%r14, 8;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd14, %fd12;  mov.b64 {lo, hi}, %fd12;  shfl.sync.down.b32 lo|p, lo, %r14, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r14, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd14, %fd14, r0;}
	// end inline asm
	mov.b32 	%r17, 16;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd48, %fd14;  mov.b64 {lo, hi}, %fd14;  shfl.sync.down.b32 lo|p, lo, %r17, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r17, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd48, %fd48, r0;}
	// end inline asm
	setp.ne.s32 	%p2, %r4, 0;
	@%p2 bra 	$L__BB57_4;
// %bb.3:
	shr.s32 	%r20, %r2, 31;
	shr.u32 	%r21, %r20, 27;
	add.s32 	%r22, %r2, %r21;
	shr.s32 	%r23, %r22, 5;
	mul.wide.s32 	%rd14, %r23, 8;
	mov.u64 	%rd15, _ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage;
	add.s64 	%rd16, %rd15, %rd14;
	st.shared.f64 	[%rd16+16], %fd48;
$L__BB57_4:
	bar.sync 	0;
	setp.ne.s32 	%p3, %r2, 0;
	@%p3 bra 	$L__BB57_6;
// %bb.5:
	ld.shared.f64 	%fd18, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+24];
	add.rn.f64 	%fd19, %fd48, %fd18;
	ld.shared.f64 	%fd20, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+32];
	add.rn.f64 	%fd21, %fd19, %fd20;
	ld.shared.f64 	%fd22, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+40];
	add.rn.f64 	%fd23, %fd21, %fd22;
	ld.shared.f64 	%fd24, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+48];
	add.rn.f64 	%fd25, %fd23, %fd24;
	ld.shared.f64 	%fd26, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+56];
	add.rn.f64 	%fd27, %fd25, %fd26;
	ld.shared.f64 	%fd28, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+64];
	add.rn.f64 	%fd29, %fd27, %fd28;
	ld.shared.f64 	%fd30, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+72];
	add.rn.f64 	%fd31, %fd29, %fd30;
	ld.shared.f64 	%fd32, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+80];
	add.rn.f64 	%fd33, %fd31, %fd32;
	ld.shared.f64 	%fd34, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+88];
	add.rn.f64 	%fd35, %fd33, %fd34;
	ld.shared.f64 	%fd36, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+96];
	add.rn.f64 	%fd37, %fd35, %fd36;
	ld.shared.f64 	%fd38, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+104];
	add.rn.f64 	%fd39, %fd37, %fd38;
	ld.shared.f64 	%fd40, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+112];
	add.rn.f64 	%fd41, %fd39, %fd40;
	ld.shared.f64 	%fd42, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+120];
	add.rn.f64 	%fd43, %fd41, %fd42;
	ld.shared.f64 	%fd44, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+128];
	add.rn.f64 	%fd45, %fd43, %fd44;
	ld.shared.f64 	%fd46, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+136];
	add.rn.f64 	%fd48, %fd45, %fd46;
$L__BB57_6:
	@%p3 bra 	$L__BB57_8;
// %bb.7:
	ld.param.u64 	%rd5, [chpl_gpu_kernel_amatter3d_line_265__param_4];
	cvta.to.global.u64 	%rd1, %rd5;
	mul.wide.u32 	%rd17, %r1, 8;
	add.s64 	%rd3, %rd1, %rd17;
	st.global.f64 	[%rd3], %fd48;
$L__BB57_8:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_amatter3d_line_271_ // -- Begin function chpl_gpu_kernel_amatter3d_line_271_
.visible .entry chpl_gpu_kernel_amatter3d_line_271_(
	.param .u64 chpl_gpu_kernel_amatter3d_line_271__param_0,
	.param .u64 chpl_gpu_kernel_amatter3d_line_271__param_1,
	.param .u64 chpl_gpu_kernel_amatter3d_line_271__param_2,
	.param .f64 chpl_gpu_kernel_amatter3d_line_271__param_3,
	.param .u64 chpl_gpu_kernel_amatter3d_line_271__param_4
)                                       // @chpl_gpu_kernel_amatter3d_line_271_
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<24>;
	.reg .b64 	%rd<18>;
	.reg .f64 	%fd<49>;

// %bb.0:
	ld.param.f64 	%fd47, [chpl_gpu_kernel_amatter3d_line_271__param_3];
	ld.param.u64 	%rd4, [chpl_gpu_kernel_amatter3d_line_271__param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_amatter3d_line_271__param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r2, %tid.x;
	mul.wide.s32 	%rd9, %r3, %r1;
	cvt.s64.s32 	%rd10, %r2;
	add.s64 	%rd11, %rd10, %rd4;
	add.s64 	%rd12, %rd11, %rd9;
	setp.gt.s64 	%p1, %rd12, %rd6;
	@%p1 bra 	$L__BB58_2;
// %bb.1:
	ld.param.u64 	%rd7, [chpl_gpu_kernel_amatter3d_line_271__param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	shl.b64 	%rd13, %rd12, 3;
	add.s64 	%rd2, %rd8, %rd13;
	ld.global.f64 	%fd7, [%rd2];
	add.rn.f64 	%fd47, %fd7, %fd47;
$L__BB58_2:
	// begin inline asm
	mov.u32 %r4, %laneid;
	// end inline asm
	mov.b32 	%r5, 1;
	mov.b32 	%r6, 31;
	mov.b32 	%r7, -1;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd8, %fd47;  mov.b64 {lo, hi}, %fd47;  shfl.sync.down.b32 lo|p, lo, %r5, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r5, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd8, %fd8, r0;}
	// end inline asm
	mov.b32 	%r8, 2;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd10, %fd8;  mov.b64 {lo, hi}, %fd8;  shfl.sync.down.b32 lo|p, lo, %r8, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r8, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd10, %fd10, r0;}
	// end inline asm
	mov.b32 	%r11, 4;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd12, %fd10;  mov.b64 {lo, hi}, %fd10;  shfl.sync.down.b32 lo|p, lo, %r11, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r11, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd12, %fd12, r0;}
	// end inline asm
	mov.b32 	%r14, 8;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd14, %fd12;  mov.b64 {lo, hi}, %fd12;  shfl.sync.down.b32 lo|p, lo, %r14, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r14, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd14, %fd14, r0;}
	// end inline asm
	mov.b32 	%r17, 16;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd48, %fd14;  mov.b64 {lo, hi}, %fd14;  shfl.sync.down.b32 lo|p, lo, %r17, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r17, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd48, %fd48, r0;}
	// end inline asm
	setp.ne.s32 	%p2, %r4, 0;
	@%p2 bra 	$L__BB58_4;
// %bb.3:
	shr.s32 	%r20, %r2, 31;
	shr.u32 	%r21, %r20, 27;
	add.s32 	%r22, %r2, %r21;
	shr.s32 	%r23, %r22, 5;
	mul.wide.s32 	%rd14, %r23, 8;
	mov.u64 	%rd15, _ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage;
	add.s64 	%rd16, %rd15, %rd14;
	st.shared.f64 	[%rd16+16], %fd48;
$L__BB58_4:
	bar.sync 	0;
	setp.ne.s32 	%p3, %r2, 0;
	@%p3 bra 	$L__BB58_6;
// %bb.5:
	ld.shared.f64 	%fd18, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+24];
	add.rn.f64 	%fd19, %fd48, %fd18;
	ld.shared.f64 	%fd20, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+32];
	add.rn.f64 	%fd21, %fd19, %fd20;
	ld.shared.f64 	%fd22, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+40];
	add.rn.f64 	%fd23, %fd21, %fd22;
	ld.shared.f64 	%fd24, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+48];
	add.rn.f64 	%fd25, %fd23, %fd24;
	ld.shared.f64 	%fd26, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+56];
	add.rn.f64 	%fd27, %fd25, %fd26;
	ld.shared.f64 	%fd28, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+64];
	add.rn.f64 	%fd29, %fd27, %fd28;
	ld.shared.f64 	%fd30, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+72];
	add.rn.f64 	%fd31, %fd29, %fd30;
	ld.shared.f64 	%fd32, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+80];
	add.rn.f64 	%fd33, %fd31, %fd32;
	ld.shared.f64 	%fd34, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+88];
	add.rn.f64 	%fd35, %fd33, %fd34;
	ld.shared.f64 	%fd36, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+96];
	add.rn.f64 	%fd37, %fd35, %fd36;
	ld.shared.f64 	%fd38, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+104];
	add.rn.f64 	%fd39, %fd37, %fd38;
	ld.shared.f64 	%fd40, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+112];
	add.rn.f64 	%fd41, %fd39, %fd40;
	ld.shared.f64 	%fd42, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+120];
	add.rn.f64 	%fd43, %fd41, %fd42;
	ld.shared.f64 	%fd44, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+128];
	add.rn.f64 	%fd45, %fd43, %fd44;
	ld.shared.f64 	%fd46, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+136];
	add.rn.f64 	%fd48, %fd45, %fd46;
$L__BB58_6:
	@%p3 bra 	$L__BB58_8;
// %bb.7:
	ld.param.u64 	%rd5, [chpl_gpu_kernel_amatter3d_line_271__param_4];
	cvta.to.global.u64 	%rd1, %rd5;
	mul.wide.u32 	%rd17, %r1, 8;
	add.s64 	%rd3, %rd1, %rd17;
	st.global.f64 	[%rd3], %fd48;
$L__BB58_8:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_amatter3d_line_272_ // -- Begin function chpl_gpu_kernel_amatter3d_line_272_
.visible .entry chpl_gpu_kernel_amatter3d_line_272_(
	.param .u64 chpl_gpu_kernel_amatter3d_line_272__param_0,
	.param .u64 chpl_gpu_kernel_amatter3d_line_272__param_1,
	.param .u64 chpl_gpu_kernel_amatter3d_line_272__param_2,
	.param .f64 chpl_gpu_kernel_amatter3d_line_272__param_3,
	.param .u64 chpl_gpu_kernel_amatter3d_line_272__param_4
)                                       // @chpl_gpu_kernel_amatter3d_line_272_
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<24>;
	.reg .b64 	%rd<18>;
	.reg .f64 	%fd<49>;

// %bb.0:
	ld.param.f64 	%fd47, [chpl_gpu_kernel_amatter3d_line_272__param_3];
	ld.param.u64 	%rd4, [chpl_gpu_kernel_amatter3d_line_272__param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_amatter3d_line_272__param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r2, %tid.x;
	mul.wide.s32 	%rd9, %r3, %r1;
	cvt.s64.s32 	%rd10, %r2;
	add.s64 	%rd11, %rd10, %rd4;
	add.s64 	%rd12, %rd11, %rd9;
	setp.gt.s64 	%p1, %rd12, %rd6;
	@%p1 bra 	$L__BB59_2;
// %bb.1:
	ld.param.u64 	%rd7, [chpl_gpu_kernel_amatter3d_line_272__param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	shl.b64 	%rd13, %rd12, 3;
	add.s64 	%rd2, %rd8, %rd13;
	ld.global.f64 	%fd7, [%rd2];
	add.rn.f64 	%fd47, %fd7, %fd47;
$L__BB59_2:
	// begin inline asm
	mov.u32 %r4, %laneid;
	// end inline asm
	mov.b32 	%r5, 1;
	mov.b32 	%r6, 31;
	mov.b32 	%r7, -1;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd8, %fd47;  mov.b64 {lo, hi}, %fd47;  shfl.sync.down.b32 lo|p, lo, %r5, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r5, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd8, %fd8, r0;}
	// end inline asm
	mov.b32 	%r8, 2;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd10, %fd8;  mov.b64 {lo, hi}, %fd8;  shfl.sync.down.b32 lo|p, lo, %r8, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r8, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd10, %fd10, r0;}
	// end inline asm
	mov.b32 	%r11, 4;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd12, %fd10;  mov.b64 {lo, hi}, %fd10;  shfl.sync.down.b32 lo|p, lo, %r11, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r11, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd12, %fd12, r0;}
	// end inline asm
	mov.b32 	%r14, 8;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd14, %fd12;  mov.b64 {lo, hi}, %fd12;  shfl.sync.down.b32 lo|p, lo, %r14, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r14, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd14, %fd14, r0;}
	// end inline asm
	mov.b32 	%r17, 16;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd48, %fd14;  mov.b64 {lo, hi}, %fd14;  shfl.sync.down.b32 lo|p, lo, %r17, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r17, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd48, %fd48, r0;}
	// end inline asm
	setp.ne.s32 	%p2, %r4, 0;
	@%p2 bra 	$L__BB59_4;
// %bb.3:
	shr.s32 	%r20, %r2, 31;
	shr.u32 	%r21, %r20, 27;
	add.s32 	%r22, %r2, %r21;
	shr.s32 	%r23, %r22, 5;
	mul.wide.s32 	%rd14, %r23, 8;
	mov.u64 	%rd15, _ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage;
	add.s64 	%rd16, %rd15, %rd14;
	st.shared.f64 	[%rd16+16], %fd48;
$L__BB59_4:
	bar.sync 	0;
	setp.ne.s32 	%p3, %r2, 0;
	@%p3 bra 	$L__BB59_6;
// %bb.5:
	ld.shared.f64 	%fd18, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+24];
	add.rn.f64 	%fd19, %fd48, %fd18;
	ld.shared.f64 	%fd20, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+32];
	add.rn.f64 	%fd21, %fd19, %fd20;
	ld.shared.f64 	%fd22, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+40];
	add.rn.f64 	%fd23, %fd21, %fd22;
	ld.shared.f64 	%fd24, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+48];
	add.rn.f64 	%fd25, %fd23, %fd24;
	ld.shared.f64 	%fd26, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+56];
	add.rn.f64 	%fd27, %fd25, %fd26;
	ld.shared.f64 	%fd28, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+64];
	add.rn.f64 	%fd29, %fd27, %fd28;
	ld.shared.f64 	%fd30, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+72];
	add.rn.f64 	%fd31, %fd29, %fd30;
	ld.shared.f64 	%fd32, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+80];
	add.rn.f64 	%fd33, %fd31, %fd32;
	ld.shared.f64 	%fd34, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+88];
	add.rn.f64 	%fd35, %fd33, %fd34;
	ld.shared.f64 	%fd36, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+96];
	add.rn.f64 	%fd37, %fd35, %fd36;
	ld.shared.f64 	%fd38, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+104];
	add.rn.f64 	%fd39, %fd37, %fd38;
	ld.shared.f64 	%fd40, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+112];
	add.rn.f64 	%fd41, %fd39, %fd40;
	ld.shared.f64 	%fd42, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+120];
	add.rn.f64 	%fd43, %fd41, %fd42;
	ld.shared.f64 	%fd44, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+128];
	add.rn.f64 	%fd45, %fd43, %fd44;
	ld.shared.f64 	%fd46, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+136];
	add.rn.f64 	%fd48, %fd45, %fd46;
$L__BB59_6:
	@%p3 bra 	$L__BB59_8;
// %bb.7:
	ld.param.u64 	%rd5, [chpl_gpu_kernel_amatter3d_line_272__param_4];
	cvta.to.global.u64 	%rd1, %rd5;
	mul.wide.u32 	%rd17, %r1, 8;
	add.s64 	%rd3, %rd1, %rd17;
	st.global.f64 	[%rd3], %fd48;
$L__BB59_8:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_amatter3d_line_273_ // -- Begin function chpl_gpu_kernel_amatter3d_line_273_
.visible .entry chpl_gpu_kernel_amatter3d_line_273_(
	.param .u64 chpl_gpu_kernel_amatter3d_line_273__param_0,
	.param .u64 chpl_gpu_kernel_amatter3d_line_273__param_1,
	.param .u64 chpl_gpu_kernel_amatter3d_line_273__param_2,
	.param .f64 chpl_gpu_kernel_amatter3d_line_273__param_3,
	.param .u64 chpl_gpu_kernel_amatter3d_line_273__param_4
)                                       // @chpl_gpu_kernel_amatter3d_line_273_
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<24>;
	.reg .b64 	%rd<18>;
	.reg .f64 	%fd<49>;

// %bb.0:
	ld.param.f64 	%fd47, [chpl_gpu_kernel_amatter3d_line_273__param_3];
	ld.param.u64 	%rd4, [chpl_gpu_kernel_amatter3d_line_273__param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_amatter3d_line_273__param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r2, %tid.x;
	mul.wide.s32 	%rd9, %r3, %r1;
	cvt.s64.s32 	%rd10, %r2;
	add.s64 	%rd11, %rd10, %rd4;
	add.s64 	%rd12, %rd11, %rd9;
	setp.gt.s64 	%p1, %rd12, %rd6;
	@%p1 bra 	$L__BB60_2;
// %bb.1:
	ld.param.u64 	%rd7, [chpl_gpu_kernel_amatter3d_line_273__param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	shl.b64 	%rd13, %rd12, 3;
	add.s64 	%rd2, %rd8, %rd13;
	ld.global.f64 	%fd7, [%rd2];
	add.rn.f64 	%fd47, %fd7, %fd47;
$L__BB60_2:
	// begin inline asm
	mov.u32 %r4, %laneid;
	// end inline asm
	mov.b32 	%r5, 1;
	mov.b32 	%r6, 31;
	mov.b32 	%r7, -1;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd8, %fd47;  mov.b64 {lo, hi}, %fd47;  shfl.sync.down.b32 lo|p, lo, %r5, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r5, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd8, %fd8, r0;}
	// end inline asm
	mov.b32 	%r8, 2;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd10, %fd8;  mov.b64 {lo, hi}, %fd8;  shfl.sync.down.b32 lo|p, lo, %r8, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r8, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd10, %fd10, r0;}
	// end inline asm
	mov.b32 	%r11, 4;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd12, %fd10;  mov.b64 {lo, hi}, %fd10;  shfl.sync.down.b32 lo|p, lo, %r11, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r11, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd12, %fd12, r0;}
	// end inline asm
	mov.b32 	%r14, 8;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd14, %fd12;  mov.b64 {lo, hi}, %fd12;  shfl.sync.down.b32 lo|p, lo, %r14, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r14, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd14, %fd14, r0;}
	// end inline asm
	mov.b32 	%r17, 16;
	// begin inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  .reg .f64 r0;  mov.b64 %fd48, %fd14;  mov.b64 {lo, hi}, %fd14;  shfl.sync.down.b32 lo|p, lo, %r17, %r6, %r7;  shfl.sync.down.b32 hi|p, hi, %r17, %r6, %r7;  mov.b64 r0, {lo, hi};  @p add.f64 %fd48, %fd48, r0;}
	// end inline asm
	setp.ne.s32 	%p2, %r4, 0;
	@%p2 bra 	$L__BB60_4;
// %bb.3:
	shr.s32 	%r20, %r2, 31;
	shr.u32 	%r21, %r20, 27;
	add.s32 	%r22, %r2, %r21;
	shr.s32 	%r23, %r22, 5;
	mul.wide.s32 	%rd14, %r23, 8;
	mov.u64 	%rd15, _ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage;
	add.s64 	%rd16, %rd15, %rd14;
	st.shared.f64 	[%rd16+16], %fd48;
$L__BB60_4:
	bar.sync 	0;
	setp.ne.s32 	%p3, %r2, 0;
	@%p3 bra 	$L__BB60_6;
// %bb.5:
	ld.shared.f64 	%fd18, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+24];
	add.rn.f64 	%fd19, %fd48, %fd18;
	ld.shared.f64 	%fd20, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+32];
	add.rn.f64 	%fd21, %fd19, %fd20;
	ld.shared.f64 	%fd22, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+40];
	add.rn.f64 	%fd23, %fd21, %fd22;
	ld.shared.f64 	%fd24, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+48];
	add.rn.f64 	%fd25, %fd23, %fd24;
	ld.shared.f64 	%fd26, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+56];
	add.rn.f64 	%fd27, %fd25, %fd26;
	ld.shared.f64 	%fd28, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+64];
	add.rn.f64 	%fd29, %fd27, %fd28;
	ld.shared.f64 	%fd30, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+72];
	add.rn.f64 	%fd31, %fd29, %fd30;
	ld.shared.f64 	%fd32, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+80];
	add.rn.f64 	%fd33, %fd31, %fd32;
	ld.shared.f64 	%fd34, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+88];
	add.rn.f64 	%fd35, %fd33, %fd34;
	ld.shared.f64 	%fd36, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+96];
	add.rn.f64 	%fd37, %fd35, %fd36;
	ld.shared.f64 	%fd38, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+104];
	add.rn.f64 	%fd39, %fd37, %fd38;
	ld.shared.f64 	%fd40, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+112];
	add.rn.f64 	%fd41, %fd39, %fd40;
	ld.shared.f64 	%fd42, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+120];
	add.rn.f64 	%fd43, %fd41, %fd42;
	ld.shared.f64 	%fd44, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+128];
	add.rn.f64 	%fd45, %fd43, %fd44;
	ld.shared.f64 	%fd46, [_ZZL36chpl_gpu_dev_sum_breduce__real64_512dPdE12temp_storage+136];
	add.rn.f64 	%fd48, %fd45, %fd46;
$L__BB60_6:
	@%p3 bra 	$L__BB60_8;
// %bb.7:
	ld.param.u64 	%rd5, [chpl_gpu_kernel_amatter3d_line_273__param_4];
	cvta.to.global.u64 	%rd1, %rd5;
	mul.wide.u32 	%rd17, %r1, 8;
	add.s64 	%rd3, %rd1, %rd17;
	st.global.f64 	[%rd3], %fd48;
$L__BB60_8:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_Forces_line_12_ // -- Begin function chpl_gpu_kernel_Forces_line_12_
.visible .entry chpl_gpu_kernel_Forces_line_12_(
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_0,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_1,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_2,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_3,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_4,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_5,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_6,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_7,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_8,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_9,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_10,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_11,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_12,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_13,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_14,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_15,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_16,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_17,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_18,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_19,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_20,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_21,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_22,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_23,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_24,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_25,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_26,
	.param .f64 chpl_gpu_kernel_Forces_line_12__param_27,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_28,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_29,
	.param .f64 chpl_gpu_kernel_Forces_line_12__param_30,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_31,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_32,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_33,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_34,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_35,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_36,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_37,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_38,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_39,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_40,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_41,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_42,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_43,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_44,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_45,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_46,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_47,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_48,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_49,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_50,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_51,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_52,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_53,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_54,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_55,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_56,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_57,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_58,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_59,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_60,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_61,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_62,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_63,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_64,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_65,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_66,
	.param .f64 chpl_gpu_kernel_Forces_line_12__param_67,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_68,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_69,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_70,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_71,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_72,
	.param .u64 chpl_gpu_kernel_Forces_line_12__param_73
)                                       // @chpl_gpu_kernel_Forces_line_12_
{
	.reg .pred 	%p<4>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<317>;
	.reg .f64 	%fd<36>;

// %bb.0:
	ld.param.u64 	%rd73, [chpl_gpu_kernel_Forces_line_12__param_0];
	ld.param.u64 	%rd75, [chpl_gpu_kernel_Forces_line_12__param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd143, %r2, %r1;
	cvt.s64.s32 	%rd144, %r3;
	add.s64 	%rd145, %rd144, %rd73;
	add.s64 	%rd69, %rd145, %rd143;
	setp.gt.s64 	%p1, %rd69, %rd75;
	@%p1 bra 	$L__BB61_4;
// %bb.1:
	ld.param.f64 	%fd35, [chpl_gpu_kernel_Forces_line_12__param_67];
	ld.param.f64 	%fd3, [chpl_gpu_kernel_Forces_line_12__param_30];
	ld.param.f64 	%fd2, [chpl_gpu_kernel_Forces_line_12__param_27];
	ld.param.u64 	%rd72, [chpl_gpu_kernel_Forces_line_12__param_3];
	ld.param.u64 	%rd77, [chpl_gpu_kernel_Forces_line_12__param_2];
	ld.param.u64 	%rd80, [chpl_gpu_kernel_Forces_line_12__param_4];
	ld.param.u64 	%rd81, [chpl_gpu_kernel_Forces_line_12__param_69];
	cvta.to.global.u64 	%rd316, %rd81;
	ld.param.u64 	%rd82, [chpl_gpu_kernel_Forces_line_12__param_5];
	ld.param.u64 	%rd83, [chpl_gpu_kernel_Forces_line_12__param_68];
	cvta.to.global.u64 	%rd315, %rd83;
	ld.param.u64 	%rd84, [chpl_gpu_kernel_Forces_line_12__param_6];
	ld.param.u64 	%rd85, [chpl_gpu_kernel_Forces_line_12__param_66];
	cvta.to.global.u64 	%rd7, %rd85;
	ld.param.u64 	%rd86, [chpl_gpu_kernel_Forces_line_12__param_7];
	ld.param.u64 	%rd87, [chpl_gpu_kernel_Forces_line_12__param_65];
	cvta.to.global.u64 	%rd8, %rd87;
	ld.param.u64 	%rd88, [chpl_gpu_kernel_Forces_line_12__param_8];
	ld.param.u64 	%rd89, [chpl_gpu_kernel_Forces_line_12__param_64];
	cvta.to.global.u64 	%rd9, %rd89;
	ld.param.u64 	%rd90, [chpl_gpu_kernel_Forces_line_12__param_9];
	ld.param.u64 	%rd91, [chpl_gpu_kernel_Forces_line_12__param_63];
	cvta.to.global.u64 	%rd10, %rd91;
	ld.param.u64 	%rd92, [chpl_gpu_kernel_Forces_line_12__param_10];
	ld.param.u64 	%rd93, [chpl_gpu_kernel_Forces_line_12__param_62];
	cvta.to.global.u64 	%rd11, %rd93;
	ld.param.u64 	%rd94, [chpl_gpu_kernel_Forces_line_12__param_11];
	ld.param.u64 	%rd95, [chpl_gpu_kernel_Forces_line_12__param_61];
	cvta.to.global.u64 	%rd12, %rd95;
	ld.param.u64 	%rd96, [chpl_gpu_kernel_Forces_line_12__param_12];
	ld.param.u64 	%rd97, [chpl_gpu_kernel_Forces_line_12__param_60];
	cvta.to.global.u64 	%rd13, %rd97;
	ld.param.u64 	%rd98, [chpl_gpu_kernel_Forces_line_12__param_13];
	ld.param.u64 	%rd99, [chpl_gpu_kernel_Forces_line_12__param_59];
	cvta.to.global.u64 	%rd14, %rd99;
	ld.param.u64 	%rd100, [chpl_gpu_kernel_Forces_line_12__param_14];
	ld.param.u64 	%rd101, [chpl_gpu_kernel_Forces_line_12__param_58];
	cvta.to.global.u64 	%rd15, %rd101;
	ld.param.u64 	%rd102, [chpl_gpu_kernel_Forces_line_12__param_15];
	ld.param.u64 	%rd103, [chpl_gpu_kernel_Forces_line_12__param_57];
	cvta.to.global.u64 	%rd16, %rd103;
	ld.param.u64 	%rd104, [chpl_gpu_kernel_Forces_line_12__param_16];
	ld.param.u64 	%rd105, [chpl_gpu_kernel_Forces_line_12__param_56];
	cvta.to.global.u64 	%rd17, %rd105;
	ld.param.u64 	%rd106, [chpl_gpu_kernel_Forces_line_12__param_17];
	ld.param.u64 	%rd107, [chpl_gpu_kernel_Forces_line_12__param_55];
	cvta.to.global.u64 	%rd18, %rd107;
	ld.param.u64 	%rd108, [chpl_gpu_kernel_Forces_line_12__param_18];
	ld.param.u64 	%rd109, [chpl_gpu_kernel_Forces_line_12__param_54];
	cvta.to.global.u64 	%rd19, %rd109;
	ld.param.u64 	%rd110, [chpl_gpu_kernel_Forces_line_12__param_19];
	ld.param.u64 	%rd111, [chpl_gpu_kernel_Forces_line_12__param_53];
	cvta.to.global.u64 	%rd20, %rd111;
	ld.param.u64 	%rd112, [chpl_gpu_kernel_Forces_line_12__param_20];
	ld.param.u64 	%rd113, [chpl_gpu_kernel_Forces_line_12__param_52];
	cvta.to.global.u64 	%rd21, %rd113;
	ld.param.u64 	%rd114, [chpl_gpu_kernel_Forces_line_12__param_21];
	ld.param.u64 	%rd115, [chpl_gpu_kernel_Forces_line_12__param_51];
	cvta.to.global.u64 	%rd22, %rd115;
	ld.param.u64 	%rd116, [chpl_gpu_kernel_Forces_line_12__param_22];
	ld.param.u64 	%rd117, [chpl_gpu_kernel_Forces_line_12__param_50];
	cvta.to.global.u64 	%rd23, %rd117;
	ld.param.u64 	%rd118, [chpl_gpu_kernel_Forces_line_12__param_23];
	ld.param.u64 	%rd119, [chpl_gpu_kernel_Forces_line_12__param_49];
	cvta.to.global.u64 	%rd24, %rd119;
	ld.param.u64 	%rd120, [chpl_gpu_kernel_Forces_line_12__param_24];
	ld.param.u64 	%rd121, [chpl_gpu_kernel_Forces_line_12__param_48];
	cvta.to.global.u64 	%rd25, %rd121;
	ld.param.u64 	%rd122, [chpl_gpu_kernel_Forces_line_12__param_25];
	ld.param.u64 	%rd123, [chpl_gpu_kernel_Forces_line_12__param_47];
	cvta.to.global.u64 	%rd26, %rd123;
	ld.param.u64 	%rd124, [chpl_gpu_kernel_Forces_line_12__param_26];
	ld.param.u64 	%rd125, [chpl_gpu_kernel_Forces_line_12__param_46];
	cvta.to.global.u64 	%rd27, %rd125;
	ld.param.u64 	%rd126, [chpl_gpu_kernel_Forces_line_12__param_45];
	cvta.to.global.u64 	%rd28, %rd126;
	ld.param.u64 	%rd127, [chpl_gpu_kernel_Forces_line_12__param_28];
	ld.param.u64 	%rd128, [chpl_gpu_kernel_Forces_line_12__param_44];
	cvta.to.global.u64 	%rd29, %rd128;
	ld.param.u64 	%rd129, [chpl_gpu_kernel_Forces_line_12__param_29];
	ld.param.u64 	%rd130, [chpl_gpu_kernel_Forces_line_12__param_43];
	cvta.to.global.u64 	%rd30, %rd130;
	ld.param.u64 	%rd131, [chpl_gpu_kernel_Forces_line_12__param_42];
	cvta.to.global.u64 	%rd31, %rd131;
	ld.param.u64 	%rd132, [chpl_gpu_kernel_Forces_line_12__param_31];
	ld.param.u64 	%rd133, [chpl_gpu_kernel_Forces_line_12__param_41];
	cvta.to.global.u64 	%rd32, %rd133;
	ld.param.u64 	%rd134, [chpl_gpu_kernel_Forces_line_12__param_32];
	ld.param.u64 	%rd135, [chpl_gpu_kernel_Forces_line_12__param_40];
	cvta.to.global.u64 	%rd33, %rd135;
	ld.param.u64 	%rd136, [chpl_gpu_kernel_Forces_line_12__param_33];
	ld.param.u64 	%rd137, [chpl_gpu_kernel_Forces_line_12__param_39];
	cvta.to.global.u64 	%rd34, %rd137;
	ld.param.u64 	%rd138, [chpl_gpu_kernel_Forces_line_12__param_34];
	ld.param.u64 	%rd139, [chpl_gpu_kernel_Forces_line_12__param_38];
	cvta.to.global.u64 	%rd35, %rd139;
	ld.param.u64 	%rd140, [chpl_gpu_kernel_Forces_line_12__param_35];
	ld.param.u64 	%rd141, [chpl_gpu_kernel_Forces_line_12__param_37];
	cvta.to.global.u64 	%rd36, %rd141;
	ld.param.u64 	%rd142, [chpl_gpu_kernel_Forces_line_12__param_36];
	cvta.to.global.u64 	%rd37, %rd142;
	cvta.to.global.u64 	%rd38, %rd140;
	cvta.to.global.u64 	%rd39, %rd138;
	cvta.to.global.u64 	%rd40, %rd136;
	cvta.to.global.u64 	%rd41, %rd134;
	cvta.to.global.u64 	%rd42, %rd132;
	cvta.to.global.u64 	%rd43, %rd129;
	cvta.to.global.u64 	%rd44, %rd127;
	cvta.to.global.u64 	%rd45, %rd124;
	cvta.to.global.u64 	%rd46, %rd122;
	cvta.to.global.u64 	%rd47, %rd120;
	cvta.to.global.u64 	%rd48, %rd118;
	cvta.to.global.u64 	%rd49, %rd116;
	cvta.to.global.u64 	%rd50, %rd114;
	cvta.to.global.u64 	%rd51, %rd112;
	cvta.to.global.u64 	%rd52, %rd110;
	cvta.to.global.u64 	%rd53, %rd108;
	cvta.to.global.u64 	%rd54, %rd106;
	cvta.to.global.u64 	%rd55, %rd104;
	cvta.to.global.u64 	%rd56, %rd102;
	cvta.to.global.u64 	%rd57, %rd100;
	cvta.to.global.u64 	%rd58, %rd98;
	cvta.to.global.u64 	%rd59, %rd96;
	cvta.to.global.u64 	%rd60, %rd94;
	cvta.to.global.u64 	%rd61, %rd92;
	cvta.to.global.u64 	%rd62, %rd90;
	cvta.to.global.u64 	%rd63, %rd88;
	cvta.to.global.u64 	%rd64, %rd86;
	cvta.to.global.u64 	%rd65, %rd84;
	cvta.to.global.u64 	%rd66, %rd82;
	cvta.to.global.u64 	%rd67, %rd80;
	cvta.to.global.u64 	%rd68, %rd77;
	ld.global.u64 	%rd146, [%rd68+96];
	mul.lo.s64 	%rd147, %rd146, %rd72;
	mul.lo.s64 	%rd148, %rd147, 144;
	add.s64 	%rd149, %rd67, %rd148;
	ld.global.u64 	%rd150, [%rd66+96];
	mul.lo.s64 	%rd151, %rd150, %rd72;
	mul.lo.s64 	%rd152, %rd151, 144;
	add.s64 	%rd153, %rd65, %rd152;
	mul.lo.s64 	%rd154, %rd69, 144;
	add.s64 	%rd155, %rd153, %rd154;
	ld.global.f64 	%fd5, [%rd155+80];
	ld.global.u64 	%rd156, [%rd64+96];
	mul.lo.s64 	%rd157, %rd156, %rd72;
	mul.lo.s64 	%rd158, %rd157, 144;
	add.s64 	%rd159, %rd63, %rd158;
	add.s64 	%rd160, %rd159, %rd154;
	ld.global.f64 	%fd6, [%rd160+128];
	div.rn.f64 	%fd7, %fd5, %fd6;
	add.s64 	%rd161, %rd149, %rd154;
	st.global.f64 	[%rd161+80], %fd7;
	ld.global.u64 	%rd162, [%rd62+96];
	mul.lo.s64 	%rd163, %rd162, %rd72;
	mul.lo.s64 	%rd164, %rd163, 144;
	add.s64 	%rd165, %rd61, %rd164;
	ld.global.u64 	%rd166, [%rd60+96];
	mul.lo.s64 	%rd167, %rd166, %rd72;
	mul.lo.s64 	%rd168, %rd167, 144;
	add.s64 	%rd169, %rd59, %rd168;
	add.s64 	%rd170, %rd169, %rd154;
	ld.global.f64 	%fd8, [%rd170+88];
	ld.global.u64 	%rd171, [%rd58+96];
	mul.lo.s64 	%rd172, %rd171, %rd72;
	mul.lo.s64 	%rd173, %rd172, 144;
	add.s64 	%rd174, %rd57, %rd173;
	add.s64 	%rd175, %rd174, %rd154;
	ld.global.f64 	%fd9, [%rd175+128];
	div.rn.f64 	%fd10, %fd8, %fd9;
	add.s64 	%rd176, %rd165, %rd154;
	st.global.f64 	[%rd176+88], %fd10;
	ld.global.u64 	%rd177, [%rd56+96];
	mul.lo.s64 	%rd178, %rd177, %rd72;
	mul.lo.s64 	%rd179, %rd178, 144;
	add.s64 	%rd180, %rd55, %rd179;
	ld.global.u64 	%rd181, [%rd54+96];
	mul.lo.s64 	%rd182, %rd181, %rd72;
	mul.lo.s64 	%rd183, %rd182, 144;
	add.s64 	%rd184, %rd53, %rd183;
	add.s64 	%rd185, %rd184, %rd154;
	ld.global.f64 	%fd11, [%rd185+96];
	ld.global.u64 	%rd186, [%rd52+96];
	mul.lo.s64 	%rd187, %rd186, %rd72;
	mul.lo.s64 	%rd188, %rd187, 144;
	add.s64 	%rd189, %rd51, %rd188;
	add.s64 	%rd190, %rd189, %rd154;
	ld.global.f64 	%fd12, [%rd190+128];
	div.rn.f64 	%fd13, %fd11, %fd12;
	add.s64 	%rd191, %rd180, %rd154;
	st.global.f64 	[%rd191+96], %fd13;
	ld.global.u64 	%rd192, [%rd50+96];
	mul.lo.s64 	%rd193, %rd192, %rd72;
	mul.lo.s64 	%rd194, %rd193, 144;
	add.s64 	%rd195, %rd49, %rd194;
	ld.global.u64 	%rd196, [%rd48+96];
	mul.lo.s64 	%rd197, %rd196, %rd72;
	mul.lo.s64 	%rd198, %rd197, 144;
	add.s64 	%rd199, %rd47, %rd198;
	add.s64 	%rd200, %rd199, %rd154;
	ld.global.f64 	%fd14, [%rd200+8];
	ld.global.u64 	%rd201, [%rd46+96];
	mul.lo.s64 	%rd202, %rd201, %rd72;
	mul.lo.s64 	%rd203, %rd202, 144;
	add.s64 	%rd204, %rd45, %rd203;
	add.s64 	%rd205, %rd204, %rd154;
	ld.global.f64 	%fd15, [%rd205+32];
	fma.rn.f64 	%fd16, %fd15, %fd2, %fd14;
	ld.global.u64 	%rd206, [%rd44+96];
	mul.lo.s64 	%rd207, %rd206, %rd72;
	mul.lo.s64 	%rd208, %rd207, 144;
	add.s64 	%rd209, %rd43, %rd208;
	add.s64 	%rd210, %rd209, %rd154;
	ld.global.f64 	%fd17, [%rd210+80];
	add.s64 	%rd211, %rd195, %rd154;
	fma.rn.f64 	%fd18, %fd17, %fd3, %fd16;
	st.global.f64 	[%rd211+8], %fd18;
	ld.global.u64 	%rd212, [%rd42+96];
	mul.lo.s64 	%rd213, %rd212, %rd72;
	mul.lo.s64 	%rd214, %rd213, 144;
	add.s64 	%rd215, %rd41, %rd214;
	ld.global.u64 	%rd216, [%rd40+96];
	mul.lo.s64 	%rd217, %rd216, %rd72;
	mul.lo.s64 	%rd218, %rd217, 144;
	add.s64 	%rd219, %rd39, %rd218;
	add.s64 	%rd220, %rd219, %rd154;
	ld.global.f64 	%fd19, [%rd220+16];
	ld.global.u64 	%rd221, [%rd38+96];
	mul.lo.s64 	%rd222, %rd221, %rd72;
	mul.lo.s64 	%rd223, %rd222, 144;
	add.s64 	%rd224, %rd37, %rd223;
	add.s64 	%rd225, %rd224, %rd154;
	ld.global.f64 	%fd20, [%rd225+40];
	fma.rn.f64 	%fd21, %fd20, %fd2, %fd19;
	ld.global.u64 	%rd226, [%rd36+96];
	mul.lo.s64 	%rd227, %rd226, %rd72;
	mul.lo.s64 	%rd228, %rd227, 144;
	add.s64 	%rd229, %rd35, %rd228;
	add.s64 	%rd230, %rd229, %rd154;
	ld.global.f64 	%fd22, [%rd230+88];
	add.s64 	%rd231, %rd215, %rd154;
	fma.rn.f64 	%fd23, %fd22, %fd3, %fd21;
	st.global.f64 	[%rd231+16], %fd23;
	ld.global.u64 	%rd232, [%rd34+96];
	mul.lo.s64 	%rd233, %rd232, %rd72;
	mul.lo.s64 	%rd234, %rd233, 144;
	add.s64 	%rd235, %rd33, %rd234;
	ld.global.u64 	%rd236, [%rd32+96];
	mul.lo.s64 	%rd237, %rd236, %rd72;
	mul.lo.s64 	%rd238, %rd237, 144;
	add.s64 	%rd239, %rd31, %rd238;
	add.s64 	%rd240, %rd239, %rd154;
	ld.global.f64 	%fd24, [%rd240+24];
	ld.global.u64 	%rd241, [%rd30+96];
	mul.lo.s64 	%rd242, %rd241, %rd72;
	mul.lo.s64 	%rd243, %rd242, 144;
	add.s64 	%rd244, %rd29, %rd243;
	add.s64 	%rd245, %rd244, %rd154;
	ld.global.f64 	%fd25, [%rd245+48];
	fma.rn.f64 	%fd26, %fd25, %fd2, %fd24;
	ld.global.u64 	%rd246, [%rd28+96];
	mul.lo.s64 	%rd247, %rd246, %rd72;
	mul.lo.s64 	%rd248, %rd247, 144;
	add.s64 	%rd249, %rd27, %rd248;
	add.s64 	%rd250, %rd249, %rd154;
	ld.global.f64 	%fd27, [%rd250+96];
	add.s64 	%rd251, %rd235, %rd154;
	fma.rn.f64 	%fd28, %fd27, %fd3, %fd26;
	st.global.f64 	[%rd251+24], %fd28;
	ld.global.u64 	%rd252, [%rd26+96];
	mul.lo.s64 	%rd253, %rd252, %rd72;
	mul.lo.s64 	%rd254, %rd253, 144;
	add.s64 	%rd255, %rd25, %rd254;
	ld.global.u64 	%rd256, [%rd24+96];
	mul.lo.s64 	%rd257, %rd256, %rd72;
	mul.lo.s64 	%rd258, %rd257, 144;
	add.s64 	%rd259, %rd23, %rd258;
	add.s64 	%rd260, %rd259, %rd154;
	ld.global.f64 	%fd29, [%rd260+80];
	add.s64 	%rd261, %rd255, %rd154;
	st.global.f64 	[%rd261+104], %fd29;
	ld.global.u64 	%rd262, [%rd22+96];
	mul.lo.s64 	%rd263, %rd262, %rd72;
	mul.lo.s64 	%rd264, %rd263, 144;
	add.s64 	%rd265, %rd21, %rd264;
	ld.global.u64 	%rd266, [%rd20+96];
	mul.lo.s64 	%rd267, %rd266, %rd72;
	mul.lo.s64 	%rd268, %rd267, 144;
	add.s64 	%rd269, %rd19, %rd268;
	add.s64 	%rd270, %rd269, %rd154;
	ld.global.f64 	%fd30, [%rd270+88];
	add.s64 	%rd271, %rd265, %rd154;
	st.global.f64 	[%rd271+112], %fd30;
	ld.global.u64 	%rd272, [%rd18+96];
	mul.lo.s64 	%rd273, %rd272, %rd72;
	mul.lo.s64 	%rd274, %rd273, 144;
	add.s64 	%rd275, %rd17, %rd274;
	ld.global.u64 	%rd276, [%rd16+96];
	mul.lo.s64 	%rd277, %rd276, %rd72;
	mul.lo.s64 	%rd278, %rd277, 144;
	add.s64 	%rd279, %rd15, %rd278;
	add.s64 	%rd280, %rd279, %rd154;
	ld.global.f64 	%fd31, [%rd280+96];
	add.s64 	%rd281, %rd275, %rd154;
	st.global.f64 	[%rd281+120], %fd31;
	ld.global.u64 	%rd282, [%rd14+96];
	mul.lo.s64 	%rd283, %rd282, %rd72;
	mul.lo.s64 	%rd284, %rd283, 144;
	add.s64 	%rd285, %rd13, %rd284;
	add.s64 	%rd286, %rd285, %rd154;
	mov.u64 	%rd287, 0;
	st.global.u64 	[%rd286+80], %rd287;
	ld.global.u64 	%rd288, [%rd12+96];
	mul.lo.s64 	%rd289, %rd288, %rd72;
	mul.lo.s64 	%rd290, %rd289, 144;
	add.s64 	%rd291, %rd11, %rd290;
	add.s64 	%rd292, %rd291, %rd154;
	st.global.u64 	[%rd292+88], %rd287;
	ld.global.u64 	%rd293, [%rd10+96];
	mul.lo.s64 	%rd294, %rd293, %rd72;
	mul.lo.s64 	%rd295, %rd294, 144;
	add.s64 	%rd296, %rd9, %rd295;
	add.s64 	%rd297, %rd296, %rd154;
	st.global.u64 	[%rd297+96], %rd287;
	ld.global.u64 	%rd298, [%rd8+96];
	mul.lo.s64 	%rd299, %rd298, %rd72;
	mul.lo.s64 	%rd300, %rd299, 144;
	add.s64 	%rd301, %rd7, %rd300;
	add.s64 	%rd302, %rd301, %rd154;
	ld.global.f64 	%fd32, [%rd302+24];
	setp.gt.f64 	%p2, %fd32, %fd35;
	@%p2 bra 	$L__BB61_3;
// %bb.2:
	ld.param.u64 	%rd74, [chpl_gpu_kernel_Forces_line_12__param_73];
	cvta.to.global.u64 	%rd316, %rd74;
	ld.param.u64 	%rd76, [chpl_gpu_kernel_Forces_line_12__param_72];
	cvta.to.global.u64 	%rd315, %rd76;
	ld.param.u64 	%rd78, [chpl_gpu_kernel_Forces_line_12__param_71];
	cvta.to.global.u64 	%rd3, %rd78;
	ld.param.u64 	%rd79, [chpl_gpu_kernel_Forces_line_12__param_70];
	cvta.to.global.u64 	%rd4, %rd79;
	ld.global.u64 	%rd303, [%rd4+96];
	mul.lo.s64 	%rd304, %rd303, %rd72;
	mul.lo.s64 	%rd305, %rd304, 144;
	add.s64 	%rd306, %rd3, %rd305;
	add.s64 	%rd308, %rd306, %rd154;
	ld.global.f64 	%fd34, [%rd308+24];
	setp.geu.f64 	%p3, %fd34, 0d0000000000000000;
	mov.f64 	%fd35, 0d0000000000000000;
	@%p3 bra 	$L__BB61_4;
$L__BB61_3:
	ld.global.u64 	%rd309, [%rd315+96];
	mul.lo.s64 	%rd310, %rd309, %rd72;
	mul.lo.s64 	%rd311, %rd310, 144;
	add.s64 	%rd312, %rd316, %rd311;
	add.s64 	%rd314, %rd312, %rd154;
	st.global.f64 	[%rd314+24], %fd35;
$L__BB61_4:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_Forces_line_49_ // -- Begin function chpl_gpu_kernel_Forces_line_49_
.visible .entry chpl_gpu_kernel_Forces_line_49_(
	.param .u64 chpl_gpu_kernel_Forces_line_49__param_0,
	.param .u64 chpl_gpu_kernel_Forces_line_49__param_1,
	.param .u64 chpl_gpu_kernel_Forces_line_49__param_2,
	.param .f64 chpl_gpu_kernel_Forces_line_49__param_3,
	.param .f64 chpl_gpu_kernel_Forces_line_49__param_4,
	.param .u64 chpl_gpu_kernel_Forces_line_49__param_5
)                                       // @chpl_gpu_kernel_Forces_line_49_
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<23>;
	.reg .f64 	%fd<47>;

// %bb.0:
	ld.param.u64 	%rd22, [chpl_gpu_kernel_Forces_line_49__param_5];
	ld.param.u64 	%rd9, [chpl_gpu_kernel_Forces_line_49__param_0];
	ld.param.u64 	%rd11, [chpl_gpu_kernel_Forces_line_49__param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd12, %r2, %r1;
	cvt.s64.s32 	%rd13, %r3;
	add.s64 	%rd14, %rd13, %rd9;
	add.s64 	%rd2, %rd14, %rd12;
	setp.le.s64 	%p1, %rd2, %rd11;
	setp.gt.s64 	%p2, %rd22, 0;
	and.pred  	%p3, %p1, %p2;
	@!%p3 bra 	$L__BB62_3;
	bra.uni 	$L__BB62_1;
$L__BB62_1:
	ld.param.f64 	%fd20, [chpl_gpu_kernel_Forces_line_49__param_4];
	ld.param.f64 	%fd19, [chpl_gpu_kernel_Forces_line_49__param_3];
	ld.param.u64 	%rd10, [chpl_gpu_kernel_Forces_line_49__param_2];
	cvta.to.global.u64 	%rd1, %rd10;
	ld.global.u64 	%rd15, [%rd1+8];
	ld.u64 	%rd16, [%rd15+96];
	ld.u64 	%rd17, [%rd15+176];
	mul.lo.s64 	%rd18, %rd16, %rd2;
	mul.lo.s64 	%rd19, %rd18, 144;
	add.s64 	%rd20, %rd17, %rd19;
	ld.f64 	%fd46, [%rd20+152];
	ld.f64 	%fd45, [%rd20+160];
	ld.f64 	%fd44, [%rd20+168];
	ld.f64 	%fd43, [%rd20+224];
	ld.f64 	%fd42, [%rd20+232];
	ld.f64 	%fd41, [%rd20+240];
	add.s64 	%rd21, %rd20, 384;
$L__BB62_2:                             // =>This Inner Loop Header: Depth=1
	ld.f64 	%fd13, [%rd21+-88];
	ld.f64 	%fd14, [%rd21+-80];
	ld.f64 	%fd15, [%rd21+-72];
	sub.rn.f64 	%fd21, %fd13, %fd46;
	sub.rn.f64 	%fd22, %fd14, %fd45;
	sub.rn.f64 	%fd23, %fd15, %fd44;
	mul.rn.f64 	%fd24, %fd22, %fd22;
	fma.rn.f64 	%fd25, %fd21, %fd21, %fd24;
	fma.rn.f64 	%fd26, %fd23, %fd23, %fd25;
	sqrt.rn.f64 	%fd27, %fd26;
	sub.rn.f64 	%fd28, %fd27, %fd19;
	neg.f64 	%fd29, %fd28;
	mul.rn.f64 	%fd30, %fd29, %fd20;
	div.rn.f64 	%fd31, %fd30, %fd27;
	ld.f64 	%fd32, [%rd21+-16];
	fma.rn.f64 	%fd16, %fd21, %fd31, %fd32;
	st.f64 	[%rd21+-16], %fd16;
	neg.f64 	%fd33, %fd21;
	fma.rn.f64 	%fd34, %fd33, %fd31, %fd43;
	st.f64 	[%rd21+-160], %fd34;
	ld.f64 	%fd35, [%rd21+-8];
	fma.rn.f64 	%fd17, %fd22, %fd31, %fd35;
	st.f64 	[%rd21+-8], %fd17;
	neg.f64 	%fd36, %fd22;
	fma.rn.f64 	%fd37, %fd36, %fd31, %fd42;
	st.f64 	[%rd21+-152], %fd37;
	ld.f64 	%fd38, [%rd21];
	fma.rn.f64 	%fd18, %fd23, %fd31, %fd38;
	st.f64 	[%rd21], %fd18;
	neg.f64 	%fd39, %fd23;
	fma.rn.f64 	%fd40, %fd39, %fd31, %fd41;
	st.f64 	[%rd21+-144], %fd40;
	add.s64 	%rd22, %rd22, -1;
	add.s64 	%rd21, %rd21, 144;
	setp.ne.s64 	%p4, %rd22, 0;
	mov.f64 	%fd41, %fd18;
	mov.f64 	%fd42, %fd17;
	mov.f64 	%fd43, %fd16;
	mov.f64 	%fd44, %fd15;
	mov.f64 	%fd45, %fd14;
	mov.f64 	%fd46, %fd13;
	@%p4 bra 	$L__BB62_2;
$L__BB62_3:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_Forces_line_71_ // -- Begin function chpl_gpu_kernel_Forces_line_71_
.visible .entry chpl_gpu_kernel_Forces_line_71_(
	.param .u64 chpl_gpu_kernel_Forces_line_71__param_0,
	.param .u64 chpl_gpu_kernel_Forces_line_71__param_1,
	.param .u64 chpl_gpu_kernel_Forces_line_71__param_2,
	.param .f64 chpl_gpu_kernel_Forces_line_71__param_3,
	.param .f64 chpl_gpu_kernel_Forces_line_71__param_4,
	.param .u64 chpl_gpu_kernel_Forces_line_71__param_5
)                                       // @chpl_gpu_kernel_Forces_line_71_
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<23>;
	.reg .f64 	%fd<35>;

// %bb.0:
	ld.param.u64 	%rd22, [chpl_gpu_kernel_Forces_line_71__param_5];
	ld.param.u64 	%rd9, [chpl_gpu_kernel_Forces_line_71__param_0];
	ld.param.u64 	%rd11, [chpl_gpu_kernel_Forces_line_71__param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd12, %r2, %r1;
	cvt.s64.s32 	%rd13, %r3;
	add.s64 	%rd14, %rd13, %rd9;
	add.s64 	%rd2, %rd14, %rd12;
	setp.le.s64 	%p1, %rd2, %rd11;
	setp.gt.s64 	%p2, %rd22, 0;
	and.pred  	%p3, %p1, %p2;
	@!%p3 bra 	$L__BB63_3;
	bra.uni 	$L__BB63_1;
$L__BB63_1:
	ld.param.f64 	%fd2, [chpl_gpu_kernel_Forces_line_71__param_4];
	ld.param.f64 	%fd1, [chpl_gpu_kernel_Forces_line_71__param_3];
	ld.param.u64 	%rd10, [chpl_gpu_kernel_Forces_line_71__param_2];
	cvta.to.global.u64 	%rd1, %rd10;
	ld.global.u64 	%rd15, [%rd1+8];
	ld.u64 	%rd16, [%rd15+96];
	ld.u64 	%rd17, [%rd15+176];
	mul.lo.s64 	%rd18, %rd16, %rd2;
	mul.lo.s64 	%rd19, %rd18, 144;
	add.s64 	%rd20, %rd19, %rd17;
	add.s64 	%rd21, %rd20, 528;
$L__BB63_2:                             // =>This Inner Loop Header: Depth=1
	ld.f64 	%fd3, [%rd21+-88];
	ld.f64 	%fd4, [%rd21+-80];
	ld.f64 	%fd5, [%rd21+-72];
	ld.f64 	%fd6, [%rd21+-376];
	ld.f64 	%fd7, [%rd21+-368];
	ld.f64 	%fd8, [%rd21+-360];
	sub.rn.f64 	%fd9, %fd3, %fd6;
	sub.rn.f64 	%fd10, %fd4, %fd7;
	sub.rn.f64 	%fd11, %fd5, %fd8;
	mul.rn.f64 	%fd12, %fd10, %fd10;
	fma.rn.f64 	%fd13, %fd9, %fd9, %fd12;
	fma.rn.f64 	%fd14, %fd11, %fd11, %fd13;
	sqrt.rn.f64 	%fd15, %fd14;
	sub.rn.f64 	%fd16, %fd15, %fd1;
	neg.f64 	%fd17, %fd16;
	mul.rn.f64 	%fd18, %fd17, %fd2;
	div.rn.f64 	%fd19, %fd18, %fd15;
	ld.f64 	%fd20, [%rd21+-16];
	fma.rn.f64 	%fd21, %fd9, %fd19, %fd20;
	st.f64 	[%rd21+-16], %fd21;
	ld.f64 	%fd22, [%rd21+-304];
	neg.f64 	%fd23, %fd9;
	fma.rn.f64 	%fd24, %fd23, %fd19, %fd22;
	st.f64 	[%rd21+-304], %fd24;
	ld.f64 	%fd25, [%rd21+-8];
	fma.rn.f64 	%fd26, %fd10, %fd19, %fd25;
	st.f64 	[%rd21+-8], %fd26;
	ld.f64 	%fd27, [%rd21+-296];
	neg.f64 	%fd28, %fd10;
	fma.rn.f64 	%fd29, %fd28, %fd19, %fd27;
	st.f64 	[%rd21+-296], %fd29;
	ld.f64 	%fd30, [%rd21];
	fma.rn.f64 	%fd31, %fd11, %fd19, %fd30;
	st.f64 	[%rd21], %fd31;
	ld.f64 	%fd32, [%rd21+-288];
	neg.f64 	%fd33, %fd11;
	fma.rn.f64 	%fd34, %fd33, %fd19, %fd32;
	st.f64 	[%rd21+-288], %fd34;
	add.s64 	%rd22, %rd22, -1;
	add.s64 	%rd21, %rd21, 144;
	setp.ne.s64 	%p4, %rd22, 0;
	@%p4 bra 	$L__BB63_2;
$L__BB63_3:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_Forces_line_97_ // -- Begin function chpl_gpu_kernel_Forces_line_97_
.visible .entry chpl_gpu_kernel_Forces_line_97_(
	.param .u64 chpl_gpu_kernel_Forces_line_97__param_0,
	.param .u64 chpl_gpu_kernel_Forces_line_97__param_1,
	.param .u64 chpl_gpu_kernel_Forces_line_97__param_2,
	.param .f64 chpl_gpu_kernel_Forces_line_97__param_3,
	.param .f64 chpl_gpu_kernel_Forces_line_97__param_4,
	.param .u64 chpl_gpu_kernel_Forces_line_97__param_5
)                                       // @chpl_gpu_kernel_Forces_line_97_
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<23>;
	.reg .f64 	%fd<35>;

// %bb.0:
	ld.param.u64 	%rd22, [chpl_gpu_kernel_Forces_line_97__param_5];
	ld.param.u64 	%rd9, [chpl_gpu_kernel_Forces_line_97__param_0];
	ld.param.u64 	%rd11, [chpl_gpu_kernel_Forces_line_97__param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd12, %r2, %r1;
	cvt.s64.s32 	%rd13, %r3;
	add.s64 	%rd14, %rd13, %rd9;
	add.s64 	%rd2, %rd14, %rd12;
	setp.le.s64 	%p1, %rd2, %rd11;
	setp.gt.s64 	%p2, %rd22, 0;
	and.pred  	%p3, %p1, %p2;
	@!%p3 bra 	$L__BB64_3;
	bra.uni 	$L__BB64_1;
$L__BB64_1:
	ld.param.f64 	%fd2, [chpl_gpu_kernel_Forces_line_97__param_4];
	ld.param.f64 	%fd1, [chpl_gpu_kernel_Forces_line_97__param_3];
	ld.param.u64 	%rd10, [chpl_gpu_kernel_Forces_line_97__param_2];
	cvta.to.global.u64 	%rd1, %rd10;
	ld.global.u64 	%rd15, [%rd1+8];
	ld.u64 	%rd16, [%rd15+96];
	ld.u64 	%rd17, [%rd15+176];
	mul.lo.s64 	%rd18, %rd16, %rd2;
	mul.lo.s64 	%rd19, %rd18, 144;
	add.s64 	%rd20, %rd19, %rd17;
	add.s64 	%rd21, %rd20, 672;
$L__BB64_2:                             // =>This Inner Loop Header: Depth=1
	ld.f64 	%fd3, [%rd21+-88];
	ld.f64 	%fd4, [%rd21+-80];
	ld.f64 	%fd5, [%rd21+-72];
	ld.f64 	%fd6, [%rd21+-520];
	ld.f64 	%fd7, [%rd21+-512];
	ld.f64 	%fd8, [%rd21+-504];
	sub.rn.f64 	%fd9, %fd3, %fd6;
	sub.rn.f64 	%fd10, %fd4, %fd7;
	sub.rn.f64 	%fd11, %fd5, %fd8;
	mul.rn.f64 	%fd12, %fd10, %fd10;
	fma.rn.f64 	%fd13, %fd9, %fd9, %fd12;
	fma.rn.f64 	%fd14, %fd11, %fd11, %fd13;
	sqrt.rn.f64 	%fd15, %fd14;
	sub.rn.f64 	%fd16, %fd15, %fd1;
	neg.f64 	%fd17, %fd16;
	mul.rn.f64 	%fd18, %fd17, %fd2;
	div.rn.f64 	%fd19, %fd18, %fd15;
	ld.f64 	%fd20, [%rd21+-16];
	fma.rn.f64 	%fd21, %fd9, %fd19, %fd20;
	st.f64 	[%rd21+-16], %fd21;
	ld.f64 	%fd22, [%rd21+-448];
	neg.f64 	%fd23, %fd9;
	fma.rn.f64 	%fd24, %fd23, %fd19, %fd22;
	st.f64 	[%rd21+-448], %fd24;
	ld.f64 	%fd25, [%rd21+-8];
	fma.rn.f64 	%fd26, %fd10, %fd19, %fd25;
	st.f64 	[%rd21+-8], %fd26;
	ld.f64 	%fd27, [%rd21+-440];
	neg.f64 	%fd28, %fd10;
	fma.rn.f64 	%fd29, %fd28, %fd19, %fd27;
	st.f64 	[%rd21+-440], %fd29;
	ld.f64 	%fd30, [%rd21];
	fma.rn.f64 	%fd31, %fd11, %fd19, %fd30;
	st.f64 	[%rd21], %fd31;
	ld.f64 	%fd32, [%rd21+-432];
	neg.f64 	%fd33, %fd11;
	fma.rn.f64 	%fd34, %fd33, %fd19, %fd32;
	st.f64 	[%rd21+-432], %fd34;
	add.s64 	%rd22, %rd22, -1;
	add.s64 	%rd21, %rd21, 144;
	setp.ne.s64 	%p4, %rd22, 0;
	@%p4 bra 	$L__BB64_2;
$L__BB64_3:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_Forces_line_690_ // -- Begin function chpl_gpu_kernel_Forces_line_690_
.visible .entry chpl_gpu_kernel_Forces_line_690_(
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_0,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_1,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_2,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_3,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_4,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_5,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_6,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_7,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_8,
	.param .f64 chpl_gpu_kernel_Forces_line_690__param_9,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_10,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_11,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_12,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_13,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_14,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_15,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_16,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_17,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_18,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_19,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_20,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_21,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_22,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_23,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_24,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_25,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_26,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_27,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_28,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_29,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_30,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_31,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_32,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_33,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_34,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_35,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_36,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_37,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_38,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_39,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_40,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_41,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_42,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_43,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_44,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_45,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_46,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_47,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_48,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_49,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_50,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_51,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_52,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_53,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_54,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_55,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_56,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_57,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_58,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_59,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_60,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_61,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_62,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_63,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_64,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_65,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_66,
	.param .f64 chpl_gpu_kernel_Forces_line_690__param_67,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_68,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_69,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_70,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_71,
	.param .f64 chpl_gpu_kernel_Forces_line_690__param_72,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_73,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_74,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_75,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_76,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_77,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_78,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_79,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_80,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_81,
	.param .u64 chpl_gpu_kernel_Forces_line_690__param_82
)                                       // @chpl_gpu_kernel_Forces_line_690_
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<359>;
	.reg .f64 	%fd<58>;

// %bb.0:
	ld.param.u64 	%rd80, [chpl_gpu_kernel_Forces_line_690__param_0];
	ld.param.u64 	%rd82, [chpl_gpu_kernel_Forces_line_690__param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd159, %r2, %r1;
	cvt.s64.s32 	%rd160, %r3;
	add.s64 	%rd161, %rd160, %rd80;
	add.s64 	%rd78, %rd161, %rd159;
	setp.gt.s64 	%p1, %rd78, %rd82;
	@%p1 bra 	$L__BB65_2;
// %bb.1:
	ld.param.f64 	%fd3, [chpl_gpu_kernel_Forces_line_690__param_72];
	ld.param.f64 	%fd2, [chpl_gpu_kernel_Forces_line_690__param_67];
	ld.param.f64 	%fd1, [chpl_gpu_kernel_Forces_line_690__param_9];
	ld.param.u64 	%rd79, [chpl_gpu_kernel_Forces_line_690__param_3];
	ld.param.u64 	%rd81, [chpl_gpu_kernel_Forces_line_690__param_82];
	cvta.to.global.u64 	%rd1, %rd81;
	ld.param.u64 	%rd83, [chpl_gpu_kernel_Forces_line_690__param_81];
	cvta.to.global.u64 	%rd2, %rd83;
	ld.param.u64 	%rd84, [chpl_gpu_kernel_Forces_line_690__param_2];
	ld.param.u64 	%rd85, [chpl_gpu_kernel_Forces_line_690__param_80];
	cvta.to.global.u64 	%rd3, %rd85;
	ld.param.u64 	%rd86, [chpl_gpu_kernel_Forces_line_690__param_79];
	cvta.to.global.u64 	%rd4, %rd86;
	ld.param.u64 	%rd87, [chpl_gpu_kernel_Forces_line_690__param_4];
	ld.param.u64 	%rd88, [chpl_gpu_kernel_Forces_line_690__param_78];
	cvta.to.global.u64 	%rd5, %rd88;
	ld.param.u64 	%rd89, [chpl_gpu_kernel_Forces_line_690__param_5];
	ld.param.u64 	%rd90, [chpl_gpu_kernel_Forces_line_690__param_77];
	cvta.to.global.u64 	%rd6, %rd90;
	ld.param.u64 	%rd91, [chpl_gpu_kernel_Forces_line_690__param_6];
	ld.param.u64 	%rd92, [chpl_gpu_kernel_Forces_line_690__param_76];
	cvta.to.global.u64 	%rd7, %rd92;
	ld.param.u64 	%rd93, [chpl_gpu_kernel_Forces_line_690__param_7];
	ld.param.u64 	%rd94, [chpl_gpu_kernel_Forces_line_690__param_75];
	cvta.to.global.u64 	%rd8, %rd94;
	ld.param.u64 	%rd95, [chpl_gpu_kernel_Forces_line_690__param_8];
	ld.param.u64 	%rd96, [chpl_gpu_kernel_Forces_line_690__param_74];
	cvta.to.global.u64 	%rd9, %rd96;
	ld.param.u64 	%rd97, [chpl_gpu_kernel_Forces_line_690__param_73];
	cvta.to.global.u64 	%rd10, %rd97;
	ld.param.u64 	%rd98, [chpl_gpu_kernel_Forces_line_690__param_10];
	ld.param.u64 	%rd99, [chpl_gpu_kernel_Forces_line_690__param_71];
	cvta.to.global.u64 	%rd11, %rd99;
	ld.param.u64 	%rd100, [chpl_gpu_kernel_Forces_line_690__param_11];
	ld.param.u64 	%rd101, [chpl_gpu_kernel_Forces_line_690__param_70];
	cvta.to.global.u64 	%rd12, %rd101;
	ld.param.u64 	%rd102, [chpl_gpu_kernel_Forces_line_690__param_12];
	ld.param.u64 	%rd103, [chpl_gpu_kernel_Forces_line_690__param_69];
	cvta.to.global.u64 	%rd13, %rd103;
	ld.param.u64 	%rd104, [chpl_gpu_kernel_Forces_line_690__param_13];
	ld.param.u64 	%rd105, [chpl_gpu_kernel_Forces_line_690__param_68];
	cvta.to.global.u64 	%rd14, %rd105;
	ld.param.u64 	%rd106, [chpl_gpu_kernel_Forces_line_690__param_14];
	ld.param.u64 	%rd107, [chpl_gpu_kernel_Forces_line_690__param_66];
	cvta.to.global.u64 	%rd15, %rd107;
	ld.param.u64 	%rd108, [chpl_gpu_kernel_Forces_line_690__param_15];
	ld.param.u64 	%rd109, [chpl_gpu_kernel_Forces_line_690__param_65];
	cvta.to.global.u64 	%rd16, %rd109;
	ld.param.u64 	%rd110, [chpl_gpu_kernel_Forces_line_690__param_16];
	ld.param.u64 	%rd111, [chpl_gpu_kernel_Forces_line_690__param_64];
	cvta.to.global.u64 	%rd17, %rd111;
	ld.param.u64 	%rd112, [chpl_gpu_kernel_Forces_line_690__param_17];
	ld.param.u64 	%rd113, [chpl_gpu_kernel_Forces_line_690__param_63];
	cvta.to.global.u64 	%rd18, %rd113;
	ld.param.u64 	%rd114, [chpl_gpu_kernel_Forces_line_690__param_18];
	ld.param.u64 	%rd115, [chpl_gpu_kernel_Forces_line_690__param_62];
	cvta.to.global.u64 	%rd19, %rd115;
	ld.param.u64 	%rd116, [chpl_gpu_kernel_Forces_line_690__param_19];
	ld.param.u64 	%rd117, [chpl_gpu_kernel_Forces_line_690__param_61];
	cvta.to.global.u64 	%rd20, %rd117;
	ld.param.u64 	%rd118, [chpl_gpu_kernel_Forces_line_690__param_20];
	ld.param.u64 	%rd119, [chpl_gpu_kernel_Forces_line_690__param_60];
	cvta.to.global.u64 	%rd21, %rd119;
	ld.param.u64 	%rd120, [chpl_gpu_kernel_Forces_line_690__param_21];
	ld.param.u64 	%rd121, [chpl_gpu_kernel_Forces_line_690__param_59];
	cvta.to.global.u64 	%rd22, %rd121;
	ld.param.u64 	%rd122, [chpl_gpu_kernel_Forces_line_690__param_22];
	ld.param.u64 	%rd123, [chpl_gpu_kernel_Forces_line_690__param_58];
	cvta.to.global.u64 	%rd23, %rd123;
	ld.param.u64 	%rd124, [chpl_gpu_kernel_Forces_line_690__param_23];
	ld.param.u64 	%rd125, [chpl_gpu_kernel_Forces_line_690__param_57];
	cvta.to.global.u64 	%rd24, %rd125;
	ld.param.u64 	%rd126, [chpl_gpu_kernel_Forces_line_690__param_24];
	ld.param.u64 	%rd127, [chpl_gpu_kernel_Forces_line_690__param_56];
	cvta.to.global.u64 	%rd25, %rd127;
	ld.param.u64 	%rd128, [chpl_gpu_kernel_Forces_line_690__param_25];
	ld.param.u64 	%rd129, [chpl_gpu_kernel_Forces_line_690__param_55];
	cvta.to.global.u64 	%rd26, %rd129;
	ld.param.u64 	%rd130, [chpl_gpu_kernel_Forces_line_690__param_26];
	ld.param.u64 	%rd131, [chpl_gpu_kernel_Forces_line_690__param_54];
	cvta.to.global.u64 	%rd27, %rd131;
	ld.param.u64 	%rd132, [chpl_gpu_kernel_Forces_line_690__param_27];
	ld.param.u64 	%rd133, [chpl_gpu_kernel_Forces_line_690__param_53];
	cvta.to.global.u64 	%rd28, %rd133;
	ld.param.u64 	%rd134, [chpl_gpu_kernel_Forces_line_690__param_28];
	ld.param.u64 	%rd135, [chpl_gpu_kernel_Forces_line_690__param_52];
	cvta.to.global.u64 	%rd29, %rd135;
	ld.param.u64 	%rd136, [chpl_gpu_kernel_Forces_line_690__param_29];
	ld.param.u64 	%rd137, [chpl_gpu_kernel_Forces_line_690__param_51];
	cvta.to.global.u64 	%rd30, %rd137;
	ld.param.u64 	%rd138, [chpl_gpu_kernel_Forces_line_690__param_30];
	ld.param.u64 	%rd139, [chpl_gpu_kernel_Forces_line_690__param_50];
	cvta.to.global.u64 	%rd31, %rd139;
	ld.param.u64 	%rd140, [chpl_gpu_kernel_Forces_line_690__param_31];
	ld.param.u64 	%rd141, [chpl_gpu_kernel_Forces_line_690__param_49];
	cvta.to.global.u64 	%rd32, %rd141;
	ld.param.u64 	%rd142, [chpl_gpu_kernel_Forces_line_690__param_32];
	ld.param.u64 	%rd143, [chpl_gpu_kernel_Forces_line_690__param_48];
	cvta.to.global.u64 	%rd33, %rd143;
	ld.param.u64 	%rd144, [chpl_gpu_kernel_Forces_line_690__param_33];
	ld.param.u64 	%rd145, [chpl_gpu_kernel_Forces_line_690__param_47];
	cvta.to.global.u64 	%rd34, %rd145;
	ld.param.u64 	%rd146, [chpl_gpu_kernel_Forces_line_690__param_34];
	ld.param.u64 	%rd147, [chpl_gpu_kernel_Forces_line_690__param_46];
	cvta.to.global.u64 	%rd35, %rd147;
	ld.param.u64 	%rd148, [chpl_gpu_kernel_Forces_line_690__param_35];
	ld.param.u64 	%rd149, [chpl_gpu_kernel_Forces_line_690__param_45];
	cvta.to.global.u64 	%rd36, %rd149;
	ld.param.u64 	%rd150, [chpl_gpu_kernel_Forces_line_690__param_36];
	ld.param.u64 	%rd151, [chpl_gpu_kernel_Forces_line_690__param_44];
	cvta.to.global.u64 	%rd37, %rd151;
	ld.param.u64 	%rd152, [chpl_gpu_kernel_Forces_line_690__param_37];
	ld.param.u64 	%rd153, [chpl_gpu_kernel_Forces_line_690__param_43];
	cvta.to.global.u64 	%rd38, %rd153;
	ld.param.u64 	%rd154, [chpl_gpu_kernel_Forces_line_690__param_38];
	ld.param.u64 	%rd155, [chpl_gpu_kernel_Forces_line_690__param_42];
	cvta.to.global.u64 	%rd39, %rd155;
	ld.param.u64 	%rd156, [chpl_gpu_kernel_Forces_line_690__param_39];
	ld.param.u64 	%rd157, [chpl_gpu_kernel_Forces_line_690__param_41];
	cvta.to.global.u64 	%rd40, %rd157;
	ld.param.u64 	%rd158, [chpl_gpu_kernel_Forces_line_690__param_40];
	cvta.to.global.u64 	%rd41, %rd158;
	cvta.to.global.u64 	%rd42, %rd156;
	cvta.to.global.u64 	%rd43, %rd154;
	cvta.to.global.u64 	%rd44, %rd152;
	cvta.to.global.u64 	%rd45, %rd150;
	cvta.to.global.u64 	%rd46, %rd148;
	cvta.to.global.u64 	%rd47, %rd146;
	cvta.to.global.u64 	%rd48, %rd144;
	cvta.to.global.u64 	%rd49, %rd142;
	cvta.to.global.u64 	%rd50, %rd140;
	cvta.to.global.u64 	%rd51, %rd138;
	cvta.to.global.u64 	%rd52, %rd136;
	cvta.to.global.u64 	%rd53, %rd134;
	cvta.to.global.u64 	%rd54, %rd132;
	cvta.to.global.u64 	%rd55, %rd130;
	cvta.to.global.u64 	%rd56, %rd128;
	cvta.to.global.u64 	%rd57, %rd126;
	cvta.to.global.u64 	%rd58, %rd124;
	cvta.to.global.u64 	%rd59, %rd122;
	cvta.to.global.u64 	%rd60, %rd120;
	cvta.to.global.u64 	%rd61, %rd118;
	cvta.to.global.u64 	%rd62, %rd116;
	cvta.to.global.u64 	%rd63, %rd114;
	cvta.to.global.u64 	%rd64, %rd112;
	cvta.to.global.u64 	%rd65, %rd110;
	cvta.to.global.u64 	%rd66, %rd108;
	cvta.to.global.u64 	%rd67, %rd106;
	cvta.to.global.u64 	%rd68, %rd104;
	cvta.to.global.u64 	%rd69, %rd102;
	cvta.to.global.u64 	%rd70, %rd100;
	cvta.to.global.u64 	%rd71, %rd98;
	cvta.to.global.u64 	%rd72, %rd95;
	cvta.to.global.u64 	%rd73, %rd93;
	cvta.to.global.u64 	%rd74, %rd91;
	cvta.to.global.u64 	%rd75, %rd89;
	cvta.to.global.u64 	%rd76, %rd87;
	cvta.to.global.u64 	%rd77, %rd84;
	ld.global.u64 	%rd162, [%rd77+96];
	mul.lo.s64 	%rd163, %rd162, %rd79;
	mul.lo.s64 	%rd164, %rd163, 144;
	add.s64 	%rd165, %rd76, %rd164;
	mul.lo.s64 	%rd166, %rd78, 144;
	add.s64 	%rd167, %rd165, %rd166;
	ld.global.u64 	%rd168, [%rd75+96];
	mul.lo.s64 	%rd169, %rd168, %rd79;
	mul.lo.s64 	%rd170, %rd169, 144;
	add.s64 	%rd171, %rd74, %rd170;
	add.s64 	%rd172, %rd171, %rd166;
	ld.global.f64 	%fd4, [%rd172+80];
	ld.global.u64 	%rd173, [%rd73+96];
	mul.lo.s64 	%rd174, %rd173, %rd79;
	mul.lo.s64 	%rd175, %rd174, 144;
	add.s64 	%rd176, %rd72, %rd175;
	add.s64 	%rd177, %rd176, %rd166;
	ld.global.f64 	%fd5, [%rd177+104];
	add.rn.f64 	%fd6, %fd4, %fd5;
	ld.global.f64 	%fd7, [%rd167+32];
	fma.rn.f64 	%fd8, %fd6, %fd1, %fd7;
	st.global.f64 	[%rd167+32], %fd8;
	ld.global.u64 	%rd178, [%rd71+96];
	mul.lo.s64 	%rd179, %rd178, %rd79;
	mul.lo.s64 	%rd180, %rd179, 144;
	add.s64 	%rd181, %rd70, %rd180;
	add.s64 	%rd182, %rd181, %rd166;
	ld.global.u64 	%rd183, [%rd69+96];
	mul.lo.s64 	%rd184, %rd183, %rd79;
	mul.lo.s64 	%rd185, %rd184, 144;
	add.s64 	%rd186, %rd68, %rd185;
	add.s64 	%rd187, %rd186, %rd166;
	ld.global.f64 	%fd9, [%rd187+88];
	ld.global.u64 	%rd188, [%rd67+96];
	mul.lo.s64 	%rd189, %rd188, %rd79;
	mul.lo.s64 	%rd190, %rd189, 144;
	add.s64 	%rd191, %rd66, %rd190;
	add.s64 	%rd192, %rd191, %rd166;
	ld.global.f64 	%fd10, [%rd192+112];
	add.rn.f64 	%fd11, %fd9, %fd10;
	ld.global.f64 	%fd12, [%rd182+40];
	fma.rn.f64 	%fd13, %fd11, %fd1, %fd12;
	st.global.f64 	[%rd182+40], %fd13;
	ld.global.u64 	%rd193, [%rd65+96];
	mul.lo.s64 	%rd194, %rd193, %rd79;
	mul.lo.s64 	%rd195, %rd194, 144;
	add.s64 	%rd196, %rd64, %rd195;
	ld.global.u64 	%rd197, [%rd63+96];
	mul.lo.s64 	%rd198, %rd197, %rd79;
	mul.lo.s64 	%rd199, %rd198, 144;
	add.s64 	%rd200, %rd62, %rd199;
	add.s64 	%rd201, %rd200, %rd166;
	ld.global.f64 	%fd14, [%rd201+56];
	ld.global.u64 	%rd202, [%rd61+96];
	mul.lo.s64 	%rd203, %rd202, %rd79;
	shl.b64 	%rd204, %rd203, 3;
	add.s64 	%rd205, %rd60, %rd204;
	shl.b64 	%rd206, %rd78, 3;
	add.s64 	%rd207, %rd205, %rd206;
	ld.global.u64 	%rd208, [%rd207];
	cvt.rn.f64.s64 	%fd15, %rd208;
	div.rn.f64 	%fd16, %fd14, %fd15;
	add.s64 	%rd209, %rd196, %rd166;
	st.global.f64 	[%rd209+56], %fd16;
	ld.global.u64 	%rd210, [%rd59+96];
	mul.lo.s64 	%rd211, %rd210, %rd79;
	mul.lo.s64 	%rd212, %rd211, 144;
	add.s64 	%rd213, %rd58, %rd212;
	ld.global.u64 	%rd214, [%rd57+96];
	mul.lo.s64 	%rd215, %rd214, %rd79;
	mul.lo.s64 	%rd216, %rd215, 144;
	add.s64 	%rd217, %rd56, %rd216;
	add.s64 	%rd218, %rd217, %rd166;
	ld.global.f64 	%fd17, [%rd218+64];
	ld.global.u64 	%rd219, [%rd55+96];
	mul.lo.s64 	%rd220, %rd219, %rd79;
	shl.b64 	%rd221, %rd220, 3;
	add.s64 	%rd222, %rd54, %rd221;
	add.s64 	%rd223, %rd222, %rd206;
	ld.global.u64 	%rd224, [%rd223];
	cvt.rn.f64.s64 	%fd18, %rd224;
	div.rn.f64 	%fd19, %fd17, %fd18;
	add.s64 	%rd225, %rd213, %rd166;
	st.global.f64 	[%rd225+64], %fd19;
	ld.global.u64 	%rd226, [%rd53+96];
	mul.lo.s64 	%rd227, %rd226, %rd79;
	mul.lo.s64 	%rd228, %rd227, 144;
	add.s64 	%rd229, %rd52, %rd228;
	ld.global.u64 	%rd230, [%rd51+96];
	mul.lo.s64 	%rd231, %rd230, %rd79;
	mul.lo.s64 	%rd232, %rd231, 144;
	add.s64 	%rd233, %rd50, %rd232;
	add.s64 	%rd234, %rd233, %rd166;
	ld.global.f64 	%fd20, [%rd234+72];
	ld.global.u64 	%rd235, [%rd49+96];
	mul.lo.s64 	%rd236, %rd235, %rd79;
	shl.b64 	%rd237, %rd236, 3;
	add.s64 	%rd238, %rd48, %rd237;
	add.s64 	%rd239, %rd238, %rd206;
	ld.global.u64 	%rd240, [%rd239];
	cvt.rn.f64.s64 	%fd21, %rd240;
	div.rn.f64 	%fd22, %fd20, %fd21;
	add.s64 	%rd241, %rd229, %rd166;
	st.global.f64 	[%rd241+72], %fd22;
	mul.lo.s64 	%rd242, %rd78, %rd79;
	shl.b64 	%rd243, %rd242, 3;
	add.s64 	%rd244, %rd47, %rd243;
	ld.global.u64 	%rd245, [%rd46+96];
	mul.lo.s64 	%rd246, %rd245, %rd79;
	mul.lo.s64 	%rd247, %rd246, 144;
	add.s64 	%rd248, %rd45, %rd247;
	add.s64 	%rd249, %rd248, %rd166;
	ld.global.f64 	%fd23, [%rd249+128];
	mul.rn.f64 	%fd24, %fd23, 0d3FE0000000000000;
	ld.global.u64 	%rd250, [%rd44+96];
	mul.lo.s64 	%rd251, %rd250, %rd79;
	mul.lo.s64 	%rd252, %rd251, 144;
	add.s64 	%rd253, %rd43, %rd252;
	add.s64 	%rd254, %rd253, %rd166;
	ld.global.f64 	%fd25, [%rd254+32];
	ld.global.u64 	%rd255, [%rd42+96];
	mul.lo.s64 	%rd256, %rd255, %rd79;
	mul.lo.s64 	%rd257, %rd256, 144;
	add.s64 	%rd258, %rd41, %rd257;
	add.s64 	%rd259, %rd258, %rd166;
	ld.global.f64 	%fd26, [%rd259+32];
	ld.global.u64 	%rd260, [%rd40+96];
	mul.lo.s64 	%rd261, %rd260, %rd79;
	mul.lo.s64 	%rd262, %rd261, 144;
	add.s64 	%rd263, %rd39, %rd262;
	add.s64 	%rd264, %rd263, %rd166;
	ld.global.f64 	%fd27, [%rd264+40];
	ld.global.u64 	%rd265, [%rd38+96];
	mul.lo.s64 	%rd266, %rd265, %rd79;
	mul.lo.s64 	%rd267, %rd266, 144;
	add.s64 	%rd268, %rd37, %rd267;
	add.s64 	%rd269, %rd268, %rd166;
	ld.global.f64 	%fd28, [%rd269+40];
	mul.rn.f64 	%fd29, %fd27, %fd28;
	fma.rn.f64 	%fd30, %fd25, %fd26, %fd29;
	mul.rn.f64 	%fd31, %fd24, %fd30;
	st.global.f64 	[%rd244], %fd31;
	add.s64 	%rd270, %rd36, %rd243;
	ld.global.u64 	%rd271, [%rd35+96];
	mul.lo.s64 	%rd272, %rd271, %rd79;
	mul.lo.s64 	%rd273, %rd272, 144;
	add.s64 	%rd274, %rd34, %rd273;
	add.s64 	%rd275, %rd274, %rd166;
	ld.global.f64 	%fd32, [%rd275+128];
	mul.rn.f64 	%fd33, %fd32, 0d3FE0000000000000;
	ld.global.u64 	%rd276, [%rd33+96];
	mul.lo.s64 	%rd277, %rd276, %rd79;
	mul.lo.s64 	%rd278, %rd277, 144;
	add.s64 	%rd279, %rd32, %rd278;
	add.s64 	%rd280, %rd279, %rd166;
	ld.global.f64 	%fd34, [%rd280+32];
	ld.global.u64 	%rd281, [%rd31+96];
	mul.lo.s64 	%rd282, %rd281, %rd79;
	mul.lo.s64 	%rd283, %rd282, 144;
	add.s64 	%rd284, %rd30, %rd283;
	add.s64 	%rd285, %rd284, %rd166;
	ld.global.f64 	%fd35, [%rd285+56];
	sub.rn.f64 	%fd36, %fd34, %fd35;
	ld.global.u64 	%rd286, [%rd29+96];
	mul.lo.s64 	%rd287, %rd286, %rd79;
	mul.lo.s64 	%rd288, %rd287, 144;
	add.s64 	%rd289, %rd28, %rd288;
	add.s64 	%rd290, %rd289, %rd166;
	ld.global.f64 	%fd37, [%rd290+32];
	ld.global.u64 	%rd291, [%rd27+96];
	mul.lo.s64 	%rd292, %rd291, %rd79;
	mul.lo.s64 	%rd293, %rd292, 144;
	add.s64 	%rd294, %rd26, %rd293;
	add.s64 	%rd295, %rd294, %rd166;
	ld.global.f64 	%fd38, [%rd295+56];
	sub.rn.f64 	%fd39, %fd37, %fd38;
	ld.global.u64 	%rd296, [%rd25+96];
	mul.lo.s64 	%rd297, %rd296, %rd79;
	mul.lo.s64 	%rd298, %rd297, 144;
	add.s64 	%rd299, %rd24, %rd298;
	add.s64 	%rd300, %rd299, %rd166;
	ld.global.f64 	%fd40, [%rd300+40];
	ld.global.u64 	%rd301, [%rd23+96];
	mul.lo.s64 	%rd302, %rd301, %rd79;
	mul.lo.s64 	%rd303, %rd302, 144;
	add.s64 	%rd304, %rd22, %rd303;
	add.s64 	%rd305, %rd304, %rd166;
	ld.global.f64 	%fd41, [%rd305+64];
	sub.rn.f64 	%fd42, %fd40, %fd41;
	ld.global.u64 	%rd306, [%rd21+96];
	mul.lo.s64 	%rd307, %rd306, %rd79;
	mul.lo.s64 	%rd308, %rd307, 144;
	add.s64 	%rd309, %rd20, %rd308;
	add.s64 	%rd310, %rd309, %rd166;
	ld.global.f64 	%fd43, [%rd310+40];
	ld.global.u64 	%rd311, [%rd19+96];
	mul.lo.s64 	%rd312, %rd311, %rd79;
	mul.lo.s64 	%rd313, %rd312, 144;
	add.s64 	%rd314, %rd18, %rd313;
	add.s64 	%rd315, %rd314, %rd166;
	ld.global.f64 	%fd44, [%rd315+64];
	sub.rn.f64 	%fd45, %fd43, %fd44;
	mul.rn.f64 	%fd46, %fd42, %fd45;
	fma.rn.f64 	%fd47, %fd36, %fd39, %fd46;
	mul.rn.f64 	%fd48, %fd33, %fd47;
	st.global.f64 	[%rd270], %fd48;
	add.s64 	%rd316, %rd17, %rd243;
	ld.global.u64 	%rd317, [%rd16+96];
	mul.lo.s64 	%rd318, %rd317, %rd79;
	mul.lo.s64 	%rd319, %rd318, 144;
	add.s64 	%rd320, %rd15, %rd319;
	add.s64 	%rd321, %rd320, %rd166;
	ld.global.f64 	%fd49, [%rd321+8];
	sub.rn.f64 	%fd50, %fd49, %fd2;
	ld.global.u64 	%rd322, [%rd14+96];
	mul.lo.s64 	%rd323, %rd322, %rd79;
	mul.lo.s64 	%rd324, %rd323, 144;
	add.s64 	%rd325, %rd13, %rd324;
	add.s64 	%rd326, %rd325, %rd166;
	ld.global.f64 	%fd51, [%rd326+40];
	ld.global.u64 	%rd327, [%rd12+96];
	mul.lo.s64 	%rd328, %rd327, %rd79;
	mul.lo.s64 	%rd329, %rd328, 144;
	add.s64 	%rd330, %rd11, %rd329;
	add.s64 	%rd331, %rd330, %rd166;
	ld.global.f64 	%fd52, [%rd331+16];
	sub.rn.f64 	%fd53, %fd52, %fd3;
	ld.global.u64 	%rd332, [%rd10+96];
	mul.lo.s64 	%rd333, %rd332, %rd79;
	mul.lo.s64 	%rd334, %rd333, 144;
	add.s64 	%rd335, %rd9, %rd334;
	add.s64 	%rd336, %rd335, %rd166;
	ld.global.f64 	%fd54, [%rd336+32];
	mul.rn.f64 	%fd55, %fd53, %fd54;
	neg.f64 	%fd56, %fd55;
	fma.rn.f64 	%fd57, %fd50, %fd51, %fd56;
	st.global.f64 	[%rd316], %fd57;
	ld.global.u64 	%rd337, [%rd8+96];
	mul.lo.s64 	%rd338, %rd337, %rd79;
	shl.b64 	%rd339, %rd338, 3;
	add.s64 	%rd340, %rd7, %rd339;
	add.s64 	%rd341, %rd340, %rd206;
	mov.u64 	%rd342, 1;
	st.global.u64 	[%rd341], %rd342;
	ld.global.u64 	%rd343, [%rd6+96];
	mul.lo.s64 	%rd344, %rd343, %rd79;
	mul.lo.s64 	%rd345, %rd344, 144;
	add.s64 	%rd346, %rd5, %rd345;
	add.s64 	%rd347, %rd346, %rd166;
	mov.u64 	%rd348, 0;
	st.global.u64 	[%rd347+56], %rd348;
	ld.global.u64 	%rd349, [%rd4+96];
	mul.lo.s64 	%rd350, %rd349, %rd79;
	mul.lo.s64 	%rd351, %rd350, 144;
	add.s64 	%rd352, %rd3, %rd351;
	add.s64 	%rd353, %rd352, %rd166;
	st.global.u64 	[%rd353+64], %rd348;
	ld.global.u64 	%rd354, [%rd2+96];
	mul.lo.s64 	%rd355, %rd354, %rd79;
	mul.lo.s64 	%rd356, %rd355, 144;
	add.s64 	%rd357, %rd1, %rd356;
	add.s64 	%rd358, %rd357, %rd166;
	st.global.u64 	[%rd358+72], %rd348;
$L__BB65_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_Forces_line_778_ // -- Begin function chpl_gpu_kernel_Forces_line_778_
.visible .entry chpl_gpu_kernel_Forces_line_778_(
	.param .u64 chpl_gpu_kernel_Forces_line_778__param_0,
	.param .u64 chpl_gpu_kernel_Forces_line_778__param_1,
	.param .u64 chpl_gpu_kernel_Forces_line_778__param_2,
	.param .u64 chpl_gpu_kernel_Forces_line_778__param_3,
	.param .f64 chpl_gpu_kernel_Forces_line_778__param_4,
	.param .u64 chpl_gpu_kernel_Forces_line_778__param_5,
	.param .f64 chpl_gpu_kernel_Forces_line_778__param_6,
	.param .u64 chpl_gpu_kernel_Forces_line_778__param_7,
	.param .u64 chpl_gpu_kernel_Forces_line_778__param_8,
	.param .u64 chpl_gpu_kernel_Forces_line_778__param_9,
	.param .f64 chpl_gpu_kernel_Forces_line_778__param_10,
	.param .u64 chpl_gpu_kernel_Forces_line_778__param_11,
	.param .u64 chpl_gpu_kernel_Forces_line_778__param_12,
	.param .u64 chpl_gpu_kernel_Forces_line_778__param_13,
	.param .u64 chpl_gpu_kernel_Forces_line_778__param_14,
	.param .u64 chpl_gpu_kernel_Forces_line_778__param_15,
	.param .u64 chpl_gpu_kernel_Forces_line_778__param_16,
	.param .u64 chpl_gpu_kernel_Forces_line_778__param_17,
	.param .u64 chpl_gpu_kernel_Forces_line_778__param_18,
	.param .f64 chpl_gpu_kernel_Forces_line_778__param_19,
	.param .u64 chpl_gpu_kernel_Forces_line_778__param_20,
	.param .u64 chpl_gpu_kernel_Forces_line_778__param_21,
	.param .f64 chpl_gpu_kernel_Forces_line_778__param_22,
	.param .u64 chpl_gpu_kernel_Forces_line_778__param_23,
	.param .u64 chpl_gpu_kernel_Forces_line_778__param_24,
	.param .u64 chpl_gpu_kernel_Forces_line_778__param_25,
	.param .u64 chpl_gpu_kernel_Forces_line_778__param_26
)                                       // @chpl_gpu_kernel_Forces_line_778_
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<69>;
	.reg .f64 	%fd<32>;

// %bb.0:
	ld.param.u64 	%rd22, [chpl_gpu_kernel_Forces_line_778__param_0];
	ld.param.u64 	%rd24, [chpl_gpu_kernel_Forces_line_778__param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd44, %r2, %r1;
	cvt.s64.s32 	%rd45, %r3;
	add.s64 	%rd46, %rd45, %rd22;
	add.s64 	%rd21, %rd46, %rd44;
	setp.gt.s64 	%p1, %rd21, %rd24;
	@%p1 bra 	$L__BB66_2;
// %bb.1:
	ld.param.f64 	%fd5, [chpl_gpu_kernel_Forces_line_778__param_22];
	ld.param.f64 	%fd4, [chpl_gpu_kernel_Forces_line_778__param_19];
	ld.param.f64 	%fd3, [chpl_gpu_kernel_Forces_line_778__param_10];
	ld.param.f64 	%fd2, [chpl_gpu_kernel_Forces_line_778__param_6];
	ld.param.f64 	%fd1, [chpl_gpu_kernel_Forces_line_778__param_4];
	ld.param.u64 	%rd23, [chpl_gpu_kernel_Forces_line_778__param_26];
	cvta.to.global.u64 	%rd1, %rd23;
	ld.param.u64 	%rd25, [chpl_gpu_kernel_Forces_line_778__param_25];
	cvta.to.global.u64 	%rd2, %rd25;
	ld.param.u64 	%rd26, [chpl_gpu_kernel_Forces_line_778__param_2];
	ld.param.u64 	%rd27, [chpl_gpu_kernel_Forces_line_778__param_24];
	cvta.to.global.u64 	%rd3, %rd27;
	ld.param.u64 	%rd28, [chpl_gpu_kernel_Forces_line_778__param_3];
	ld.param.u64 	%rd29, [chpl_gpu_kernel_Forces_line_778__param_23];
	cvta.to.global.u64 	%rd4, %rd29;
	ld.param.u64 	%rd30, [chpl_gpu_kernel_Forces_line_778__param_21];
	cvta.to.global.u64 	%rd5, %rd30;
	ld.param.u64 	%rd31, [chpl_gpu_kernel_Forces_line_778__param_5];
	ld.param.u64 	%rd32, [chpl_gpu_kernel_Forces_line_778__param_20];
	cvta.to.global.u64 	%rd6, %rd32;
	ld.param.u64 	%rd33, [chpl_gpu_kernel_Forces_line_778__param_18];
	cvta.to.global.u64 	%rd7, %rd33;
	ld.param.u64 	%rd34, [chpl_gpu_kernel_Forces_line_778__param_7];
	ld.param.u64 	%rd35, [chpl_gpu_kernel_Forces_line_778__param_17];
	cvta.to.global.u64 	%rd8, %rd35;
	ld.param.u64 	%rd36, [chpl_gpu_kernel_Forces_line_778__param_8];
	ld.param.u64 	%rd37, [chpl_gpu_kernel_Forces_line_778__param_16];
	cvta.to.global.u64 	%rd9, %rd37;
	ld.param.u64 	%rd38, [chpl_gpu_kernel_Forces_line_778__param_9];
	ld.param.u64 	%rd39, [chpl_gpu_kernel_Forces_line_778__param_15];
	cvta.to.global.u64 	%rd10, %rd39;
	ld.param.u64 	%rd40, [chpl_gpu_kernel_Forces_line_778__param_14];
	cvta.to.global.u64 	%rd11, %rd40;
	ld.param.u64 	%rd41, [chpl_gpu_kernel_Forces_line_778__param_11];
	ld.param.u64 	%rd42, [chpl_gpu_kernel_Forces_line_778__param_13];
	cvta.to.global.u64 	%rd12, %rd42;
	ld.param.u64 	%rd43, [chpl_gpu_kernel_Forces_line_778__param_12];
	cvta.to.global.u64 	%rd13, %rd43;
	cvta.to.global.u64 	%rd14, %rd41;
	cvta.to.global.u64 	%rd15, %rd38;
	cvta.to.global.u64 	%rd16, %rd36;
	cvta.to.global.u64 	%rd17, %rd34;
	cvta.to.global.u64 	%rd18, %rd31;
	cvta.to.global.u64 	%rd19, %rd28;
	cvta.to.global.u64 	%rd20, %rd26;
	mul.lo.s64 	%rd47, %rd21, 144;
	add.s64 	%rd48, %rd20, %rd47;
	add.s64 	%rd49, %rd19, %rd47;
	ld.global.f64 	%fd6, [%rd49+32];
	add.s64 	%rd50, %rd18, %rd47;
	ld.global.f64 	%fd7, [%rd50+80];
	mul.rn.f64 	%fd8, %fd7, 0d3FE0000000000000;
	mul.rn.f64 	%fd9, %fd8, %fd2;
	fma.rn.f64 	%fd10, %fd6, %fd1, %fd9;
	ld.global.f64 	%fd11, [%rd48+8];
	add.rn.f64 	%fd12, %fd11, %fd10;
	st.global.f64 	[%rd48+8], %fd12;
	add.s64 	%rd51, %rd17, %rd47;
	add.s64 	%rd52, %rd16, %rd47;
	ld.global.f64 	%fd13, [%rd52+40];
	add.s64 	%rd53, %rd15, %rd47;
	ld.global.f64 	%fd14, [%rd53+88];
	mul.rn.f64 	%fd15, %fd14, 0d3FE0000000000000;
	mul.rn.f64 	%fd16, %fd15, %fd3;
	fma.rn.f64 	%fd17, %fd13, %fd1, %fd16;
	ld.global.f64 	%fd18, [%rd51+16];
	add.rn.f64 	%fd19, %fd18, %fd17;
	st.global.f64 	[%rd51+16], %fd19;
	add.s64 	%rd54, %rd13, %rd47;
	ld.global.f64 	%fd20, [%rd54+80];
	add.s64 	%rd55, %rd12, %rd47;
	ld.global.f64 	%fd21, [%rd55+128];
	div.rn.f64 	%fd22, %fd20, %fd21;
	add.s64 	%rd56, %rd14, %rd47;
	st.global.f64 	[%rd56+80], %fd22;
	add.s64 	%rd57, %rd10, %rd47;
	ld.global.f64 	%fd23, [%rd57+88];
	add.s64 	%rd58, %rd9, %rd47;
	ld.global.f64 	%fd24, [%rd58+128];
	div.rn.f64 	%fd25, %fd23, %fd24;
	add.s64 	%rd59, %rd11, %rd47;
	st.global.f64 	[%rd59+88], %fd25;
	add.s64 	%rd60, %rd8, %rd47;
	add.s64 	%rd61, %rd7, %rd47;
	ld.global.f64 	%fd26, [%rd61+80];
	ld.global.f64 	%fd27, [%rd60+32];
	fma.rn.f64 	%fd28, %fd26, %fd4, %fd27;
	st.global.f64 	[%rd60+32], %fd28;
	add.s64 	%rd62, %rd6, %rd47;
	add.s64 	%rd63, %rd5, %rd47;
	ld.global.f64 	%fd29, [%rd63+88];
	ld.global.f64 	%fd30, [%rd62+40];
	fma.rn.f64 	%fd31, %fd29, %fd5, %fd30;
	st.global.f64 	[%rd62+40], %fd31;
	add.s64 	%rd64, %rd4, %rd47;
	mov.u64 	%rd65, 0;
	st.global.u64 	[%rd64+48], %rd65;
	add.s64 	%rd66, %rd3, %rd47;
	st.global.u64 	[%rd66+80], %rd65;
	add.s64 	%rd67, %rd2, %rd47;
	st.global.u64 	[%rd67+88], %rd65;
	add.s64 	%rd68, %rd1, %rd47;
	st.global.u64 	[%rd68+96], %rd65;
$L__BB66_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_Forces_line_845_ // -- Begin function chpl_gpu_kernel_Forces_line_845_
.visible .entry chpl_gpu_kernel_Forces_line_845_(
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_0,
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_1,
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_2,
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_3,
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_4,
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_5,
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_6,
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_7,
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_8,
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_9,
	.param .f64 chpl_gpu_kernel_Forces_line_845__param_10,
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_11,
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_12,
	.param .f64 chpl_gpu_kernel_Forces_line_845__param_13,
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_14,
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_15,
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_16,
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_17,
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_18,
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_19,
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_20,
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_21,
	.param .f64 chpl_gpu_kernel_Forces_line_845__param_22,
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_23,
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_24,
	.param .f64 chpl_gpu_kernel_Forces_line_845__param_25,
	.param .u64 chpl_gpu_kernel_Forces_line_845__param_26
)                                       // @chpl_gpu_kernel_Forces_line_845_
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<72>;
	.reg .f64 	%fd<35>;

// %bb.0:
	ld.param.u64 	%rd23, [chpl_gpu_kernel_Forces_line_845__param_0];
	ld.param.u64 	%rd25, [chpl_gpu_kernel_Forces_line_845__param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %tid.x;
	mul.wide.s32 	%rd46, %r2, %r1;
	cvt.s64.s32 	%rd47, %r3;
	add.s64 	%rd48, %rd47, %rd23;
	add.s64 	%rd22, %rd48, %rd46;
	setp.gt.s64 	%p1, %rd22, %rd25;
	@%p1 bra 	$L__BB67_2;
// %bb.1:
	ld.param.f64 	%fd4, [chpl_gpu_kernel_Forces_line_845__param_25];
	ld.param.f64 	%fd3, [chpl_gpu_kernel_Forces_line_845__param_22];
	ld.param.f64 	%fd2, [chpl_gpu_kernel_Forces_line_845__param_13];
	ld.param.f64 	%fd1, [chpl_gpu_kernel_Forces_line_845__param_10];
	ld.param.u64 	%rd24, [chpl_gpu_kernel_Forces_line_845__param_26];
	cvta.to.global.u64 	%rd1, %rd24;
	ld.param.u64 	%rd26, [chpl_gpu_kernel_Forces_line_845__param_24];
	cvta.to.global.u64 	%rd2, %rd26;
	ld.param.u64 	%rd27, [chpl_gpu_kernel_Forces_line_845__param_2];
	ld.param.u64 	%rd28, [chpl_gpu_kernel_Forces_line_845__param_23];
	cvta.to.global.u64 	%rd3, %rd28;
	ld.param.u64 	%rd29, [chpl_gpu_kernel_Forces_line_845__param_3];
	ld.param.u64 	%rd30, [chpl_gpu_kernel_Forces_line_845__param_21];
	cvta.to.global.u64 	%rd4, %rd30;
	ld.param.u64 	%rd31, [chpl_gpu_kernel_Forces_line_845__param_4];
	ld.param.u64 	%rd32, [chpl_gpu_kernel_Forces_line_845__param_20];
	cvta.to.global.u64 	%rd5, %rd32;
	ld.param.u64 	%rd33, [chpl_gpu_kernel_Forces_line_845__param_5];
	ld.param.u64 	%rd34, [chpl_gpu_kernel_Forces_line_845__param_19];
	cvta.to.global.u64 	%rd6, %rd34;
	ld.param.u64 	%rd35, [chpl_gpu_kernel_Forces_line_845__param_6];
	ld.param.u64 	%rd36, [chpl_gpu_kernel_Forces_line_845__param_18];
	cvta.to.global.u64 	%rd7, %rd36;
	ld.param.u64 	%rd37, [chpl_gpu_kernel_Forces_line_845__param_7];
	ld.param.u64 	%rd38, [chpl_gpu_kernel_Forces_line_845__param_17];
	cvta.to.global.u64 	%rd8, %rd38;
	ld.param.u64 	%rd39, [chpl_gpu_kernel_Forces_line_845__param_8];
	ld.param.u64 	%rd40, [chpl_gpu_kernel_Forces_line_845__param_16];
	cvta.to.global.u64 	%rd9, %rd40;
	ld.param.u64 	%rd41, [chpl_gpu_kernel_Forces_line_845__param_9];
	ld.param.u64 	%rd42, [chpl_gpu_kernel_Forces_line_845__param_15];
	cvta.to.global.u64 	%rd10, %rd42;
	ld.param.u64 	%rd43, [chpl_gpu_kernel_Forces_line_845__param_14];
	cvta.to.global.u64 	%rd11, %rd43;
	ld.param.u64 	%rd44, [chpl_gpu_kernel_Forces_line_845__param_11];
	ld.param.u64 	%rd45, [chpl_gpu_kernel_Forces_line_845__param_12];
	cvta.to.global.u64 	%rd12, %rd45;
	cvta.to.global.u64 	%rd13, %rd44;
	cvta.to.global.u64 	%rd14, %rd41;
	cvta.to.global.u64 	%rd15, %rd39;
	cvta.to.global.u64 	%rd16, %rd37;
	cvta.to.global.u64 	%rd17, %rd35;
	cvta.to.global.u64 	%rd18, %rd33;
	cvta.to.global.u64 	%rd19, %rd31;
	cvta.to.global.u64 	%rd20, %rd29;
	cvta.to.global.u64 	%rd21, %rd27;
	mul.lo.s64 	%rd49, %rd22, 144;
	add.s64 	%rd50, %rd20, %rd49;
	ld.global.f64 	%fd5, [%rd50+80];
	add.s64 	%rd51, %rd19, %rd49;
	ld.global.f64 	%fd6, [%rd51+128];
	div.rn.f64 	%fd7, %fd5, %fd6;
	add.s64 	%rd52, %rd21, %rd49;
	st.global.f64 	[%rd52+80], %fd7;
	add.s64 	%rd53, %rd17, %rd49;
	ld.global.f64 	%fd8, [%rd53+88];
	add.s64 	%rd54, %rd16, %rd49;
	ld.global.f64 	%fd9, [%rd54+128];
	div.rn.f64 	%fd10, %fd8, %fd9;
	add.s64 	%rd55, %rd18, %rd49;
	st.global.f64 	[%rd55+88], %fd10;
	add.s64 	%rd56, %rd15, %rd49;
	add.s64 	%rd57, %rd14, %rd49;
	ld.global.f64 	%fd11, [%rd57+80];
	ld.global.f64 	%fd12, [%rd56+32];
	fma.rn.f64 	%fd13, %fd11, %fd1, %fd12;
	st.global.f64 	[%rd56+32], %fd13;
	add.s64 	%rd58, %rd13, %rd49;
	add.s64 	%rd59, %rd12, %rd49;
	ld.global.f64 	%fd14, [%rd59+88];
	ld.global.f64 	%fd15, [%rd58+40];
	fma.rn.f64 	%fd16, %fd14, %fd2, %fd15;
	st.global.f64 	[%rd58+40], %fd16;
	shl.b64 	%rd60, %rd22, 3;
	add.s64 	%rd61, %rd11, %rd60;
	add.s64 	%rd62, %rd10, %rd49;
	ld.global.f64 	%fd17, [%rd62+128];
	mul.rn.f64 	%fd18, %fd17, 0d3FE0000000000000;
	add.s64 	%rd63, %rd9, %rd49;
	ld.global.f64 	%fd19, [%rd63+32];
	add.s64 	%rd64, %rd8, %rd49;
	ld.global.f64 	%fd20, [%rd64+32];
	add.s64 	%rd65, %rd7, %rd49;
	ld.global.f64 	%fd21, [%rd65+40];
	add.s64 	%rd66, %rd6, %rd49;
	ld.global.f64 	%fd22, [%rd66+40];
	mul.rn.f64 	%fd23, %fd21, %fd22;
	fma.rn.f64 	%fd24, %fd19, %fd20, %fd23;
	mul.rn.f64 	%fd25, %fd18, %fd24;
	st.global.f64 	[%rd61], %fd25;
	add.s64 	%rd67, %rd5, %rd60;
	add.s64 	%rd68, %rd4, %rd49;
	ld.global.f64 	%fd26, [%rd68+8];
	add.s64 	%rd69, %rd3, %rd49;
	ld.global.f64 	%fd27, [%rd69+40];
	add.s64 	%rd70, %rd2, %rd49;
	ld.global.f64 	%fd28, [%rd70+16];
	add.s64 	%rd71, %rd1, %rd49;
	ld.global.f64 	%fd29, [%rd71+32];
	sub.rn.f64 	%fd30, %fd28, %fd4;
	mul.rn.f64 	%fd31, %fd30, %fd29;
	sub.rn.f64 	%fd32, %fd26, %fd3;
	neg.f64 	%fd33, %fd31;
	fma.rn.f64 	%fd34, %fd32, %fd27, %fd33;
	st.global.f64 	[%rd67], %fd34;
$L__BB67_2:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_InitFluid_line_241_ // -- Begin function chpl_gpu_kernel_InitFluid_line_241_
.visible .entry chpl_gpu_kernel_InitFluid_line_241_(
	.param .u64 chpl_gpu_kernel_InitFluid_line_241__param_0,
	.param .u64 chpl_gpu_kernel_InitFluid_line_241__param_1,
	.param .u64 chpl_gpu_kernel_InitFluid_line_241__param_2,
	.param .u64 chpl_gpu_kernel_InitFluid_line_241__param_3,
	.param .f64 chpl_gpu_kernel_InitFluid_line_241__param_4,
	.param .u64 chpl_gpu_kernel_InitFluid_line_241__param_5
)                                       // @chpl_gpu_kernel_InitFluid_line_241_
{
	.reg .pred 	%p<32>;
	.reg .b32 	%r<59>;
	.reg .b64 	%rd<44>;
	.reg .f64 	%fd<55>;

// %bb.0:
	ld.param.f64 	%fd53, [chpl_gpu_kernel_InitFluid_line_241__param_4];
	ld.param.u64 	%rd4, [chpl_gpu_kernel_InitFluid_line_241__param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_InitFluid_line_241__param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r2, %tid.x;
	mul.wide.s32 	%rd9, %r3, %r1;
	cvt.s64.s32 	%rd10, %r2;
	add.s64 	%rd11, %rd10, %rd4;
	add.s64 	%rd12, %rd11, %rd9;
	setp.gt.s64 	%p1, %rd12, %rd6;
	@%p1 bra 	$L__BB68_2;
// %bb.1:
	ld.param.u64 	%rd7, [chpl_gpu_kernel_InitFluid_line_241__param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	abs.f64 	%fd1, %fd53;
	mul.lo.s64 	%rd13, %rd12, 144;
	add.s64 	%rd14, %rd8, %rd13;
	add.s64 	%rd2, %rd14, 16;
	setp.le.f64 	%p2, %fd1, 0d7FF0000000000000;
	ld.global.f64 	%fd8, [%rd2];
	setp.gt.f64 	%p3, %fd8, %fd53;
	selp.f64 	%fd9, %fd8, %fd53, %p2;
	selp.f64 	%fd53, %fd53, %fd9, %p3;
$L__BB68_2:
	// begin inline asm
	mov.u32 %r4, %laneid;
	// end inline asm
	mov.b64 	%rd15, %fd53;
	cvt.u32.u64 	%r6, %rd15;
	mov.b32 	%r7, 1;
	mov.b32 	%r8, 31;
	mov.b32 	%r9, -1;
	// begin inline asm
	shfl.sync.down.b32 %r5, %r6, %r7, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd16, %r5;
	{ .reg .b32 tmp; mov.b64 {tmp, %r11}, %rd15; }
	// begin inline asm
	shfl.sync.down.b32 %r10, %r11, %r7, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd17, %r10;
	shl.b64 	%rd18, %rd17, 32;
	or.b64  	%rd19, %rd18, %rd16;
	mov.b64 	%fd10, %rd19;
	setp.lt.s32 	%p4, %r4, 31;
	setp.gt.f64 	%p5, %fd53, %fd10;
	selp.f64 	%fd11, %fd10, %fd53, %p5;
	selp.f64 	%fd12, %fd11, %fd53, %p4;
	mov.b64 	%rd20, %fd12;
	cvt.u32.u64 	%r16, %rd20;
	mov.b32 	%r17, 2;
	// begin inline asm
	shfl.sync.down.b32 %r15, %r16, %r17, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd21, %r15;
	{ .reg .b32 tmp; mov.b64 {tmp, %r21}, %rd20; }
	// begin inline asm
	shfl.sync.down.b32 %r20, %r21, %r17, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd22, %r20;
	shl.b64 	%rd23, %rd22, 32;
	or.b64  	%rd24, %rd23, %rd21;
	mov.b64 	%fd13, %rd24;
	setp.lt.s32 	%p6, %r4, 30;
	setp.gt.f64 	%p7, %fd12, %fd13;
	selp.f64 	%fd14, %fd13, %fd12, %p7;
	selp.f64 	%fd15, %fd14, %fd12, %p6;
	mov.b64 	%rd25, %fd15;
	cvt.u32.u64 	%r26, %rd25;
	mov.b32 	%r27, 4;
	// begin inline asm
	shfl.sync.down.b32 %r25, %r26, %r27, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd26, %r25;
	{ .reg .b32 tmp; mov.b64 {tmp, %r31}, %rd25; }
	// begin inline asm
	shfl.sync.down.b32 %r30, %r31, %r27, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd27, %r30;
	shl.b64 	%rd28, %rd27, 32;
	or.b64  	%rd29, %rd28, %rd26;
	mov.b64 	%fd16, %rd29;
	setp.lt.s32 	%p8, %r4, 28;
	setp.gt.f64 	%p9, %fd15, %fd16;
	selp.f64 	%fd17, %fd16, %fd15, %p9;
	selp.f64 	%fd18, %fd17, %fd15, %p8;
	mov.b64 	%rd30, %fd18;
	cvt.u32.u64 	%r36, %rd30;
	mov.b32 	%r37, 8;
	// begin inline asm
	shfl.sync.down.b32 %r35, %r36, %r37, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd31, %r35;
	{ .reg .b32 tmp; mov.b64 {tmp, %r41}, %rd30; }
	// begin inline asm
	shfl.sync.down.b32 %r40, %r41, %r37, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd32, %r40;
	shl.b64 	%rd33, %rd32, 32;
	or.b64  	%rd34, %rd33, %rd31;
	mov.b64 	%fd19, %rd34;
	setp.lt.s32 	%p10, %r4, 24;
	setp.gt.f64 	%p11, %fd18, %fd19;
	selp.f64 	%fd20, %fd19, %fd18, %p11;
	selp.f64 	%fd21, %fd20, %fd18, %p10;
	mov.b64 	%rd35, %fd21;
	cvt.u32.u64 	%r46, %rd35;
	mov.b32 	%r47, 16;
	// begin inline asm
	shfl.sync.down.b32 %r45, %r46, %r47, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd36, %r45;
	{ .reg .b32 tmp; mov.b64 {tmp, %r51}, %rd35; }
	// begin inline asm
	shfl.sync.down.b32 %r50, %r51, %r47, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd37, %r50;
	shl.b64 	%rd38, %rd37, 32;
	or.b64  	%rd39, %rd38, %rd36;
	mov.b64 	%fd22, %rd39;
	setp.lt.s32 	%p12, %r4, 16;
	setp.gt.f64 	%p13, %fd21, %fd22;
	selp.f64 	%fd23, %fd22, %fd21, %p13;
	selp.f64 	%fd54, %fd23, %fd21, %p12;
	setp.ne.s32 	%p14, %r4, 0;
	@%p14 bra 	$L__BB68_4;
// %bb.3:
	shr.s32 	%r55, %r2, 31;
	shr.u32 	%r56, %r55, 27;
	add.s32 	%r57, %r2, %r56;
	shr.s32 	%r58, %r57, 5;
	mul.wide.s32 	%rd40, %r58, 8;
	mov.u64 	%rd41, _ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage;
	add.s64 	%rd42, %rd41, %rd40;
	st.shared.f64 	[%rd42+16], %fd54;
$L__BB68_4:
	bar.sync 	0;
	setp.ne.s32 	%p15, %r2, 0;
	@%p15 bra 	$L__BB68_6;
// %bb.5:
	ld.shared.f64 	%fd24, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+24];
	setp.lt.f64 	%p16, %fd24, %fd54;
	selp.f64 	%fd25, %fd24, %fd54, %p16;
	ld.shared.f64 	%fd26, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+32];
	setp.lt.f64 	%p17, %fd26, %fd25;
	selp.f64 	%fd27, %fd26, %fd25, %p17;
	ld.shared.f64 	%fd28, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+40];
	setp.lt.f64 	%p18, %fd28, %fd27;
	selp.f64 	%fd29, %fd28, %fd27, %p18;
	ld.shared.f64 	%fd30, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+48];
	setp.lt.f64 	%p19, %fd30, %fd29;
	selp.f64 	%fd31, %fd30, %fd29, %p19;
	ld.shared.f64 	%fd32, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+56];
	setp.lt.f64 	%p20, %fd32, %fd31;
	selp.f64 	%fd33, %fd32, %fd31, %p20;
	ld.shared.f64 	%fd34, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+64];
	setp.lt.f64 	%p21, %fd34, %fd33;
	selp.f64 	%fd35, %fd34, %fd33, %p21;
	ld.shared.f64 	%fd36, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+72];
	setp.lt.f64 	%p22, %fd36, %fd35;
	selp.f64 	%fd37, %fd36, %fd35, %p22;
	ld.shared.f64 	%fd38, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+80];
	setp.lt.f64 	%p23, %fd38, %fd37;
	selp.f64 	%fd39, %fd38, %fd37, %p23;
	ld.shared.f64 	%fd40, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+88];
	setp.lt.f64 	%p24, %fd40, %fd39;
	selp.f64 	%fd41, %fd40, %fd39, %p24;
	ld.shared.f64 	%fd42, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+96];
	setp.lt.f64 	%p25, %fd42, %fd41;
	selp.f64 	%fd43, %fd42, %fd41, %p25;
	ld.shared.f64 	%fd44, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+104];
	setp.lt.f64 	%p26, %fd44, %fd43;
	selp.f64 	%fd45, %fd44, %fd43, %p26;
	ld.shared.f64 	%fd46, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+112];
	setp.lt.f64 	%p27, %fd46, %fd45;
	selp.f64 	%fd47, %fd46, %fd45, %p27;
	ld.shared.f64 	%fd48, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+120];
	setp.lt.f64 	%p28, %fd48, %fd47;
	selp.f64 	%fd49, %fd48, %fd47, %p28;
	ld.shared.f64 	%fd50, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+128];
	setp.lt.f64 	%p29, %fd50, %fd49;
	selp.f64 	%fd51, %fd50, %fd49, %p29;
	ld.shared.f64 	%fd52, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+136];
	setp.lt.f64 	%p30, %fd52, %fd51;
	selp.f64 	%fd54, %fd52, %fd51, %p30;
$L__BB68_6:
	@%p15 bra 	$L__BB68_8;
// %bb.7:
	ld.param.u64 	%rd5, [chpl_gpu_kernel_InitFluid_line_241__param_5];
	cvta.to.global.u64 	%rd1, %rd5;
	mul.wide.u32 	%rd43, %r1, 8;
	add.s64 	%rd3, %rd1, %rd43;
	st.global.f64 	[%rd3], %fd54;
$L__BB68_8:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_InitFluid_line_241_2 // -- Begin function chpl_gpu_kernel_InitFluid_line_241_2
.visible .entry chpl_gpu_kernel_InitFluid_line_241_2(
	.param .u64 chpl_gpu_kernel_InitFluid_line_241_2_param_0,
	.param .u64 chpl_gpu_kernel_InitFluid_line_241_2_param_1,
	.param .u64 chpl_gpu_kernel_InitFluid_line_241_2_param_2,
	.param .u64 chpl_gpu_kernel_InitFluid_line_241_2_param_3,
	.param .f64 chpl_gpu_kernel_InitFluid_line_241_2_param_4,
	.param .u64 chpl_gpu_kernel_InitFluid_line_241_2_param_5
)                                       // @chpl_gpu_kernel_InitFluid_line_241_2
{
	.reg .pred 	%p<32>;
	.reg .b32 	%r<59>;
	.reg .b64 	%rd<44>;
	.reg .f64 	%fd<55>;

// %bb.0:
	ld.param.f64 	%fd53, [chpl_gpu_kernel_InitFluid_line_241_2_param_4];
	ld.param.u64 	%rd4, [chpl_gpu_kernel_InitFluid_line_241_2_param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_InitFluid_line_241_2_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r2, %tid.x;
	mul.wide.s32 	%rd9, %r3, %r1;
	cvt.s64.s32 	%rd10, %r2;
	add.s64 	%rd11, %rd10, %rd4;
	add.s64 	%rd12, %rd11, %rd9;
	setp.gt.s64 	%p1, %rd12, %rd6;
	@%p1 bra 	$L__BB69_2;
// %bb.1:
	ld.param.u64 	%rd7, [chpl_gpu_kernel_InitFluid_line_241_2_param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	abs.f64 	%fd1, %fd53;
	mul.lo.s64 	%rd13, %rd12, 144;
	add.s64 	%rd14, %rd8, %rd13;
	add.s64 	%rd2, %rd14, 8;
	setp.le.f64 	%p2, %fd1, 0d7FF0000000000000;
	ld.global.f64 	%fd8, [%rd2];
	setp.lt.f64 	%p3, %fd8, %fd53;
	selp.f64 	%fd9, %fd8, %fd53, %p2;
	selp.f64 	%fd53, %fd53, %fd9, %p3;
$L__BB69_2:
	// begin inline asm
	mov.u32 %r4, %laneid;
	// end inline asm
	mov.b64 	%rd15, %fd53;
	cvt.u32.u64 	%r6, %rd15;
	mov.b32 	%r7, 1;
	mov.b32 	%r8, 31;
	mov.b32 	%r9, -1;
	// begin inline asm
	shfl.sync.down.b32 %r5, %r6, %r7, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd16, %r5;
	{ .reg .b32 tmp; mov.b64 {tmp, %r11}, %rd15; }
	// begin inline asm
	shfl.sync.down.b32 %r10, %r11, %r7, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd17, %r10;
	shl.b64 	%rd18, %rd17, 32;
	or.b64  	%rd19, %rd18, %rd16;
	mov.b64 	%fd10, %rd19;
	setp.lt.s32 	%p4, %r4, 31;
	setp.lt.f64 	%p5, %fd53, %fd10;
	selp.f64 	%fd11, %fd10, %fd53, %p5;
	selp.f64 	%fd12, %fd11, %fd53, %p4;
	mov.b64 	%rd20, %fd12;
	cvt.u32.u64 	%r16, %rd20;
	mov.b32 	%r17, 2;
	// begin inline asm
	shfl.sync.down.b32 %r15, %r16, %r17, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd21, %r15;
	{ .reg .b32 tmp; mov.b64 {tmp, %r21}, %rd20; }
	// begin inline asm
	shfl.sync.down.b32 %r20, %r21, %r17, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd22, %r20;
	shl.b64 	%rd23, %rd22, 32;
	or.b64  	%rd24, %rd23, %rd21;
	mov.b64 	%fd13, %rd24;
	setp.lt.s32 	%p6, %r4, 30;
	setp.lt.f64 	%p7, %fd12, %fd13;
	selp.f64 	%fd14, %fd13, %fd12, %p7;
	selp.f64 	%fd15, %fd14, %fd12, %p6;
	mov.b64 	%rd25, %fd15;
	cvt.u32.u64 	%r26, %rd25;
	mov.b32 	%r27, 4;
	// begin inline asm
	shfl.sync.down.b32 %r25, %r26, %r27, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd26, %r25;
	{ .reg .b32 tmp; mov.b64 {tmp, %r31}, %rd25; }
	// begin inline asm
	shfl.sync.down.b32 %r30, %r31, %r27, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd27, %r30;
	shl.b64 	%rd28, %rd27, 32;
	or.b64  	%rd29, %rd28, %rd26;
	mov.b64 	%fd16, %rd29;
	setp.lt.s32 	%p8, %r4, 28;
	setp.lt.f64 	%p9, %fd15, %fd16;
	selp.f64 	%fd17, %fd16, %fd15, %p9;
	selp.f64 	%fd18, %fd17, %fd15, %p8;
	mov.b64 	%rd30, %fd18;
	cvt.u32.u64 	%r36, %rd30;
	mov.b32 	%r37, 8;
	// begin inline asm
	shfl.sync.down.b32 %r35, %r36, %r37, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd31, %r35;
	{ .reg .b32 tmp; mov.b64 {tmp, %r41}, %rd30; }
	// begin inline asm
	shfl.sync.down.b32 %r40, %r41, %r37, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd32, %r40;
	shl.b64 	%rd33, %rd32, 32;
	or.b64  	%rd34, %rd33, %rd31;
	mov.b64 	%fd19, %rd34;
	setp.lt.s32 	%p10, %r4, 24;
	setp.lt.f64 	%p11, %fd18, %fd19;
	selp.f64 	%fd20, %fd19, %fd18, %p11;
	selp.f64 	%fd21, %fd20, %fd18, %p10;
	mov.b64 	%rd35, %fd21;
	cvt.u32.u64 	%r46, %rd35;
	mov.b32 	%r47, 16;
	// begin inline asm
	shfl.sync.down.b32 %r45, %r46, %r47, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd36, %r45;
	{ .reg .b32 tmp; mov.b64 {tmp, %r51}, %rd35; }
	// begin inline asm
	shfl.sync.down.b32 %r50, %r51, %r47, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd37, %r50;
	shl.b64 	%rd38, %rd37, 32;
	or.b64  	%rd39, %rd38, %rd36;
	mov.b64 	%fd22, %rd39;
	setp.lt.s32 	%p12, %r4, 16;
	setp.lt.f64 	%p13, %fd21, %fd22;
	selp.f64 	%fd23, %fd22, %fd21, %p13;
	selp.f64 	%fd54, %fd23, %fd21, %p12;
	setp.ne.s32 	%p14, %r4, 0;
	@%p14 bra 	$L__BB69_4;
// %bb.3:
	shr.s32 	%r55, %r2, 31;
	shr.u32 	%r56, %r55, 27;
	add.s32 	%r57, %r2, %r56;
	shr.s32 	%r58, %r57, 5;
	mul.wide.s32 	%rd40, %r58, 8;
	mov.u64 	%rd41, _ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage;
	add.s64 	%rd42, %rd41, %rd40;
	st.shared.f64 	[%rd42+16], %fd54;
$L__BB69_4:
	bar.sync 	0;
	setp.ne.s32 	%p15, %r2, 0;
	@%p15 bra 	$L__BB69_6;
// %bb.5:
	ld.shared.f64 	%fd24, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+24];
	setp.gt.f64 	%p16, %fd24, %fd54;
	selp.f64 	%fd25, %fd24, %fd54, %p16;
	ld.shared.f64 	%fd26, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+32];
	setp.gt.f64 	%p17, %fd26, %fd25;
	selp.f64 	%fd27, %fd26, %fd25, %p17;
	ld.shared.f64 	%fd28, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+40];
	setp.gt.f64 	%p18, %fd28, %fd27;
	selp.f64 	%fd29, %fd28, %fd27, %p18;
	ld.shared.f64 	%fd30, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+48];
	setp.gt.f64 	%p19, %fd30, %fd29;
	selp.f64 	%fd31, %fd30, %fd29, %p19;
	ld.shared.f64 	%fd32, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+56];
	setp.gt.f64 	%p20, %fd32, %fd31;
	selp.f64 	%fd33, %fd32, %fd31, %p20;
	ld.shared.f64 	%fd34, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+64];
	setp.gt.f64 	%p21, %fd34, %fd33;
	selp.f64 	%fd35, %fd34, %fd33, %p21;
	ld.shared.f64 	%fd36, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+72];
	setp.gt.f64 	%p22, %fd36, %fd35;
	selp.f64 	%fd37, %fd36, %fd35, %p22;
	ld.shared.f64 	%fd38, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+80];
	setp.gt.f64 	%p23, %fd38, %fd37;
	selp.f64 	%fd39, %fd38, %fd37, %p23;
	ld.shared.f64 	%fd40, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+88];
	setp.gt.f64 	%p24, %fd40, %fd39;
	selp.f64 	%fd41, %fd40, %fd39, %p24;
	ld.shared.f64 	%fd42, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+96];
	setp.gt.f64 	%p25, %fd42, %fd41;
	selp.f64 	%fd43, %fd42, %fd41, %p25;
	ld.shared.f64 	%fd44, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+104];
	setp.gt.f64 	%p26, %fd44, %fd43;
	selp.f64 	%fd45, %fd44, %fd43, %p26;
	ld.shared.f64 	%fd46, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+112];
	setp.gt.f64 	%p27, %fd46, %fd45;
	selp.f64 	%fd47, %fd46, %fd45, %p27;
	ld.shared.f64 	%fd48, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+120];
	setp.gt.f64 	%p28, %fd48, %fd47;
	selp.f64 	%fd49, %fd48, %fd47, %p28;
	ld.shared.f64 	%fd50, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+128];
	setp.gt.f64 	%p29, %fd50, %fd49;
	selp.f64 	%fd51, %fd50, %fd49, %p29;
	ld.shared.f64 	%fd52, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+136];
	setp.gt.f64 	%p30, %fd52, %fd51;
	selp.f64 	%fd54, %fd52, %fd51, %p30;
$L__BB69_6:
	@%p15 bra 	$L__BB69_8;
// %bb.7:
	ld.param.u64 	%rd5, [chpl_gpu_kernel_InitFluid_line_241_2_param_5];
	cvta.to.global.u64 	%rd1, %rd5;
	mul.wide.u32 	%rd43, %r1, 8;
	add.s64 	%rd3, %rd1, %rd43;
	st.global.f64 	[%rd3], %fd54;
$L__BB69_8:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_InitFluid_line_242_ // -- Begin function chpl_gpu_kernel_InitFluid_line_242_
.visible .entry chpl_gpu_kernel_InitFluid_line_242_(
	.param .u64 chpl_gpu_kernel_InitFluid_line_242__param_0,
	.param .u64 chpl_gpu_kernel_InitFluid_line_242__param_1,
	.param .u64 chpl_gpu_kernel_InitFluid_line_242__param_2,
	.param .u64 chpl_gpu_kernel_InitFluid_line_242__param_3,
	.param .f64 chpl_gpu_kernel_InitFluid_line_242__param_4,
	.param .u64 chpl_gpu_kernel_InitFluid_line_242__param_5
)                                       // @chpl_gpu_kernel_InitFluid_line_242_
{
	.reg .pred 	%p<32>;
	.reg .b32 	%r<59>;
	.reg .b64 	%rd<44>;
	.reg .f64 	%fd<55>;

// %bb.0:
	ld.param.f64 	%fd53, [chpl_gpu_kernel_InitFluid_line_242__param_4];
	ld.param.u64 	%rd4, [chpl_gpu_kernel_InitFluid_line_242__param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_InitFluid_line_242__param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r2, %tid.x;
	mul.wide.s32 	%rd9, %r3, %r1;
	cvt.s64.s32 	%rd10, %r2;
	add.s64 	%rd11, %rd10, %rd4;
	add.s64 	%rd12, %rd11, %rd9;
	setp.gt.s64 	%p1, %rd12, %rd6;
	@%p1 bra 	$L__BB70_2;
// %bb.1:
	ld.param.u64 	%rd7, [chpl_gpu_kernel_InitFluid_line_242__param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	abs.f64 	%fd1, %fd53;
	mul.lo.s64 	%rd13, %rd12, 144;
	add.s64 	%rd14, %rd8, %rd13;
	add.s64 	%rd2, %rd14, 16;
	setp.le.f64 	%p2, %fd1, 0d7FF0000000000000;
	ld.global.f64 	%fd8, [%rd2];
	setp.gt.f64 	%p3, %fd8, %fd53;
	selp.f64 	%fd9, %fd8, %fd53, %p2;
	selp.f64 	%fd53, %fd53, %fd9, %p3;
$L__BB70_2:
	// begin inline asm
	mov.u32 %r4, %laneid;
	// end inline asm
	mov.b64 	%rd15, %fd53;
	cvt.u32.u64 	%r6, %rd15;
	mov.b32 	%r7, 1;
	mov.b32 	%r8, 31;
	mov.b32 	%r9, -1;
	// begin inline asm
	shfl.sync.down.b32 %r5, %r6, %r7, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd16, %r5;
	{ .reg .b32 tmp; mov.b64 {tmp, %r11}, %rd15; }
	// begin inline asm
	shfl.sync.down.b32 %r10, %r11, %r7, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd17, %r10;
	shl.b64 	%rd18, %rd17, 32;
	or.b64  	%rd19, %rd18, %rd16;
	mov.b64 	%fd10, %rd19;
	setp.lt.s32 	%p4, %r4, 31;
	setp.gt.f64 	%p5, %fd53, %fd10;
	selp.f64 	%fd11, %fd10, %fd53, %p5;
	selp.f64 	%fd12, %fd11, %fd53, %p4;
	mov.b64 	%rd20, %fd12;
	cvt.u32.u64 	%r16, %rd20;
	mov.b32 	%r17, 2;
	// begin inline asm
	shfl.sync.down.b32 %r15, %r16, %r17, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd21, %r15;
	{ .reg .b32 tmp; mov.b64 {tmp, %r21}, %rd20; }
	// begin inline asm
	shfl.sync.down.b32 %r20, %r21, %r17, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd22, %r20;
	shl.b64 	%rd23, %rd22, 32;
	or.b64  	%rd24, %rd23, %rd21;
	mov.b64 	%fd13, %rd24;
	setp.lt.s32 	%p6, %r4, 30;
	setp.gt.f64 	%p7, %fd12, %fd13;
	selp.f64 	%fd14, %fd13, %fd12, %p7;
	selp.f64 	%fd15, %fd14, %fd12, %p6;
	mov.b64 	%rd25, %fd15;
	cvt.u32.u64 	%r26, %rd25;
	mov.b32 	%r27, 4;
	// begin inline asm
	shfl.sync.down.b32 %r25, %r26, %r27, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd26, %r25;
	{ .reg .b32 tmp; mov.b64 {tmp, %r31}, %rd25; }
	// begin inline asm
	shfl.sync.down.b32 %r30, %r31, %r27, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd27, %r30;
	shl.b64 	%rd28, %rd27, 32;
	or.b64  	%rd29, %rd28, %rd26;
	mov.b64 	%fd16, %rd29;
	setp.lt.s32 	%p8, %r4, 28;
	setp.gt.f64 	%p9, %fd15, %fd16;
	selp.f64 	%fd17, %fd16, %fd15, %p9;
	selp.f64 	%fd18, %fd17, %fd15, %p8;
	mov.b64 	%rd30, %fd18;
	cvt.u32.u64 	%r36, %rd30;
	mov.b32 	%r37, 8;
	// begin inline asm
	shfl.sync.down.b32 %r35, %r36, %r37, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd31, %r35;
	{ .reg .b32 tmp; mov.b64 {tmp, %r41}, %rd30; }
	// begin inline asm
	shfl.sync.down.b32 %r40, %r41, %r37, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd32, %r40;
	shl.b64 	%rd33, %rd32, 32;
	or.b64  	%rd34, %rd33, %rd31;
	mov.b64 	%fd19, %rd34;
	setp.lt.s32 	%p10, %r4, 24;
	setp.gt.f64 	%p11, %fd18, %fd19;
	selp.f64 	%fd20, %fd19, %fd18, %p11;
	selp.f64 	%fd21, %fd20, %fd18, %p10;
	mov.b64 	%rd35, %fd21;
	cvt.u32.u64 	%r46, %rd35;
	mov.b32 	%r47, 16;
	// begin inline asm
	shfl.sync.down.b32 %r45, %r46, %r47, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd36, %r45;
	{ .reg .b32 tmp; mov.b64 {tmp, %r51}, %rd35; }
	// begin inline asm
	shfl.sync.down.b32 %r50, %r51, %r47, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd37, %r50;
	shl.b64 	%rd38, %rd37, 32;
	or.b64  	%rd39, %rd38, %rd36;
	mov.b64 	%fd22, %rd39;
	setp.lt.s32 	%p12, %r4, 16;
	setp.gt.f64 	%p13, %fd21, %fd22;
	selp.f64 	%fd23, %fd22, %fd21, %p13;
	selp.f64 	%fd54, %fd23, %fd21, %p12;
	setp.ne.s32 	%p14, %r4, 0;
	@%p14 bra 	$L__BB70_4;
// %bb.3:
	shr.s32 	%r55, %r2, 31;
	shr.u32 	%r56, %r55, 27;
	add.s32 	%r57, %r2, %r56;
	shr.s32 	%r58, %r57, 5;
	mul.wide.s32 	%rd40, %r58, 8;
	mov.u64 	%rd41, _ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage;
	add.s64 	%rd42, %rd41, %rd40;
	st.shared.f64 	[%rd42+16], %fd54;
$L__BB70_4:
	bar.sync 	0;
	setp.ne.s32 	%p15, %r2, 0;
	@%p15 bra 	$L__BB70_6;
// %bb.5:
	ld.shared.f64 	%fd24, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+24];
	setp.lt.f64 	%p16, %fd24, %fd54;
	selp.f64 	%fd25, %fd24, %fd54, %p16;
	ld.shared.f64 	%fd26, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+32];
	setp.lt.f64 	%p17, %fd26, %fd25;
	selp.f64 	%fd27, %fd26, %fd25, %p17;
	ld.shared.f64 	%fd28, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+40];
	setp.lt.f64 	%p18, %fd28, %fd27;
	selp.f64 	%fd29, %fd28, %fd27, %p18;
	ld.shared.f64 	%fd30, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+48];
	setp.lt.f64 	%p19, %fd30, %fd29;
	selp.f64 	%fd31, %fd30, %fd29, %p19;
	ld.shared.f64 	%fd32, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+56];
	setp.lt.f64 	%p20, %fd32, %fd31;
	selp.f64 	%fd33, %fd32, %fd31, %p20;
	ld.shared.f64 	%fd34, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+64];
	setp.lt.f64 	%p21, %fd34, %fd33;
	selp.f64 	%fd35, %fd34, %fd33, %p21;
	ld.shared.f64 	%fd36, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+72];
	setp.lt.f64 	%p22, %fd36, %fd35;
	selp.f64 	%fd37, %fd36, %fd35, %p22;
	ld.shared.f64 	%fd38, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+80];
	setp.lt.f64 	%p23, %fd38, %fd37;
	selp.f64 	%fd39, %fd38, %fd37, %p23;
	ld.shared.f64 	%fd40, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+88];
	setp.lt.f64 	%p24, %fd40, %fd39;
	selp.f64 	%fd41, %fd40, %fd39, %p24;
	ld.shared.f64 	%fd42, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+96];
	setp.lt.f64 	%p25, %fd42, %fd41;
	selp.f64 	%fd43, %fd42, %fd41, %p25;
	ld.shared.f64 	%fd44, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+104];
	setp.lt.f64 	%p26, %fd44, %fd43;
	selp.f64 	%fd45, %fd44, %fd43, %p26;
	ld.shared.f64 	%fd46, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+112];
	setp.lt.f64 	%p27, %fd46, %fd45;
	selp.f64 	%fd47, %fd46, %fd45, %p27;
	ld.shared.f64 	%fd48, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+120];
	setp.lt.f64 	%p28, %fd48, %fd47;
	selp.f64 	%fd49, %fd48, %fd47, %p28;
	ld.shared.f64 	%fd50, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+128];
	setp.lt.f64 	%p29, %fd50, %fd49;
	selp.f64 	%fd51, %fd50, %fd49, %p29;
	ld.shared.f64 	%fd52, [_ZZL36chpl_gpu_dev_min_breduce__real64_512dPdE12temp_storage+136];
	setp.lt.f64 	%p30, %fd52, %fd51;
	selp.f64 	%fd54, %fd52, %fd51, %p30;
$L__BB70_6:
	@%p15 bra 	$L__BB70_8;
// %bb.7:
	ld.param.u64 	%rd5, [chpl_gpu_kernel_InitFluid_line_242__param_5];
	cvta.to.global.u64 	%rd1, %rd5;
	mul.wide.u32 	%rd43, %r1, 8;
	add.s64 	%rd3, %rd1, %rd43;
	st.global.f64 	[%rd3], %fd54;
$L__BB70_8:
	ret;
                                        // -- End function
}
	// .globl	chpl_gpu_kernel_InitFluid_line_242_2 // -- Begin function chpl_gpu_kernel_InitFluid_line_242_2
.visible .entry chpl_gpu_kernel_InitFluid_line_242_2(
	.param .u64 chpl_gpu_kernel_InitFluid_line_242_2_param_0,
	.param .u64 chpl_gpu_kernel_InitFluid_line_242_2_param_1,
	.param .u64 chpl_gpu_kernel_InitFluid_line_242_2_param_2,
	.param .u64 chpl_gpu_kernel_InitFluid_line_242_2_param_3,
	.param .f64 chpl_gpu_kernel_InitFluid_line_242_2_param_4,
	.param .u64 chpl_gpu_kernel_InitFluid_line_242_2_param_5
)                                       // @chpl_gpu_kernel_InitFluid_line_242_2
{
	.reg .pred 	%p<32>;
	.reg .b32 	%r<59>;
	.reg .b64 	%rd<44>;
	.reg .f64 	%fd<55>;

// %bb.0:
	ld.param.f64 	%fd53, [chpl_gpu_kernel_InitFluid_line_242_2_param_4];
	ld.param.u64 	%rd4, [chpl_gpu_kernel_InitFluid_line_242_2_param_0];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_InitFluid_line_242_2_param_1];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r2, %tid.x;
	mul.wide.s32 	%rd9, %r3, %r1;
	cvt.s64.s32 	%rd10, %r2;
	add.s64 	%rd11, %rd10, %rd4;
	add.s64 	%rd12, %rd11, %rd9;
	setp.gt.s64 	%p1, %rd12, %rd6;
	@%p1 bra 	$L__BB71_2;
// %bb.1:
	ld.param.u64 	%rd7, [chpl_gpu_kernel_InitFluid_line_242_2_param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	abs.f64 	%fd1, %fd53;
	mul.lo.s64 	%rd13, %rd12, 144;
	add.s64 	%rd14, %rd8, %rd13;
	add.s64 	%rd2, %rd14, 8;
	setp.le.f64 	%p2, %fd1, 0d7FF0000000000000;
	ld.global.f64 	%fd8, [%rd2];
	setp.lt.f64 	%p3, %fd8, %fd53;
	selp.f64 	%fd9, %fd8, %fd53, %p2;
	selp.f64 	%fd53, %fd53, %fd9, %p3;
$L__BB71_2:
	// begin inline asm
	mov.u32 %r4, %laneid;
	// end inline asm
	mov.b64 	%rd15, %fd53;
	cvt.u32.u64 	%r6, %rd15;
	mov.b32 	%r7, 1;
	mov.b32 	%r8, 31;
	mov.b32 	%r9, -1;
	// begin inline asm
	shfl.sync.down.b32 %r5, %r6, %r7, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd16, %r5;
	{ .reg .b32 tmp; mov.b64 {tmp, %r11}, %rd15; }
	// begin inline asm
	shfl.sync.down.b32 %r10, %r11, %r7, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd17, %r10;
	shl.b64 	%rd18, %rd17, 32;
	or.b64  	%rd19, %rd18, %rd16;
	mov.b64 	%fd10, %rd19;
	setp.lt.s32 	%p4, %r4, 31;
	setp.lt.f64 	%p5, %fd53, %fd10;
	selp.f64 	%fd11, %fd10, %fd53, %p5;
	selp.f64 	%fd12, %fd11, %fd53, %p4;
	mov.b64 	%rd20, %fd12;
	cvt.u32.u64 	%r16, %rd20;
	mov.b32 	%r17, 2;
	// begin inline asm
	shfl.sync.down.b32 %r15, %r16, %r17, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd21, %r15;
	{ .reg .b32 tmp; mov.b64 {tmp, %r21}, %rd20; }
	// begin inline asm
	shfl.sync.down.b32 %r20, %r21, %r17, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd22, %r20;
	shl.b64 	%rd23, %rd22, 32;
	or.b64  	%rd24, %rd23, %rd21;
	mov.b64 	%fd13, %rd24;
	setp.lt.s32 	%p6, %r4, 30;
	setp.lt.f64 	%p7, %fd12, %fd13;
	selp.f64 	%fd14, %fd13, %fd12, %p7;
	selp.f64 	%fd15, %fd14, %fd12, %p6;
	mov.b64 	%rd25, %fd15;
	cvt.u32.u64 	%r26, %rd25;
	mov.b32 	%r27, 4;
	// begin inline asm
	shfl.sync.down.b32 %r25, %r26, %r27, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd26, %r25;
	{ .reg .b32 tmp; mov.b64 {tmp, %r31}, %rd25; }
	// begin inline asm
	shfl.sync.down.b32 %r30, %r31, %r27, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd27, %r30;
	shl.b64 	%rd28, %rd27, 32;
	or.b64  	%rd29, %rd28, %rd26;
	mov.b64 	%fd16, %rd29;
	setp.lt.s32 	%p8, %r4, 28;
	setp.lt.f64 	%p9, %fd15, %fd16;
	selp.f64 	%fd17, %fd16, %fd15, %p9;
	selp.f64 	%fd18, %fd17, %fd15, %p8;
	mov.b64 	%rd30, %fd18;
	cvt.u32.u64 	%r36, %rd30;
	mov.b32 	%r37, 8;
	// begin inline asm
	shfl.sync.down.b32 %r35, %r36, %r37, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd31, %r35;
	{ .reg .b32 tmp; mov.b64 {tmp, %r41}, %rd30; }
	// begin inline asm
	shfl.sync.down.b32 %r40, %r41, %r37, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd32, %r40;
	shl.b64 	%rd33, %rd32, 32;
	or.b64  	%rd34, %rd33, %rd31;
	mov.b64 	%fd19, %rd34;
	setp.lt.s32 	%p10, %r4, 24;
	setp.lt.f64 	%p11, %fd18, %fd19;
	selp.f64 	%fd20, %fd19, %fd18, %p11;
	selp.f64 	%fd21, %fd20, %fd18, %p10;
	mov.b64 	%rd35, %fd21;
	cvt.u32.u64 	%r46, %rd35;
	mov.b32 	%r47, 16;
	// begin inline asm
	shfl.sync.down.b32 %r45, %r46, %r47, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd36, %r45;
	{ .reg .b32 tmp; mov.b64 {tmp, %r51}, %rd35; }
	// begin inline asm
	shfl.sync.down.b32 %r50, %r51, %r47, %r8, %r9;
	// end inline asm
	cvt.u64.u32 	%rd37, %r50;
	shl.b64 	%rd38, %rd37, 32;
	or.b64  	%rd39, %rd38, %rd36;
	mov.b64 	%fd22, %rd39;
	setp.lt.s32 	%p12, %r4, 16;
	setp.lt.f64 	%p13, %fd21, %fd22;
	selp.f64 	%fd23, %fd22, %fd21, %p13;
	selp.f64 	%fd54, %fd23, %fd21, %p12;
	setp.ne.s32 	%p14, %r4, 0;
	@%p14 bra 	$L__BB71_4;
// %bb.3:
	shr.s32 	%r55, %r2, 31;
	shr.u32 	%r56, %r55, 27;
	add.s32 	%r57, %r2, %r56;
	shr.s32 	%r58, %r57, 5;
	mul.wide.s32 	%rd40, %r58, 8;
	mov.u64 	%rd41, _ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage;
	add.s64 	%rd42, %rd41, %rd40;
	st.shared.f64 	[%rd42+16], %fd54;
$L__BB71_4:
	bar.sync 	0;
	setp.ne.s32 	%p15, %r2, 0;
	@%p15 bra 	$L__BB71_6;
// %bb.5:
	ld.shared.f64 	%fd24, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+24];
	setp.gt.f64 	%p16, %fd24, %fd54;
	selp.f64 	%fd25, %fd24, %fd54, %p16;
	ld.shared.f64 	%fd26, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+32];
	setp.gt.f64 	%p17, %fd26, %fd25;
	selp.f64 	%fd27, %fd26, %fd25, %p17;
	ld.shared.f64 	%fd28, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+40];
	setp.gt.f64 	%p18, %fd28, %fd27;
	selp.f64 	%fd29, %fd28, %fd27, %p18;
	ld.shared.f64 	%fd30, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+48];
	setp.gt.f64 	%p19, %fd30, %fd29;
	selp.f64 	%fd31, %fd30, %fd29, %p19;
	ld.shared.f64 	%fd32, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+56];
	setp.gt.f64 	%p20, %fd32, %fd31;
	selp.f64 	%fd33, %fd32, %fd31, %p20;
	ld.shared.f64 	%fd34, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+64];
	setp.gt.f64 	%p21, %fd34, %fd33;
	selp.f64 	%fd35, %fd34, %fd33, %p21;
	ld.shared.f64 	%fd36, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+72];
	setp.gt.f64 	%p22, %fd36, %fd35;
	selp.f64 	%fd37, %fd36, %fd35, %p22;
	ld.shared.f64 	%fd38, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+80];
	setp.gt.f64 	%p23, %fd38, %fd37;
	selp.f64 	%fd39, %fd38, %fd37, %p23;
	ld.shared.f64 	%fd40, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+88];
	setp.gt.f64 	%p24, %fd40, %fd39;
	selp.f64 	%fd41, %fd40, %fd39, %p24;
	ld.shared.f64 	%fd42, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+96];
	setp.gt.f64 	%p25, %fd42, %fd41;
	selp.f64 	%fd43, %fd42, %fd41, %p25;
	ld.shared.f64 	%fd44, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+104];
	setp.gt.f64 	%p26, %fd44, %fd43;
	selp.f64 	%fd45, %fd44, %fd43, %p26;
	ld.shared.f64 	%fd46, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+112];
	setp.gt.f64 	%p27, %fd46, %fd45;
	selp.f64 	%fd47, %fd46, %fd45, %p27;
	ld.shared.f64 	%fd48, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+120];
	setp.gt.f64 	%p28, %fd48, %fd47;
	selp.f64 	%fd49, %fd48, %fd47, %p28;
	ld.shared.f64 	%fd50, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+128];
	setp.gt.f64 	%p29, %fd50, %fd49;
	selp.f64 	%fd51, %fd50, %fd49, %p29;
	ld.shared.f64 	%fd52, [_ZZL36chpl_gpu_dev_max_breduce__real64_512dPdE12temp_storage+136];
	setp.gt.f64 	%p30, %fd52, %fd51;
	selp.f64 	%fd54, %fd52, %fd51, %p30;
$L__BB71_6:
	@%p15 bra 	$L__BB71_8;
// %bb.7:
	ld.param.u64 	%rd5, [chpl_gpu_kernel_InitFluid_line_242_2_param_5];
	cvta.to.global.u64 	%rd1, %rd5;
	mul.wide.u32 	%rd43, %r1, 8;
	add.s64 	%rd3, %rd1, %rd43;
	st.global.f64 	[%rd3], %fd54;
$L__BB71_8:
	ret;
                                        // -- End function
}
	// .globl	_local__ASSIGN__chpl    // -- Begin function _local__ASSIGN__chpl
.visible .func _local__ASSIGN__chpl(
	.param .b64 _local__ASSIGN__chpl_param_0,
	.param .b64 _local__ASSIGN__chpl_param_1
)                                       // @_local__ASSIGN__chpl
{
	.reg .b64 	%rd<5>;
	.reg .f64 	%fd<17>;

// %bb.0:
	ld.param.u64 	%rd1, [_local__ASSIGN__chpl_param_0];
	ld.param.u64 	%rd2, [_local__ASSIGN__chpl_param_1];
	ld.u64 	%rd3, [%rd2];
	ld.f64 	%fd1, [%rd2+8];
	ld.f64 	%fd2, [%rd2+16];
	ld.f64 	%fd3, [%rd2+24];
	ld.f64 	%fd4, [%rd2+32];
	ld.f64 	%fd5, [%rd2+40];
	ld.f64 	%fd6, [%rd2+48];
	ld.f64 	%fd7, [%rd2+56];
	ld.f64 	%fd8, [%rd2+64];
	ld.f64 	%fd9, [%rd2+72];
	ld.f64 	%fd10, [%rd2+80];
	ld.f64 	%fd11, [%rd2+88];
	ld.f64 	%fd12, [%rd2+96];
	ld.f64 	%fd13, [%rd2+104];
	ld.f64 	%fd14, [%rd2+112];
	ld.f64 	%fd15, [%rd2+120];
	ld.f64 	%fd16, [%rd2+128];
	ld.u64 	%rd4, [%rd2+136];
	st.u64 	[%rd1], %rd3;
	st.f64 	[%rd1+8], %fd1;
	st.f64 	[%rd1+16], %fd2;
	st.f64 	[%rd1+24], %fd3;
	st.f64 	[%rd1+32], %fd4;
	st.f64 	[%rd1+40], %fd5;
	st.f64 	[%rd1+48], %fd6;
	st.f64 	[%rd1+56], %fd7;
	st.f64 	[%rd1+64], %fd8;
	st.f64 	[%rd1+72], %fd9;
	st.f64 	[%rd1+80], %fd10;
	st.f64 	[%rd1+88], %fd11;
	st.f64 	[%rd1+96], %fd12;
	st.f64 	[%rd1+104], %fd13;
	st.f64 	[%rd1+112], %fd14;
	st.f64 	[%rd1+120], %fd15;
	st.f64 	[%rd1+128], %fd16;
	st.u64 	[%rd1+136], %rd4;
	ret;
                                        // -- End function
}
	// .globl	chpl___ASSIGN_17        // -- Begin function chpl___ASSIGN_17
.visible .func chpl___ASSIGN_17(
	.param .b64 chpl___ASSIGN_17_param_0,
	.param .b64 chpl___ASSIGN_17_param_1
)                                       // @chpl___ASSIGN_17
{
	.reg .b64 	%rd<5>;
	.reg .f64 	%fd<17>;

// %bb.0:
	ld.param.u64 	%rd1, [chpl___ASSIGN_17_param_0];
	ld.param.u64 	%rd2, [chpl___ASSIGN_17_param_1];
	ld.u64 	%rd3, [%rd2];
	ld.f64 	%fd1, [%rd2+8];
	ld.f64 	%fd2, [%rd2+16];
	ld.f64 	%fd3, [%rd2+24];
	ld.f64 	%fd4, [%rd2+32];
	ld.f64 	%fd5, [%rd2+40];
	ld.f64 	%fd6, [%rd2+48];
	ld.f64 	%fd7, [%rd2+56];
	ld.f64 	%fd8, [%rd2+64];
	ld.f64 	%fd9, [%rd2+72];
	ld.f64 	%fd10, [%rd2+80];
	ld.f64 	%fd11, [%rd2+88];
	ld.f64 	%fd12, [%rd2+96];
	ld.f64 	%fd13, [%rd2+104];
	ld.f64 	%fd14, [%rd2+112];
	ld.f64 	%fd15, [%rd2+120];
	ld.f64 	%fd16, [%rd2+128];
	ld.u64 	%rd4, [%rd2+136];
	st.u64 	[%rd1], %rd3;
	st.f64 	[%rd1+8], %fd1;
	st.f64 	[%rd1+16], %fd2;
	st.f64 	[%rd1+24], %fd3;
	st.f64 	[%rd1+32], %fd4;
	st.f64 	[%rd1+40], %fd5;
	st.f64 	[%rd1+48], %fd6;
	st.f64 	[%rd1+56], %fd7;
	st.f64 	[%rd1+64], %fd8;
	st.f64 	[%rd1+72], %fd9;
	st.f64 	[%rd1+80], %fd10;
	st.f64 	[%rd1+88], %fd11;
	st.f64 	[%rd1+96], %fd12;
	st.f64 	[%rd1+104], %fd13;
	st.f64 	[%rd1+112], %fd14;
	st.f64 	[%rd1+120], %fd15;
	st.f64 	[%rd1+128], %fd16;
	st.u64 	[%rd1+136], %rd4;
	ret;
                                        // -- End function
}
	// .globl	_ZN3cub32CUB_200500___CUDA_ARCH_LIST___NS11EmptyKernelIvEEvv // -- Begin function _ZN3cub32CUB_200500___CUDA_ARCH_LIST___NS11EmptyKernelIvEEvv
.visible .entry _ZN3cub32CUB_200500___CUDA_ARCH_LIST___NS11EmptyKernelIvEEvv() // @_ZN3cub32CUB_200500___CUDA_ARCH_LIST___NS11EmptyKernelIvEEvv
{


// %bb.0:
	ret;
                                        // -- End function
}
	// .globl	__nv_sqrt               // -- Begin function __nv_sqrt
.visible .func  (.param .b64 func_retval0) __nv_sqrt(
	.param .b64 __nv_sqrt_param_0
)                                       // @__nv_sqrt
{
	.reg .f64 	%fd<3>;

// %bb.0:
	ld.param.f64 	%fd1, [__nv_sqrt_param_0];
	sqrt.rn.f64 	%fd2, %fd1;
	st.param.f64 	[func_retval0+0], %fd2;
	ret;
                                        // -- End function
}
	// .globl	__nv_isnand             // -- Begin function __nv_isnand
.visible .func  (.param .b32 func_retval0) __nv_isnand(
	.param .b64 __nv_isnand_param_0
)                                       // @__nv_isnand
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<2>;
	.reg .f64 	%fd<3>;

// %bb.0:
	ld.param.f64 	%fd1, [__nv_isnand_param_0];
	abs.f64 	%fd2, %fd1;
	setp.gtu.f64 	%p1, %fd2, 0d7FF0000000000000;
	selp.u32 	%r1, 1, 0, %p1;
	st.param.b32 	[func_retval0+0], %r1;
	ret;
                                        // -- End function
}
